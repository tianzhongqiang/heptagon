<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>香港精算学会前会长，陆健瑜先生教你如何衡量一家寿险公司</title>
      <link href="/2018/12/04/baoxian-7/"/>
      <url>/2018/12/04/baoxian-7/</url>
      
        <content type="html"><![CDATA[<p>文章转自：<a href="http://blog.sina.com.cn/s/blog_470f56ac01011bk7.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_470f56ac01011bk7.html</a></p><p>假如有人问：如何衡量一家寿险公司的价值？这里给出的简单回答是：它等于三家公司加一幅画。<br>这是什么意思呢？它是指一家寿险公司可被当作是拥有三家子公司的控股公司：服务公司、销售公司以及投资公司，再加上一幅名画。<br>以下的方法虽然是用来对寿险公司价值作评估的，但实际上其原理适用于各种公司，而非单单保险公司。</p><h2 id="服务公司"><a href="#服务公司" class="headerlink" title="服务公司"></a>服务公司</h2><p>服务公司通过向已有客户提供服务来赚取利润，它需要适量的资本来维持运作，多余的资本将作为红利返还给控股公司。显然，该公司的价值等于红利的现金价值减去初始的资本需求。<br>红利的现金价值通过将红利贴现得到，贴现率i通常被称作基准利率，同时也可以作为股东回报率或者资本成本率。<br>如上所述，服务公司需要资本，主要有两类：一类是营运资本，例如购置机器设备、营业场所费用、后勤支持等的资金。对于银行和保险公司，由于它们对公众的信托职责，因此还需另外一种资本——监管机构指定的风险资本。对于保险公司这通常也称作偿付能力额度（solvency margin）或者风险资本（risk-based capital），它作为一种缓冲器，确保这些金融机构在经济情况不利时不至于破产。在大多数情况下（并非全部），风险资本会超过营运资本。如果监管机构对风险资本的投资未作任何的限制，营运资本可以由部分的风险资本构成。在这种情况下，公司实际上只需要风险资本。假如公司将一部分的业务外包给外部公司，这些外部公司将必须拥有自己的营运资本，而不能利用银行或保险公司的风险资本，因而总体的经济效应是会差了一些。<br>对于保险公司，尤其是寿险公司而言，有效保单的维持类似于服务公司的职能，并且有效保单的价值类似于服务公司的价值。<br>下面给出一张有效保单的价值计算过程：在现实（或者最优估计）的假设基础上进行公司每年的帐目预测，这些假设包括未来的投资回报率j，死亡率和发病率，失效率和退保率，获取成本和维持费用（包括固定费用和可变费用），税率等等。保单的责任准备金按照法定原则(通常较为保守的)进行计算。同样，偿付能力额度也是根据监管要求进行计算。这样，预测的结果是每年的“可分配利润”。就是说，这些利润是服务公司经营时所不需要的多余的利润。这里我们假设把这可分配利润转移至“投资公司”（见下（3））进行投资。<br>精算实务的谨慎性要求可分配利润的预测值必须每年为正。假如某年的预测值为负，这意味着该年需要资本注入。如果公司缺乏资金，那么保单持有人将得不到赔付，保险公司业务的信托性质不允许这种情况发生。唯一允许损失发生的时间是保单起始年，即新业务的发生年，这种损失被称为展业负担 (new business strain)，这种损失可看作是保险公司的投资以获取新业务。如果一家保险公司不能承受这种展业负担，公司应当停止承保新业务。<br>值得一提的是j与i有很大的区别：j是公司资产组合（包括公债、股票等）的回报率，当前很多公司的j值在5％左右。相对而言，i指股东预期的回报率，由于业务经营涉及的风险显著高于投资组合的风险，因此i通常较高。用10％与15％之间的 i 的也屡见不鲜。</p><h2 id="销售公司"><a href="#销售公司" class="headerlink" title="销售公司"></a>销售公司</h2><p>销售公司的职责顾名思义是获取新业务。一旦新业务产生，该业务立即出售给服务公司以获取酬金，其值等价于服务公司预期的该业务所有未来收益的现值，减去所需的风险资本以及（或者）营运资本。换而言之，服务公司在这部分业务上不赚取利润。<br>我们构建一个模型，用历史数据估计销售公司以后年度的销售量。这属于静态计算：仅用历史数据来推断将来，它并没有考虑动态的整体经济和社会政治环境的影响。这种动态的推断只能留给少数的智者去猜测了。<br>于是，销售公司可以预计基准年的一定利润，通过假设一定的增长率（可以逐年变化）以预测每年的期望利润。预测的年限根据个人的偏好一般在5到30年之间。然后，这些利润用贴现率k计算出现值，k通常要比i大，以补偿假设的增长率与实际情况不符的额外风险。人们常用 k＝i+5％，但没人知道其原因何在。<br>在考虑逐步加剧的业务竞争对利润的影响，模型所能作出的估计是十分有限的。两种常见的方法是：（a）在一定时期内，比如说10年，使用逐步降低的增长率假设，随后增长率趋于平稳；（b）“边际紧缩（margin squeeze）”方法，它假设利润在一定时间内逐年递减，比如每年减少0.5％。<br>于是，销售公司的价值就等于上文所得到的现值减去营运资本需求。当销售公司作为保险公司的一部分时，我们可以假定服务公司将其部分的盈余资本（即风险资本超过营运资本的部分）借给销售公司，使其实际上成为一家零资本公司。但是如果销售职能外包给外部的经纪人或者代理人公司，这种情形便不成立。经纪人或者代理人公司都需要有自己的营运资本，这对这些公司而言是一种费用。</p><h2 id="投资公司"><a href="#投资公司" class="headerlink" title="投资公司"></a>投资公司</h2><p>当我们听到微软将几十亿的美元几乎都投资在无风险的政府债券上，获取极低的回报时，常会发出一个很简单的问题：如果微软将这笔钱分给股东，那会是什么情形？股价是否会受到影响？合理的回答应该是很简单：不！因为这笔资金不会影响微软的利润。<br>同样的原因，剩余资本（即净资产减去偿付能力额度），有时也称作自由盈余，将由投资公司投资在市场上交易的证券上。投资公司的价值即等于这些证券的市价总值，这里不包含未来现金流的贴现值。<br>以上所描述的情况并不考虑把剩余资金分配给股东可能对公司的信用评级造成的影响。</p><h2 id="名画"><a href="#名画" class="headerlink" title="名画"></a>名画</h2><p>这里用“名画”来象征投资公众的心理状态。毕加索的一幅“拿烟斗的小孩”2004年5月在纽约拍卖了超过一亿美元，虽然它并不产生任何的现金流，然而人们甘愿为它付出天价。这并不体现其经济价值，而反映的是在某一时刻感情上或者心理上的价值。每一幅名画都是唯一的，其价值随时间变化而变化。<br>股票市场的涨落反映了投资公众的群体心理学。一家公司的市场价值在一天可能轻易的上涨或者下跌二到三个百分点，但公司的基础却没有丝毫的改变，这使得任何的合理的分析无效。<br>我们把这部分的公司价值称作“画价”，有趣的是公司的画价可能为负值。比方说，如果一个公司由于缺乏现金或者管理者决定退出市场，因而处于被迫出售的境地，这种情形下的“画价”可以是负的。<br>商誉是一项常令人觉得混淆的东西。我们在下面 G6 略为探讨。</p><p>保险术语：</p><ul><li>在保险术语中，服务公司和投资公司的联合价值被称为内含价值（EV）。有时候，有效保单的价值指扣除偿付能力额度以后的价值，而有时候包含偿付能力额度。这容易产生混淆，我们必须找出上下文中的真实含义。在上面的分析中，我们假设服务公司持有必须的资本而投资公司持有剩余资本。在任何情况下，下面的表达式应当不会造成误解：</li><li>内含价值＝有效保单价值 + 净资产 - 偿付能力额度＝有效保单价值 + 自由盈余</li><li>内含价值加上销售公司的价值便是评估价值（AV）。评估价值加上画的价值即等于公司的市场价值。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 保险 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 保险 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>保险业学习文章汇总兼资料整理</title>
      <link href="/2018/12/04/baoxian-8/"/>
      <url>/2018/12/04/baoxian-8/</url>
      
        <content type="html"><![CDATA[<p>文章转自：<a href="https://xueqiu.com/7379293559/98447990" target="_blank" rel="noopener">https://xueqiu.com/7379293559/98447990</a></p><p>该文内大多数资料都来自于 @红色番茄酱 本文基于作者的收藏添加了部分自己学习过程中遇到的一些较好的资料，并适当的扩展了一下文章的内容，如有侵权，敬请告知。</p><p>各位有好的学习资料欢迎推荐。</p><h1 id="保险业基本概念"><a href="#保险业基本概念" class="headerlink" title="保险业基本概念"></a>保险业基本概念</h1><p>1.保险业学习：盈利模式和估值<a href="https://xueqiu.com/7379293559/95391723" target="_blank" rel="noopener">https://xueqiu.com/7379293559/95391723</a></p><p>2.保险业学习：负债、准备金和剩余边际<a href="https://xueqiu.com/7379293559/95524754" target="_blank" rel="noopener">https://xueqiu.com/7379293559/95524754</a></p><p>3.保险业基本概念整理<a href="https://xueqiu.com/7379293559/98307233" target="_blank" rel="noopener">https://xueqiu.com/7379293559/98307233</a></p><p>4.中国平安投资者关系常见词汇表<a href="http://pingan.cn/ir/questions-answers.shtml" target="_blank" rel="noopener">http://pingan.cn/ir/questions-answers.shtml</a></p><p>5.保监会保险知识科普<a href="http://www.circ.gov.cn/web/site47/tab4313/" target="_blank" rel="noopener">http://www.circ.gov.cn/web/site47/tab4313/</a></p><h1 id="内含价值分析"><a href="#内含价值分析" class="headerlink" title="内含价值分析"></a>内含价值分析</h1><p>1.偿一代&amp;偿二代下内含价值的计算<a href="https://xueqiu.com/7379293559/97603198" target="_blank" rel="noopener">https://xueqiu.com/7379293559/97603198</a></p><p>2.平安寿险内含价值分析：偿二代下增速近30%<a href="https://xueqiu.com/7379293559/97831462" target="_blank" rel="noopener">https://xueqiu.com/7379293559/97831462</a></p><p>3.中国平安内含价值敏感性分析<a href="https://xueqiu.com/7379293559/98572368" target="_blank" rel="noopener">https://xueqiu.com/7379293559/98572368</a></p><h1 id="剩余边际和利润"><a href="#剩余边际和利润" class="headerlink" title="剩余边际和利润"></a>剩余边际和利润</h1><p>1.会计准则下寿险保险合同准备金计量方法<a href="https://xueqiu.com/4111857140/96902762" target="_blank" rel="noopener">https://xueqiu.com/4111857140/96902762</a></p><p>2.剩余边际、风险边际和保险公司利润<a href="https://xueqiu.com/7379293559/98173688" target="_blank" rel="noopener">https://xueqiu.com/7379293559/98173688</a></p><p>3.保险业研究之剩余边际测算<a href="https://xueqiu.com/7379293559/98241528" target="_blank" rel="noopener">https://xueqiu.com/7379293559/98241528</a></p><p>4.假设平安新业务不再增长，剩余边际至少增长12.5年<a href="https://xueqiu.com/7379293559/98337867" target="_blank" rel="noopener">https://xueqiu.com/7379293559/98337867</a></p><p>5.平安寿险利润拆解和预测<a href="https://xueqiu.com/7379293559/98856407" target="_blank" rel="noopener">https://xueqiu.com/7379293559/98856407</a></p><h1 id="资产负债管理"><a href="#资产负债管理" class="headerlink" title="资产负债管理"></a>资产负债管理</h1><p>1.平安寿险资产负债管理的策略与实践<a href="https://xueqiu.com/7379293559/98514453" target="_blank" rel="noopener">https://xueqiu.com/7379293559/98514453</a></p><p>2.寿险公司投资收益和利润分析（2016）<a href="https://xueqiu.com/3280830222/86734716" target="_blank" rel="noopener">https://xueqiu.com/3280830222/86734716</a></p><h1 id="好的学习资料"><a href="#好的学习资料" class="headerlink" title="好的学习资料"></a>好的学习资料</h1><p>1.上市公司资料</p><p>平安寿险价值深度解析-2016<a href="http://www.pingan.com/app_upload/images/info/upload/4c6dbcad-8840-4371-8eaa-4323871f3638.pdf" target="_blank" rel="noopener">http://www.pingan.com/app_upload/images/info/upload/4c6dbcad-8840-4371-8eaa-4323871f3638.pdf</a></p><p>平安寿险价值深度解析二-2017<a href="http://www.pingan.com/app_upload/images/info/upload/ecbb76f0-124c-4346-b387-8bcb4f0d6c19.pdf" target="_blank" rel="noopener">http://www.pingan.com/app_upload/images/info/upload/ecbb76f0-124c-4346-b387-8bcb4f0d6c19.pdf</a></p><p>中国太保2017开放日资料<a href="http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2017-12-15/601601_20171215_2.pdf" target="_blank" rel="noopener">http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2017-12-15/601601_20171215_2.pdf</a></p><p>太保-2017H锻造可持续的寿险价值增长<a href="http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2017-06-26/601601_20170626_2.pdf" target="_blank" rel="noopener">http://static.sse.com.cn/disclosure/listedinfo/announcement/c/2017-06-26/601601_20170626_2.pdf</a></p><p>2.文章类</p><p>（1）公众号：<a href="https://mp.weixin.qq.com/mp/profile_ext?action=home&__biz=MzAwMjM4MzIzNw==&scene=124#wechat_redirect" target="_blank" rel="noopener">保险神谭</a>，其中有《保险学》课程1-47【围绕财报展开的，对理清一些重要概念很有用，推荐】。<br>另外作者新出了一本书，《保险公司经营分析：基于财务报告》，可以很好的梳理一下保险学习中的框架。</p><p>（2）童成墩保险科普系列<br>【里面涉及对一些基本概念的理解，入门之后再来看可能更好】<br>公众号：<a href="https://mp.weixin.qq.com/mp/profile_ext?action=home&__biz=MzIzNzMzMzYyMg==&scene=124#wechat_redirect" target="_blank" rel="noopener">诚朴资产管理</a></p><p>（3）保险的价值视角之二：解构内含价值<a href="https://xueqiu.com/4179588445/65927931" target="_blank" rel="noopener">https://xueqiu.com/4179588445/65927931</a></p><p>【偿一代下深度解读内含价值的文章，值得一看】</p><p>（4）中国平安是一张高收益债券（草帽路飞的大作）</p><p>中国平安是一张高收益债券（4万字收藏版上）<a href="http://xueqiu.com/3727797950/33697052" target="_blank" rel="noopener">http://xueqiu.com/3727797950/33697052</a></p><p>中国平安是一张高收益债券（4万字收藏版下）<a href="http://xueqiu.com/3727797950/33697183" target="_blank" rel="noopener">http://xueqiu.com/3727797950/33697183</a><br>【偿一代下的研究，偿二代下里面说的部分内容现在已经改变；比较全面，本来是分开一部分一部分的，小块文章里多了一些推荐的保险相关大V；另外很多文章下的讨论值得一看。】</p><p>3.翻过的一些书籍</p><p>《保险财务管理》【作者周国端，很多内容是从保险公司内部出发的；要对保险深入研究者值得一看】</p><p>《保险公司会计》【这类都差不多，不具体推荐哪一本；理解会计基本概念型】</p><p>《保险学》【这类也差不多，对保险有个基本了解，比如分类，风险之类】</p><p>《日本寿险业研究》【作者万峰等，对国外保险的研究值得借鉴】</p><p>《中国保险业发展报告》【每年一本，行业视角】</p><p>《迷失的盛宴》【中国保险业历史】</p><h1 id="网站篇"><a href="#网站篇" class="headerlink" title="网站篇"></a>网站篇</h1><p>1.管理机构</p><p>保监会<a href="http://www.circ.gov.cn/web/site0/" target="_blank" rel="noopener">http://www.circ.gov.cn/web/site0/</a></p><p>精算师协会<a href="https://www.e-caa.org.cn/" target="_blank" rel="noopener">https://www.e-caa.org.cn/</a></p><p>中国保险业协会<a href="http://icid.iachina.cn/" target="_blank" rel="noopener">http://icid.iachina.cn/</a></p><p>财政部<a href="http://www.mof.gov.cn/index.htm" target="_blank" rel="noopener">http://www.mof.gov.cn/index.htm</a></p><p>保险资产管理协会<a href="http://www.iamac.org.cn/" target="_blank" rel="noopener">http://www.iamac.org.cn/</a></p><p>2.上市公司</p><p>中国太保投资者关系<a href="http://www.cpic.com.cn/ir/" target="_blank" rel="noopener">http://www.cpic.com.cn/ir/</a></p><h1 id="官方准则"><a href="#官方准则" class="headerlink" title="官方准则"></a>官方准则</h1><p>1.精算实践标准：人身保险内含价值评估标准<a href="http://www.e-caa.org.cn/systemNews/show/8a7da90a584878e4015884bd60135306?str=%E4%B8%93%E4%B8%9A%E6%A0%87%E5%87%86" target="_blank" rel="noopener">http://www.e-caa.org.cn/systemNews/show/8a7da90a584878e4015884bd60135306?str=%E4%B8%93%E4%B8%9A%E6%A0%87%E5%87%86</a></p><p>2.中国精算师协会《精算实践标准：人身保险内含价值评估标准》发布说明<a href="https://www.e-caa.org.cn/systemNews/show/8a7da90a584878e4015885ae72495355?str=%E5%8A%A8%E6%80%81%E8%A6%81%E9%97%BB" target="_blank" rel="noopener">https://www.e-caa.org.cn/systemNews/show/8a7da90a584878e4015885ae72495355?str=%E5%8A%A8%E6%80%81%E8%A6%81%E9%97%BB</a></p><p>3.偿二代偿付能力准则<a href="http://www.circ.gov.cn/web/site0/tab5225/info3951923.htm" target="_blank" rel="noopener">http://www.circ.gov.cn/web/site0/tab5225/info3951923.htm</a></p><p>4.保险合同负债适用折现率<a href="http://www.circ.gov.cn/web/site0/tab5216/info4063389.htm" target="_blank" rel="noopener">http://www.circ.gov.cn/web/site0/tab5216/info4063389.htm</a></p><p>5.财政部关于保险公司执行新金融工具相关会计准则有关过渡办法的通知<a href="http://www.gov.cn/xinwen/2017-07/06/content_5208416.htm" target="_blank" rel="noopener">http://www.gov.cn/xinwen/2017-07/06/content_5208416.htm</a></p><p>6.关于保险公司准备金支出企业所得税税前扣除有关政策问题的通知<a href="http://szs.mof.gov.cn/zhengwuxinxi/zhengcefabu/201611/t20161124_2465975.html" target="_blank" rel="noopener">http://szs.mof.gov.cn/zhengwuxinxi/zhengcefabu/201611/t20161124_2465975.html</a></p><h1 id="相关指引"><a href="#相关指引" class="headerlink" title="相关指引"></a>相关指引</h1><p>1.会计准则下寿险保险合同准备金计量方法<a href="https://xueqiu.com/4111857140/96902762" target="_blank" rel="noopener">https://xueqiu.com/4111857140/96902762</a></p><p>2.寿险估值<a href="https://xueqiu.com/7379293559/98317930" target="_blank" rel="noopener">https://xueqiu.com/7379293559/98317930</a></p><h1 id="数据篇"><a href="#数据篇" class="headerlink" title="数据篇"></a>数据篇</h1><p>1.保监会统计数据<a href="http://www.circ.gov.cn/web/site0/tab5179/" target="_blank" rel="noopener">http://www.circ.gov.cn/web/site0/tab5179/</a></p><p>2.保险合同准备金基准（750平均线）<a href="http://yield.chinabond.com.cn/cbweb-mn/yc/bxjInit?locale=zh_CN" target="_blank" rel="noopener">http://yield.chinabond.com.cn/cbweb-mn/yc/bxjInit?locale=zh_CN</a></p><h1 id="他山之石"><a href="#他山之石" class="headerlink" title="他山之石"></a>他山之石</h1><p>1.美国寿险业危机<a href="https://xueqiu.com/7379293559/97623587" target="_blank" rel="noopener">https://xueqiu.com/7379293559/97623587</a></p><p>2.日本保险业研究报告<a href="https://xueqiu.com/7912472055/73143967" target="_blank" rel="noopener">https://xueqiu.com/7912472055/73143967</a></p><h1 id="值得推荐公众号"><a href="#值得推荐公众号" class="headerlink" title="值得推荐公众号"></a>值得推荐公众号</h1><p>保监微课堂：保监会官方公众号，质量较高</p><p>慧保天下：一些文章较有深度</p><p>保险神谭：其中的《保险学》课程值得一看</p><p>中国保险资产管理业协会：保险业资产管理，部分培训内容有干货</p><p>13个精算师</p><p>券商类</p><p>海通非银</p><p>欣琦看金融</p><p>湘怀看非银</p><p>华泰金融研究全新平台</p><p>长江非银</p>]]></content>
      
      
      <categories>
          
          <category> 保险 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 保险 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>爱奇艺视频爬虫</title>
      <link href="/2018/12/02/iqiyi-1/"/>
      <url>/2018/12/02/iqiyi-1/</url>
      
        <content type="html"><![CDATA[<p>爱奇艺视频抓取主要分为3步，列表页、详情页、视频源解析</p><h1 id="一、视频列表页"><a href="#一、视频列表页" class="headerlink" title="一、视频列表页"></a>一、视频列表页</h1><p><a href="http://www.iqiyi.com/u/1412822955/v" target="_blank" rel="noopener">http://www.iqiyi.com/u/1412822955/v</a></p><p>中间参数是用户id，根据用户id抓取该用户下所有的视频。</p><p>通过列表页，可以获取到视频的标题、时长等信息，还可以获取到视频的tvid</p><p>如下图，视频翻页信息也比较容易获取<br><img src="/images/iqiyi_1.png" alt=""></p><h1 id="二、视频详情页"><a href="#二、视频详情页" class="headerlink" title="二、视频详情页"></a>二、视频详情页</h1><p><a href="https://www.iqiyi.com/v_19rrbwtx6w.html" target="_blank" rel="noopener">https://www.iqiyi.com/v_19rrbwtx6w.html</a></p><p>可以使用如下接口直接获取数据</p><p> <a href="https://pcw-api.iqiyi.com/video/video/baseinfo/936127100?t=1543654272828&amp;callback=window.Q.__callbacks__.cbbj6097" target="_blank" rel="noopener">https://pcw-api.iqiyi.com/video/video/baseinfo/936127100?t=1543654272828&amp;callback=window.Q.__callbacks__.cbbj6097</a></p><p>该接口只有<code>936127100</code>是需要替换的，该数字是视频的tvid，t是时间戳，后面的callback可以不用变<br><img src="/images/iqiyi_2.png" alt=""></p><h1 id="三、视频源解析"><a href="#三、视频源解析" class="headerlink" title="三、视频源解析"></a>三、视频源解析</h1><p>上面的数据基本上就比较全了，但是没有视频源的链接。最重要的就是这一步，如何找到视频。</p><h2 id="1、如何找到视频呢？"><a href="#1、如何找到视频呢？" class="headerlink" title="1、如何找到视频呢？"></a>1、如何找到视频呢？</h2><h3 id="a-首先找到具体的视频链接"><a href="#a-首先找到具体的视频链接" class="headerlink" title="a. 首先找到具体的视频链接"></a>a. 首先找到具体的视频链接</h3><p>翻阅请求链接，找到对应的视频链接，如下：<br><a href="https://v-7cc10085.71edge.com/videos/v0/20180302/54/75/e8cec7fac4b8e38af173e51f600fafae.f4v?key=0593dd9039bdbdadfceb451e73193dac1&amp;dis_k=26ac6922bd9b87f8531b727d5b8e7acad&amp;dis_t=1543656883&amp;dis_dz=GWBN-BeiJing&amp;dis_st=42&amp;src=iqiyi.com&amp;uuid=daf70985-5c0255b3-78&amp;rn=1543656883336&amp;retry=2&amp;qd_tm=1543656836177&amp;qd_vipdyn=0&amp;qd_k=ce09023bf1030d00183b871874d25df7&amp;cross-domain=1&amp;pv=0.1&amp;qyid=a1b97b80f70476f67d4c380242c4beed&amp;qd_aid=215235201&amp;qd_stert=0&amp;qypid=948145700_01080031010000000000&amp;qd_p=daf70985&amp;qd_vip=0&amp;z=wangsucdn_cnc|baiducdn_cnc&amp;qd_index=1&amp;qd_src=01010031010000000000&amp;qd_tvid=948145700&amp;pri_idc=beijing3_cnc&amp;qd_vipres=0&amp;qd_uid=&amp;range=8192-15074468" target="_blank" rel="noopener">https://v-7cc10085.71edge.com/videos/v0/20180302/54/75/e8cec7fac4b8e38af173e51f600fafae.f4v?key=0593dd9039bdbdadfceb451e73193dac1&amp;dis_k=26ac6922bd9b87f8531b727d5b8e7acad&amp;dis_t=1543656883&amp;dis_dz=GWBN-BeiJing&amp;dis_st=42&amp;src=iqiyi.com&amp;uuid=daf70985-5c0255b3-78&amp;rn=1543656883336&amp;retry=2&amp;qd_tm=1543656836177&amp;qd_vipdyn=0&amp;qd_k=ce09023bf1030d00183b871874d25df7&amp;cross-domain=1&amp;pv=0.1&amp;qyid=a1b97b80f70476f67d4c380242c4beed&amp;qd_aid=215235201&amp;qd_stert=0&amp;qypid=948145700_01080031010000000000&amp;qd_p=daf70985&amp;qd_vip=0&amp;z=wangsucdn_cnc|baiducdn_cnc&amp;qd_index=1&amp;qd_src=01010031010000000000&amp;qd_tvid=948145700&amp;pri_idc=beijing3_cnc&amp;qd_vipres=0&amp;qd_uid=&amp;range=8192-15074468</a></p><p>可以下载下来看一下，看看是否是真正的视频（有可能是广告）。<br><img src="/images/iqiyi_4.png" alt=""></p><h3 id="b-根据真正的视频文件链接查找"><a href="#b-根据真正的视频文件链接查找" class="headerlink" title="b. 根据真正的视频文件链接查找"></a>b. 根据真正的视频文件链接查找</h3><p>可以根据 <a href="https://v-7cc10085.71edge.com/videos/v0/20180302/54/75/e8cec7fac4b8e38af173e51f600fafae.f4v" target="_blank" rel="noopener">https://v-7cc10085.71edge.com/videos/v0/20180302/54/75/e8cec7fac4b8e38af173e51f600fafae.f4v</a> 查找，如下图，发现有两个该地址，其中有一个的返回参数中是该地址<br><img src="/images/iqiyi_5.png" alt=""></p><p>看一下返回值：<br><img src="/images/iqiyi_6.png" alt=""></p><p>该请求的链接为</p><p><a href="https://data.video.iqiyi.com/videos/v0/20180302/54/75/e8cec7fac4b8e38af173e51f600fafae.f4v?qd_tvid=948145700&amp;qd_vipres=0&amp;qd_index=1&amp;qd_aid=215235201&amp;qd_stert=0&amp;qd_scc=201b52fce94e6a1e1c3fbe0584eb0bc8&amp;qd_sc=b44bc809923064b03e096a07def1514e&amp;qd_p=daf70985&amp;qd_k=ce09023bf1030d00183b871874d25df7&amp;qd_src=01010031010000000000&amp;qd_vipdyn=0&amp;qd_uid=&amp;qd_tm=1543656836177&amp;qd_vip=0&amp;cross-domain=1&amp;qyid=a1b97b80f70476f67d4c380242c4beed&amp;qypid=948145700_01080031010000000000&amp;qypid=948145700_01080031010000000000&amp;rn=1543656883336&amp;pv=0.1&amp;cross-domain=1&amp;retry=2&amp;z=wangsucdn_cnc|baiducdn_cnc&amp;pri_idc=beijing3_cnc" target="_blank" rel="noopener">https://data.video.iqiyi.com/videos/v0/20180302/54/75/e8cec7fac4b8e38af173e51f600fafae.f4v?qd_tvid=948145700&amp;qd_vipres=0&amp;qd_index=1&amp;qd_aid=215235201&amp;qd_stert=0&amp;qd_scc=201b52fce94e6a1e1c3fbe0584eb0bc8&amp;qd_sc=b44bc809923064b03e096a07def1514e&amp;qd_p=daf70985&amp;qd_k=ce09023bf1030d00183b871874d25df7&amp;qd_src=01010031010000000000&amp;qd_vipdyn=0&amp;qd_uid=&amp;qd_tm=1543656836177&amp;qd_vip=0&amp;cross-domain=1&amp;qyid=a1b97b80f70476f67d4c380242c4beed&amp;qypid=948145700_01080031010000000000&amp;qypid=948145700_01080031010000000000&amp;rn=1543656883336&amp;pv=0.1&amp;cross-domain=1&amp;retry=2&amp;z=wangsucdn_cnc|baiducdn_cnc&amp;pri_idc=beijing3_cnc</a></p><h3 id="c-根据该链接继续往上找"><a href="#c-根据该链接继续往上找" class="headerlink" title="c. 根据该链接继续往上找"></a>c. 根据该链接继续往上找</h3><p>根据该请求的参数继续搜索，会找到这样一个链接。<br><img src="/images/iqiyi_7.png" alt=""></p><p>看一下该链接返回的部分请求<br><img src="/images/iqiyi_8.png" alt=""></p><p>从图上可以看出，该链接可以由2个参数拼接而成。</p><p>链接地址：</p><p><a href="https://cache.video.iqiyi.com/jp/dash?tvid=948145700&amp;bid=300&amp;vid=09e057ad7b03f2616a007cd90d3c429d&amp;src=01010031010000000000&amp;vt=0&amp;rs=1&amp;uid=&amp;ori=pcw&amp;ps=0&amp;tm=1543656836919&amp;qd_v=1&amp;k_uid=a1b97b80f70476f67d4c380242c4beed&amp;pt=0&amp;d=0&amp;s=&amp;lid=&amp;cf=&amp;ct=&amp;authKey=1756f66fda45b581f60e8c5345b1f49b&amp;k_tag=1&amp;ost=0&amp;ppt=0&amp;dfp=a0c6296852fce442fb9ee3af8f6411d2fb8ac1b538dcf2d3a25a54b26648919f07&amp;locale=zh_cn&amp;prio=%7B%22ff%22%3A%22f4v%22%2C%22code%22%3A2%7D&amp;pck=&amp;k_err_retries=0&amp;k_ft1=2748779069444&amp;bop=%7B%22version%22%3A%227.0%22%2C%22dfp%22%3A%22a0c6296852fce442fb9ee3af8f6411d2fb8ac1b538dcf2d3a25a54b26648919f07%22%7D&amp;callback=Q838114a04d5d4d3adb265513f3244a36&amp;ut=0&amp;vf=ce09023bf1030d00183b871874d25df7" target="_blank" rel="noopener">https://cache.video.iqiyi.com/jp/dash?tvid=948145700&amp;bid=300&amp;vid=09e057ad7b03f2616a007cd90d3c429d&amp;src=01010031010000000000&amp;vt=0&amp;rs=1&amp;uid=&amp;ori=pcw&amp;ps=0&amp;tm=1543656836919&amp;qd_v=1&amp;k_uid=a1b97b80f70476f67d4c380242c4beed&amp;pt=0&amp;d=0&amp;s=&amp;lid=&amp;cf=&amp;ct=&amp;authKey=1756f66fda45b581f60e8c5345b1f49b&amp;k_tag=1&amp;ost=0&amp;ppt=0&amp;dfp=a0c6296852fce442fb9ee3af8f6411d2fb8ac1b538dcf2d3a25a54b26648919f07&amp;locale=zh_cn&amp;prio=%7B%22ff%22%3A%22f4v%22%2C%22code%22%3A2%7D&amp;pck=&amp;k_err_retries=0&amp;k_ft1=2748779069444&amp;bop=%7B%22version%22%3A%227.0%22%2C%22dfp%22%3A%22a0c6296852fce442fb9ee3af8f6411d2fb8ac1b538dcf2d3a25a54b26648919f07%22%7D&amp;callback=Q838114a04d5d4d3adb265513f3244a36&amp;ut=0&amp;vf=ce09023bf1030d00183b871874d25df7</a></p><h3 id="d-继续找，一直找到最上层的请求链接"><a href="#d-继续找，一直找到最上层的请求链接" class="headerlink" title="d. 继续找，一直找到最上层的请求链接"></a>d. 继续找，一直找到最上层的请求链接</h3><p>发现找到不对应的链接信息了，也就是需要拼接的链接就是这个，这个也是js中拼接的请求链接。<br>接下来就需要拼接该链接。</p><p>urldecoder解码之后看一下链接：<br><a href="https://cache.video.iqiyi.com/jp/dash?tvid=948145700&amp;bid=300&amp;vid=09e057ad7b03f2616a007cd90d3c429d&amp;src=01010031010000000000&amp;vt=0&amp;rs=1&amp;uid=&amp;ori=pcw&amp;ps=0&amp;tm=1543656836919&amp;qd_v=1&amp;k_uid=a1b97b80f70476f67d4c380242c4beed&amp;pt=0&amp;d=0&amp;s=&amp;lid=&amp;cf=&amp;ct=&amp;authKey=1756f66fda45b581f60e8c5345b1f49b&amp;k_tag=1&amp;ost=0&amp;ppt=0&amp;dfp=a0c6296852fce442fb9ee3af8f6411d2fb8ac1b538dcf2d3a25a54b26648919f07&amp;locale=zh_cn&amp;prio={&quot;ff&quot;:&quot;f4v&quot;,&quot;code&quot;:2}&amp;pck=&amp;k_err_retries=0&amp;k_ft1=2748779069444&amp;bop={&quot;version&quot;:&quot;7.0&quot;,&quot;dfp&quot;:&quot;a0c6296852fce442fb9ee3af8f6411d2fb8ac1b538dcf2d3a25a54b26648919f07&quot;}&amp;callback=Q838114a04d5d4d3adb265513f3244a36&amp;ut=0&amp;vf=ce09023bf1030d00183b871874d25df7" target="_blank" rel="noopener">https://cache.video.iqiyi.com/jp/dash?tvid=948145700&amp;bid=300&amp;vid=09e057ad7b03f2616a007cd90d3c429d&amp;src=01010031010000000000&amp;vt=0&amp;rs=1&amp;uid=&amp;ori=pcw&amp;ps=0&amp;tm=1543656836919&amp;qd_v=1&amp;k_uid=a1b97b80f70476f67d4c380242c4beed&amp;pt=0&amp;d=0&amp;s=&amp;lid=&amp;cf=&amp;ct=&amp;authKey=1756f66fda45b581f60e8c5345b1f49b&amp;k_tag=1&amp;ost=0&amp;ppt=0&amp;dfp=a0c6296852fce442fb9ee3af8f6411d2fb8ac1b538dcf2d3a25a54b26648919f07&amp;locale=zh_cn&amp;prio={&quot;ff&quot;:&quot;f4v&quot;,&quot;code&quot;:2}&amp;pck=&amp;k_err_retries=0&amp;k_ft1=2748779069444&amp;bop={&quot;version&quot;:&quot;7.0&quot;,&quot;dfp&quot;:&quot;a0c6296852fce442fb9ee3af8f6411d2fb8ac1b538dcf2d3a25a54b26648919f07&quot;}&amp;callback=Q838114a04d5d4d3adb265513f3244a36&amp;ut=0&amp;vf=ce09023bf1030d00183b871874d25df7</a></p><p>将链接中的参数做拆解<br><img src="/images/iqiyi_16.png" alt=""></p><p>挨个分析一下变化的参数；</p><p>首先tvid、vid可以从数据中获取到，tm是一个时间戳，其他的几个都不知道是啥。</p><p>那需要分析的参数就是k_uid、authKey、dfp、k_ft1、bop、callback、vf</p><h4 id="k-uid"><a href="#k-uid" class="headerlink" title="k_uid"></a>k_uid</h4><p>在搜索k_uid参数的时候，发现，其他几个参数也基本都在这，所以我们索性截一个大图慢慢看，如下：</p><p><img src="/images/iqiyi_17.png" alt=""></p><p>k_uid获取的是 l.getFluid() || l.getJsuid()</p><p>然后继续打断点找getFluid和getJsuid<br><img src="/images/iqiyi_3.png" alt=""></p><p>找到了对应的getFluid和getJsuid，不过这个参数其实不用这么复杂，其实它就是一个随机的32位字符</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">getk_uid</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   Random random = <span class="keyword">new</span> Random();</span><br><span class="line">   <span class="keyword">char</span>[] chars = <span class="keyword">new</span> <span class="keyword">char</span>[] &#123; <span class="string">'0'</span>, <span class="string">'1'</span>, <span class="string">'2'</span>, <span class="string">'3'</span>, <span class="string">'4'</span>, <span class="string">'5'</span>, <span class="string">'6'</span>, <span class="string">'7'</span>, <span class="string">'8'</span>, <span class="string">'9'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>, <span class="string">'f'</span> &#125;;</span><br><span class="line">   String id = <span class="string">""</span>;</span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> index = <span class="number">0</span>; index &lt; <span class="number">32</span>; index++) &#123;</span><br><span class="line">     id += chars[random.nextInt(<span class="number">15</span>) + <span class="number">1</span>];</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> id;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h4 id="authKey"><a href="#authKey" class="headerlink" title="authKey"></a>authKey</h4><p>从下图可以看到 <code>r(r(&quot;&quot;) + L + x)</code>，打断点跟踪。通过下图可以发现，L和x都是已知的，一个是tvid，一个是时间戳<br><img src="/images/iqiyi_10.png" alt=""></p><p>通过这个找到r方法。<br><img src="/images/iqiyi_11.png" alt=""></p><p>这个是r方法<br><img src="/images/iqiyi_13.png" alt=""></p><p>看这个发现，要让r方法执行，需要有p、n、u几个变量</p><p>从最里面找，先找u，u里面全是已知项<br><img src="/images/iqiyi_15.png" alt=""></p><p>继续往外找，按照刚才的方法继续找n，依次找下去。一直找到最后，没有任何依赖项的时候，把所有找到的方法拼起来，就可以了。<br><img src="/images/iqiyi_12.png" alt=""></p><p>最后将这些js抽取出来，组成自己的解析就可以直接使用了。<br><img src="/images/iqiyi_14.png" alt=""></p><h4 id="dfp"><a href="#dfp" class="headerlink" title="dfp"></a>dfp</h4><p>跟踪之前在上面的图中可以看到<code>dfp: g.get()</code>。<br>该参数可以为空，也可以随意设置，不影响数据的获取，可以先看别的</p><h4 id="k-ft1"><a href="#k-ft1" class="headerlink" title="k_ft1"></a>k_ft1</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> (a.os.ios || a.os.android) &amp;&amp; (e.ori = <span class="string">"h5"</span>), c.src &amp;&amp; (e.src = c.src), c.preIdAll &amp;&amp; (e.preIdAll = c.preIdAll), <span class="number">-1</span> != e.prio.indexOf(<span class="string">"m3u8"</span>) ? e.k_ft1 = y.getM3U8FT1() : <span class="number">-1</span> != e.prio.indexOf(<span class="string">"mp4"</span>) ? e.k_ft1 = y.getMP4FT1() : e.k_ft1 = y.getFT1(), u.isTraditionalChinese() &amp;&amp; (e.locale = <span class="string">"zh_tw"</span>), v.isBoss() &amp;&amp; (e.vv = <span class="string">"821d3c731e374feaa629dcdaab7c394b"</span>), q &amp;&amp; (e.ecode = <span class="string">"701"</span>), e.bop = <span class="built_in">JSON</span>.stringify(&#123;</span><br><span class="line">    version: <span class="string">"7.0"</span>,</span><br><span class="line">    dfp: g.get()</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>用同样的方法打断点跟踪，如下图<br><img src="/images/iqiyi_18.png" alt=""><br>用同样分析 authKey 时做的方法，去拆解该参数相关的方法，一直找到没有任何未知参数为止，然后把这些js方法拼接起来直接使用。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getk_ft1</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">s</span>(<span class="params">e, t</span>) </span>&#123;</span><br><span class="line">c[e][t] = !<span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">d</span>(<span class="params">e, t</span>) </span>&#123;</span><br><span class="line">c[e][t] = !<span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">l</span>(<span class="params">e, t</span>) </span>&#123;</span><br><span class="line"><span class="keyword">return</span> c[e][t]</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> c = &#123;</span><br><span class="line"><span class="number">1</span> : &#123;</span><br><span class="line"><span class="number">3</span> : !<span class="number">0</span>,</span><br><span class="line"><span class="number">37</span> : !<span class="number">1</span>,</span><br><span class="line"><span class="number">40</span> : !<span class="number">0</span>,</span><br><span class="line"><span class="number">42</span> : !<span class="number">1</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="number">2</span> : &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> e = [], t = <span class="number">1</span>; t &lt;= <span class="number">64</span>; t++)</span><br><span class="line">e.push(c[<span class="number">1</span>][t] ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">parseInt</span>(e.reverse().join(<span class="string">""</span>), <span class="number">2</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h4 id="bop"><a href="#bop" class="headerlink" title="bop"></a>bop</h4><p>该参数跟dfp参数有关，这个就比较简单了。<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getbop</span>(<span class="params">dfp, version</span>) </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">encodeURI</span>(<span class="string">"&#123;\"version\":\""</span> + version + <span class="string">"\",\"dfp\":\""</span> + dfp</span><br><span class="line">+ <span class="string">"\"&#125;"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>version设置为7.0就可以，dfp空着就ok</p><h4 id="callback"><a href="#callback" class="headerlink" title="callback"></a>callback</h4><p>同样的方法做跟踪<br><img src="/images/iqiyi_19.png" alt=""><br>继续跟下去，发现该参数调用了 authKey 方法，而传入的参数是一个地址。如下<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">callback</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="keyword">var</span> url = <span class="string">"http://cache.video.iqiyi.com/jp/dash"</span></span><br><span class="line"><span class="keyword">return</span> <span class="string">"Q"</span> + authkey(url)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h4 id="vf"><a href="#vf" class="headerlink" title="vf"></a>vf</h4><p>继续往下看最后一个参数<br><img src="/images/iqiyi_20.png" alt=""><br>发现<code>p.cmd5x(a)</code> 这个就是vf参数。<br>而a就是上面拼接好的url，只是缺少了域名和最后一个参数，链接如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/jp/dash?tvid=948145700&amp;bid=300&amp;vid=09e057ad7b03f2616a007cd90d3c429d&amp;src=01010031010000000000&amp;vt=0&amp;rs=1&amp;uid=&amp;ori=pcw&amp;ps=0&amp;tm=1543656836919&amp;qd_v=1&amp;k_uid=a1b97b80f70476f67d4c380242c4beed&amp;pt=0&amp;d=0&amp;s=&amp;lid=&amp;cf=&amp;ct=&amp;authKey=1756f66fda45b581f60e8c5345b1f49b&amp;k_tag=1&amp;ost=0&amp;ppt=0&amp;dfp=a0c6296852fce442fb9ee3af8f6411d2fb8ac1b538dcf2d3a25a54b26648919f07&amp;locale=zh_cn&amp;prio=%7B%22ff%22%3A%22f4v%22%2C%22code%22%3A2%7D&amp;pck=&amp;k_err_retries=0&amp;k_ft1=2748779069444&amp;bop=%7B%22version%22%3A%227.0%22%2C%22dfp%22%3A%22a0c6296852fce442fb9ee3af8f6411d2fb8ac1b538dcf2d3a25a54b26648919f07%22%7D&amp;callback=Q838114a04d5d4d3adb265513f3244a36&amp;ut=0</span><br></pre></td></tr></table></figure></p><p>cmd5x方法这个js太长了，就不贴在博客里面了。<br>把鼠标放在该方法上，可以看到cmd5x方法，直接使用就可以<br><img src="/images/iqiyi_21.png" alt=""></p><p>至此为止，所有参数都找到了，可以直接开始抓取了</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> 视频 </tag>
            
            <tag> 爱奇艺 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>优酷视频爬虫</title>
      <link href="/2018/12/01/youku-1/"/>
      <url>/2018/12/01/youku-1/</url>
      
        <content type="html"><![CDATA[<p>优酷视频抓取主要分为3步，列表页、详情页、视频源解析</p><p>该视频抓取主要是根据用户id获取该用户下所有的视频。跟获取全部视频没有任何差别。</p><h2 id="首先是列表页"><a href="#首先是列表页" class="headerlink" title="首先是列表页"></a>首先是列表页</h2><p><a href="http://i.youku.com/i/UMTI5OTA2MzIwOA==/videos" target="_blank" rel="noopener">http://i.youku.com/i/UMTI5OTA2MzIwOA==/videos</a></p><p>中间的参数就是用户id，根据用户的id获取视频列表。</p><p>列表上边的视频信息很容易获取到，包括视频的名称、详情、播放次数、上传时间等，最重要的是可以获取到视频详情页的地址，如下：<br><img src="/images/youku_1.png" alt=""></p><h3 id="列表翻页"><a href="#列表翻页" class="headerlink" title="列表翻页"></a>列表翻页</h3><p>列表翻页比较容易找，页面中没有做任何隐藏，如下<br><img src="/images/youku_5.png" alt=""></p><h2 id="视频详情页链接"><a href="#视频详情页链接" class="headerlink" title="视频详情页链接"></a>视频详情页链接</h2><p>从列表页可以很容易获取到视频详情页链接<br><img src="/images/youku_2.png" alt=""></p><p>详情页可以看到视频的地址，如下：<br><a href="http://pl-ali.youku.com/playlist/m3u8?vid=XMzkxNzY2MDIxMg&amp;type=flvhdv3&amp;ups_client_netip=daf70985&amp;utid=SjxXFGz%2FUnECAWX%2B8woFwZ8Z&amp;ccode=0502&amp;psid=63b8b4da2b8eb3ecc93879e59c186598&amp;ups_userid=1075200454&amp;ups_ytid=1075200454&amp;duration=1019&amp;expire=18000&amp;drm_type=1&amp;drm_device=7&amp;ups_ts=1543646420&amp;onOff=0&amp;encr=0&amp;ups_key=0f6e70dd048b3606eef5beec65644549" target="_blank" rel="noopener">http://pl-ali.youku.com/playlist/m3u8?vid=XMzkxNzY2MDIxMg&amp;type=flvhdv3&amp;ups_client_netip=daf70985&amp;utid=SjxXFGz%2FUnECAWX%2B8woFwZ8Z&amp;ccode=0502&amp;psid=63b8b4da2b8eb3ecc93879e59c186598&amp;ups_userid=1075200454&amp;ups_ytid=1075200454&amp;duration=1019&amp;expire=18000&amp;drm_type=1&amp;drm_device=7&amp;ups_ts=1543646420&amp;onOff=0&amp;encr=0&amp;ups_key=0f6e70dd048b3606eef5beec65644549</a></p><p>但是看到，却拿不到该地址，需要通过请求接口才可以拿到。</p><h2 id="拼接视频解析链接"><a href="#拼接视频解析链接" class="headerlink" title="拼接视频解析链接"></a>拼接视频解析链接</h2><p>使用如下请求接口，获取视频源地址：</p><p><a href="https://ups.youku.com/ups/get.json?vid=XMzkxNzY2MDIxMg==&amp;ccode=0502&amp;client_ip=192.168.1.1&amp;utid=CSqJFEfc5CgCAdr3CYXvTZbD&amp;client_ts=1543650312&amp;ckey=DIl58SLFxFNndSV1GFNnMQVYkx1PP5tKe1siZu%2F86PR1u%2FWh1Ptd%2BWOZsHHWxysSfAOhNJpdVWsdVJNsfJ8Sxd8WKVvNfAS8aS8fAOzYARzPyPc3JvtnPHjTdKfESTdnuTW6ZPvk2pNDh4uFzotgdMEFkzQ5wZVXl2Pf1%2FY6hLK0OnCNxBj3%2Bnb0v72gZ6b0td%2BWOZsHHWxysSo%2F0y9D2K42SaB8Y%2F%2BaD2K42SaB8Y%2F%2BahU%2BWOZsHcrxysooUeND" target="_blank" rel="noopener">https://ups.youku.com/ups/get.json?vid=XMzkxNzY2MDIxMg==&amp;ccode=0502&amp;client_ip=192.168.1.1&amp;utid=CSqJFEfc5CgCAdr3CYXvTZbD&amp;client_ts=1543650312&amp;ckey=DIl58SLFxFNndSV1GFNnMQVYkx1PP5tKe1siZu%2F86PR1u%2FWh1Ptd%2BWOZsHHWxysSfAOhNJpdVWsdVJNsfJ8Sxd8WKVvNfAS8aS8fAOzYARzPyPc3JvtnPHjTdKfESTdnuTW6ZPvk2pNDh4uFzotgdMEFkzQ5wZVXl2Pf1%2FY6hLK0OnCNxBj3%2Bnb0v72gZ6b0td%2BWOZsHHWxysSo%2F0y9D2K42SaB8Y%2F%2BaD2K42SaB8Y%2F%2BahU%2BWOZsHcrxysooUeND</a></p><p>具体参数情况</p><p><img src="/images/youku_7.png" alt=""></p><p>由上图可以看出，可变的参数只有vid、client_ts、utid、ckey三个。</p><h3 id="vid"><a href="#vid" class="headerlink" title="vid"></a>vid</h3><p>vid是视频的id，从列表页和视频详情页均可获取。</p><h3 id="client-ts"><a href="#client-ts" class="headerlink" title="client_ts"></a>client_ts</h3><p>该参数是时间戳，当前时间戳即可</p><h3 id="utid"><a href="#utid" class="headerlink" title="utid"></a>utid</h3><p>该参数可以通过请求 <a href="https://log.mmstat.com/eg.js" target="_blank" rel="noopener">https://log.mmstat.com/eg.js</a> 链接获取</p><p>请求结果：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">window</span>.goldlog=(<span class="built_in">window</span>.goldlog||&#123;&#125;);goldlog.Etag=<span class="string">"Hre6ErRmgVQCAXb364XhncX+"</span>;goldlog.stag=<span class="number">1</span>;</span><br></pre></td></tr></table></figure></p><h3 id="ckey"><a href="#ckey" class="headerlink" title="ckey"></a>ckey</h3><p>通过打断点跟踪可以发现，该参数就是浏览器的ua信息，如果获取不到就默认给一个，所以可以写死，或者提供其他的ua信息。<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">getCkey: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.uabModule ? <span class="keyword">this</span>.uabModule.getUA() : <span class="string">"DIl58SLFxFNndSV1GFNnMQVYkx1PP5tKe1siZu/86PR1u/Wh1Ptd+WOZsHHWxysSfAOhNJpdVWsdVJNsfJ8Sxd8WKVvNfAS8aS8fAOzYARzPyPc3JvtnPHjTdKfESTdnuTW6ZPvk2pNDh4uFzotgdMEFkzQ5wZVXl2Pf1/Y6hLK0OnCNxBj3+nb0v72gZ6b0td+WOZsHHWxysSo/0y9D2K42SaB8Y/+aD2K42SaB8Y/+ahU+WOZsHcrxysooUeND"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><img src="/images/youku_4.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> 视频 </tag>
            
            <tag> 优酷 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>凯恩斯与弗里德曼</title>
      <link href="/2018/11/26/jingji-1/"/>
      <url>/2018/11/26/jingji-1/</url>
      
        <content type="html"><![CDATA[<p>文章来源：<a href="http://blog.sina.com.cn/s/blog_485b8a7e0100x2tq.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_485b8a7e0100x2tq.html</a><br>作者：有智思有财<br>思想有深度，一个非常值得敬重的老大哥</p><p>　　假设10个人每人每小时可以种一棵树，但树种当局每小时只提供9棵树（货币供应量），则必然会出现1人闲置（失业）；如果树种当局每小时提供11棵树，则会出现树种膨胀。这就是凯恩斯主义货币理论中的所谓的失业与通货膨胀交替关系，还有个叫菲利普斯的把它画成了什么曲线。我们可以清楚的看到这是一个双因素模型。在这个模型中，如果每个人每小时的产量提高为2棵树，则树种当局必须把树种供应量增加到每小时20棵树种，才能保证不出现劳动力闲置（失业），而增加到21棵时，才有可能出现树种膨胀；如果每个人每小时的产量提高为3棵树，则树种当局必须把树种供应量增加到每小时30棵树种，才能保证不出现劳动力闲置（失业），而增加到31棵时，才有可能出现树种膨胀；如果每个人每小时的产量提高为10棵树，则树种当局必须把树种供应量增加到每小时100棵树种，才能保证不出现劳动力闲置（失业），而增加到101棵时，才有可能出现树种膨胀。。。用凯恩斯的话说，通货膨胀只有在充分就业时才可能发生，用弗里德曼的理论来讲，货币供应增长速度在超过产出增长速度时，就会通货膨胀。看似都有道理，而弗里德曼忘记的是，产出的是树，不给它树种，是产不出树的，当树种当局把树种供应量由每小时9棵提高到每小时100棵的过程中，树种供应增长将会长期远高于当期树的产出的，但是，不会出现所谓的“树种膨胀”。弗里德曼在他的《美国货币史》中用了大量的数据和计量经济学的分析方法也证明了这一点。非常明显，观察劳动力闲置（失业）比弗里德曼的观察树种（货币）供应增长速度作为投放货币的依据要可靠也可行得多，这使得弗里德曼自己也不得不承认，货币“短期非中性”。但令人遗憾的是，弗里德曼并不打算据此做出结论，回归古典的强烈愿望使他提出了一个“既然货币短期是非中性的，那么它长期就必然是中性”的理论，这是什么道理？而这一荒唐的理论更是被他的徒子徒孙们发展为，如果“无休止地无限度地注入货币迟早会通货膨胀的”或言之“树是不会长到天上去的”！“迟早”！那是什么时候？这个东西与弗里德曼及古典经济学理论中的“长期”一样，是一个负责任的经济学概念吗？如果按照这个思路，天外还会有天，任何稀缺要素无休止、无限度地注入都会过剩的，过剩了，便没有价值了吗？如果是这样，哪里还有“非中性”的东西？更何况，与其它资源相比，货币的有效供给能力或许会强一些，但也绝不是无限的，即使是“长期”，也是一样。难怪凯恩斯会说，“长期，我们就都已经死了！”简直是，无理取闹！</p><p>　　在这个问题上的谁是谁非原本是极为明显的，但弗里德曼可以混淆视听的原因在于一个叫作“石油危机”的东西。</p><p>　　回到我们的种树模型。事实上，种树并不象我们所讲的那么简单，它并不会为了证明某个经济学家的伟大而将自己限制为一个双因素模型。在每个人每小时可以种1棵树到每个人每小时可以种10棵树的增长过程中，可耕种土地、能源、工具等等，等等，都可能出现瓶颈，说个最简单的，还是10个人，每个人每小时可以种10棵树，树种当局每小时可以提供100棵树种，这不就是一个完美的模型了吗？不尽然，如果种这些树种需要每小时10个立方的水（石油），而实际只能得到每小时9个立方，则必然会出现1个人因得不到水而闲置，同时，如果货币当局按每小时提供100棵树种的速度供树，则会出现“树种膨胀”，这也就是传说中的“滞胀”。但，这真的远不足以完全推翻凯恩斯的货币理论，或者证明弗里德曼有哪怕一丝一毫的道理。</p><p>　　总结一下。首先我们要认识到，在人类生产力水平高速发展的今天，我们是一定会需要大量的树种（货币）才能避免劳动力闲置的危险。但同时我们也应该考虑到经济发展决不会仅是劳动力、货币二者互为瓶颈的双因素模型，事实上，土地、能源、矿产资源、环境承载能力甚至是水、空气、阳光等等都可能成为经济增长的瓶颈，而瓶颈一旦形成，必然会对经济造成危害（当然我们的这个模型还只是生产型模型，也就是说没有考虑消费因素，否则就要设计为种一棵，还要再吃一棵，更复杂了）。这种危害除了限制经济增长空间外，瓶颈资源的价格也会出现上涨，从而给人们带来通货膨胀的担忧。但我们也应该认识到，这种上涨的效应并不全是负面的。加之，如果我们考虑到数次石油危机的偶然性和人为性，则会发现，我们其实并不必对这种瓶颈要素价格上涨过于恐慌，甚至可以理解为，那是一种价值回归。瓶颈资源的价格上涨首先会提高它们的使用效率，以避免价值低估所带来的滥用。而更重要的一点是，只有它的价格涨到一定程度，才会改变人类的生产方式，促进技术进步。技术进步的结果是提高单位社会产出的该要素占用量，或是调整各要素间的配比，从而使稀缺要素在生产过程中被部分替代。总之，就是使稀缺要素，不再稀缺。相反如果因为出现要素瓶颈就减少货币供应量以试图维持所谓的（稀缺要素）价格稳定，不仅会造成其它非稀缺要素的闲置，还会引来投机资金对瓶颈资源的闲置性占用（囤积），这只会进一步加重它的稀缺性，最终也无法阻止它的价格上涨，如果货币供应紧缩得太严重，还会引发经济危机。而且遗憾的是，在人类的发展史上，劳动力要素是很少出现稀缺的，所以紧缩货币的结果，被闲置的往往会是这一资源。事实上，社会毕竟是人类的社会，而不是任何资源的社会，无论它有多稀缺！所以，经济学的研究目的永远也不应该是使这个社会沿着马尔萨斯的理论体系前行。</p><p>　　少数人编造“通货膨胀理论”甚至不惜制造数次石油危机去证明这一理论的目的，无非是使本不应该出现瓶颈的生产要素“货币”出现人为的稀缺，从而使货币获得超额利润。只有货币足够贵，才能够出现足够的劳动力闲置从而使劳动力要素的持有者失去议价的能力，任人宰割，也只有这样，某些人才能从中获取最大利益。</p><p>　　这个“某些人”也包括你吗？如果不包括，你为什么要随之鼓噪？</p><p>　　这里我们不得不说，弗里德曼为我们设定的货币，太贵了。我们不尽要问，凯恩斯的廉价货币理论，究竟动了谁的奶酪？</p>]]></content>
      
      
      <categories>
          
          <category> 经济 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 经济 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>“通货膨胀”不过是资产阶级经济学家们编造出来骗人的把戏</title>
      <link href="/2018/11/26/jingji-2/"/>
      <url>/2018/11/26/jingji-2/</url>
      
        <content type="html"><![CDATA[<p>文章来源：<a href="http://blog.sina.com.cn/s/blog_485b8a7e0100mgv4.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_485b8a7e0100mgv4.html</a><br>作者：有智思有财<br>思想有深度，一个非常值得敬重的老大哥</p><p>上个世纪初，美国经济高速发展，不得不高价从英国输入英镑和黄金，巨大的货币需求养活着大英帝国。当时所有的经济学教科书，都是英国人写的，英国人总是不会忘记时刻提醒崛起中的美国，要注意“通货膨胀”，也就是说，“货币这东西，我们印就好了，你们就不要再印了”。</p><p>美国人也真的很听话，不停地紧缩再紧缩银根。但，美国的货币需求很快就超过了英国的货币供应能力（超过货币供给能力如果继续投放货币所带来的不是“通货膨胀”，恰恰相反，那是“货币有效供给不足”）结果是，1929年大萧条。史无前例的全球经济危机使英国最终失去了全球经济的领导地位，一个叫凯恩斯的英国人，代表英国交出了它的“货币权杖”，并说出了货币的秘密。史称“凯恩斯革命”。</p><p>从那儿之后，拿到货币权杖的美国人开始写教科书了，你猜他们写的是什么？仍旧是，“货币这东西，我们印就好了，你们就不要再印了”。史称“凯恩斯革命的反革命”。</p><p>它们所玩儿的这套把戏其实很简单，就是把物价的上涨称作为“通货膨胀”，并欺骗世人，说是增加货币供应引起的。而事实上如今的CPI上涨，正是通货紧缩的结果！是由于货币供应不足降低了产出，使供需失衡引发的。通胀那个东西，不过是资产阶级经济学家编出来为其剥削行为做的遮羞布而矣！对于这一点，凯恩斯已经说漏了嘴，“所谓通胀，先决条件是，充分就业”。一语道破，资产阶级经济学家哪里是怕“通货膨胀”它们怕的其实只是“充分就业”而矣！</p><p>还有一种被称为“恶性通货膨胀”的东西就更可笑了，因为那是典型的货币有效供给不足，只要你增加有效的货币供应，所谓的“通货膨胀”立即消失。</p><p>弗里德曼整本儿《美国货币史》列举了无数的数据，都在证明“增加货币供给大多数时候是不会引发物价上涨的”；“货币供应是会带来产出增加的”。然而最终的结论竟然是“货币短期非中性，而长期仍旧是中性的”，甚至提出“货币增长只有超过产出增长时才会引发通货膨胀”这种完全无法自圆其说的理论。然而最终连这个都不再提了，而是简单地讲，要把货币供应量简单地控制在一个固定的水平上。这是什么？是削足适履。目的无非是人为地制造货币稀缺，以增加货币持有者在分配过程中的话语权。</p><p>增加货币供应－－＞充分就业－－＞人民收入增长－－＞产出更高的增长－－＞由于产出增长高于收入增长，物价下降</p><p>紧缩银根－－＞货币升值－－＞失业增加－－＞人民收入下降－－＞产出下降出口却增加－－＞外币涌入进一步推高物价</p><p>人民会欢迎哪个？这个还用说吗？弗里德曼连三流骗子的水平都达不到！</p><p>今天，我们已经站到了美国当年站过的位置，尽管现在美国的货币供应能力远远超过了当年的英国，但，依旧无法满足我们的需要。更重要的是，当今世界已不可能认可再一次的“大萧条”了。对全世界人民而言，货币，太贵了。我们期待着美国的“凯恩斯”站出来，交出他们的“权杖”，期待着廉价货币，期待着对“弗里德曼反革命的革命”。难道，我们要做的，仅仅是等待？</p>]]></content>
      
      
      <categories>
          
          <category> 经济 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 经济 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>由“煮酒论英雄”看三国智慧</title>
      <link href="/2018/11/22/sanguo-1/"/>
      <url>/2018/11/22/sanguo-1/</url>
      
        <content type="html"><![CDATA[<p>文章来源：<a href="http://blog.sina.com.cn/s/blog_485b8a7e01016may.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_485b8a7e01016may.html</a><br>作者：有智思有财<br>思想有深度，一个非常值得敬重的老大哥</p><h2 id="煮酒论英雄"><a href="#煮酒论英雄" class="headerlink" title="煮酒论英雄"></a>煮酒论英雄</h2><p>刘备是否英雄？是否被曹操当作主要竞争对手？熟知《三国演义》 “青梅煮酒论英雄”的朋友，想必会提出这样的问题。</p><p>按《三国演义》的说法，当时董承约会刘备等立盟除曹，刘备恐曹生疑，每天浇水种菜；曹闻知后，以青梅绽开，煮酒邀刘宴饮，议论天下英雄。当曹说“天下英雄，唯使君与操耳”，刘备闻之大惊失箸。时雷雨大作，刘备以胆小、怕雷掩饰而使曹操释疑，并请征剿袁术、借以脱身。</p><p>故事不长，但其间却有着无数的不合逻辑之处。</p><p>原文如下：<br><blockquote><p><i><strong><code>操曰：“使君知龙之变化否？”玄德曰：“未知其详。”操曰：“龙能大能小，能升能隐；大则兴云吐雾，小则隐介藏形；升则飞腾于宇宙之间，隐则潜伏于波涛之内。方今春深，龙乘时变化，犹人得志而纵横四海。龙之为物，可比世之英雄。玄德久历四方，必知当世英雄。请试指言之。”玄德曰：“备肉眼安识英雄？”操曰：“休得过谦。”玄德曰：“备叨恩庇，得仕于朝。天下英雄，实有未知。”操曰：“既不识其面，亦闻其名。”玄德曰：“淮南袁术，兵粮足备，可为英雄？”操笑曰：“冢中枯骨，吾早晚必擒之！”玄德曰：“河北袁绍，四世三公，门多故吏；今虎踞冀州之地，部下能事者极多，可为英雄？“操笑曰：“袁绍色厉胆薄，好谋无断；干大事而惜身，见小利而忘命：非英雄也。玄德曰：“有一人名称八俊，威镇九州：刘景升可为英雄？”操曰：“刘表虚名无实，非英雄也。”玄德曰：“有一人血气方刚，江东领袖——孙伯符乃英雄也？”操曰：“孙策藉父之名，非英雄也。”玄德曰：“益州刘季玉，可为英雄乎？”操曰：“刘璋虽系宗室，乃守户之犬耳，何足为英雄！”玄德曰：“如张绣、张鲁、韩遂等辈皆何如？”操鼓掌大笑曰：“此等碌碌小人，何足挂齿！”玄德曰：“舍此之外，备实不知。”操曰：“夫英雄者，胸怀大志，腹有良谋，有包藏宇宙之机，吞吐天地之志者也。”玄德曰：“谁能当之？”操以手指玄德，后自指，曰：“今天下英雄，惟使君与操耳！”玄德闻言，吃了一惊，手中所执匙箸，不觉落于地下。时正值天雨将至，雷声大作。玄德乃从容俯首拾箸曰：“一震之威，乃至于此。”操笑曰：“丈夫亦畏雷乎？”玄德曰：“圣人迅雷风烈必变，安得不畏？”将闻言失箸缘故，轻轻掩饰过了。操遂不疑玄德。</code></strong></i></p></blockquote></p><p><strong>“玄德曰：‘圣人迅雷风烈必变，安得不畏？’将闻言失箸缘故，轻轻掩饰过了。操遂不疑玄德。”</strong>看过后，我不禁想问，这个故事说的是“奸雄”曹操吗？我们的曹丞相，什么时候，变得如此好骗？况且以常人而论，刘备当时的实力，不要说与刘备前面提到的袁术、袁绍兄弟，就是跟刘表、孙策、刘璋甚至张绣、张鲁、韩遂等辈尚相差甚远，曹丞相把那些人，全不放在眼里，却唯独如此看重这个刘备？即使是真的如此看重他，以曹丞相的为人，如何可能轻易说出？而既然如此看重他，又说了出来，按照常人之理，要么让他成为自己手下的大将，要么杀了他，怎么可能会轻易放“刘英雄”离去呢？而在他离去后，至少可以以“汉献帝实际控制人”的身份，让献帝下一纸诏书，废了这个“皇叔”，又如何会让刘备带着皇叔的称号，四处“招摇撞骗”呢？这不明显是为自己树立一个争夺天下的竞争对手吗？莫非真的只能按照主流的说法，是“碰巧”曹丞相平生少有的一次酒后吐真言？又“碰巧”曹丞相平生少有的一次一时糊涂，于是，放走了这位“刘英雄”？但看一下曹丞相幼时便会假装中风，挑拨他叔叔与他父亲之间的关系，后来更是借酒杀人，借梦杀人，这些都是他的拿手好戏，指望他酒后吐真言? 还是甭想了。显然，是另有原因。</p><h2 id="许田围猎与“衣带诏”"><a href="#许田围猎与“衣带诏”" class="headerlink" title="许田围猎与“衣带诏”"></a>许田围猎与“衣带诏”</h2><p>至于当初董国舅为了除曹，为什么会主动联系这位刘皇叔？按照《三国演义》的说法，是因为马腾看到了“许田围猎”时关羽和刘备的异常反应。但这又有了不合逻辑之处，刘备、关羽兄弟在射猎时的异常表现，连马腾那样的粗人都看在眼里，记在心上，之后董承又主动与刘备联络、结盟，其间来往难免不密，耳目众多的曹操，却偏偏毫无察觉？还兴高采烈地与刘皇叔在“煮酒论英雄”，然后继续被骗，进而竟然放这位“刘英雄”借了兵马去截击袁术？此时的袁公路因为公然自立为帝，逆天行事， 已经被“主持正义”的曹丞相打得如丧家之犬了，真真的是曹操所说的“冢中枯骨”了，随便派个人，就搞定了， 哪里用得着“刘英雄”出马？更何况，这样的举手之劳，便功在汉室的业绩，曹公就这样让与了刘备？就是为了成全刘备的“英雄之名”，让他今后有资本与曹丞相竞争？曹操什么时候变得这么厚道了？看起来，要给曹丞相改脸谱了。</p><p>还有更不合逻辑之处在于，在这件事情上，一直显得很好骗的曹丞相，“碰巧”刘皇叔一离开，董国舅集团，便全部落网了？结合无数次反曹阴谋的“碰巧”破产，我们不得不问，是那些反曹英雄们太不注重保密？还是，上天过于护佑这个“汉贼曹操”呢？还或者是有其它原因？比如说，多疑的曹操收买了大量耳目，为其监视对手们的动向？</p><p>先看一下《三国演义》中的说法吧。董承约会刘备等立盟除曹的起因即是所谓的“衣带诏”，这个“衣带诏”事起曹操“许田围猎”。而按照《三国演义》的说法，这个“许田围猎”从一开始就是曹操布的一个局，就是要看一下各方的“动静”，刘备、关羽的举动，如何可能逃过曹操的耳目呢？</p><blockquote><p><strong><i><code>谋士程昱说曹曰：“今明公威名日盛，何不乘此时行王霸之事？”操曰：“朝廷股肱尚多，未可轻动。吾当请天子田猎，以观动静。”</code></i></strong></p><footer><strong>《三国演义》</strong><cite>第二十回 曹阿瞒许田打围 董国舅内阁受诏</cite></footer></blockquote><p>果然，不仅刘备兄弟，董承等“朝廷股肱”也有了“动静”。从这份“衣带诏”送出的经过可以清楚地看出来 ，其实董承等人的一举一动，都一直在曹操的监视之中，以至于没出宫门，曹操就到了。但是曹操还是让他们把这份诏书送出来了，为什么？这不是很明显的事吗？</p><p>显然，整件事情，除了有关“刘英雄”的部分，曹操出现了选择性的视觉障碍，其它部分，完全在曹丞相的掌控之中。如果这是一部现代电视剧，大家自然会认可这些“碰巧”，不去追究这些不合逻辑之处，“英雄不死”吗! 因为导演就是这样安排的吗! 但这一切出自罗贯中之手，四大名著之一，而且是基于大量史料写成的，许多事件在史料中也有明确记载，这许多年来，便从没有人好奇过，问题出自何处吗？</p><h2 id="真相"><a href="#真相" class="headerlink" title="真相"></a>真相</h2><p>如果我们把《三国志•先主传》中的记载拿来对比了一下，或许会受到一些启发。</p><p>作为罗贯中写《三国演义》最主要历史资料的《三国志》 ，“论英雄”相关内容的记载极为简单，但却，极为惊人：当刘备败于吕布后，投奔曹操，曹操不仅“帮刘备”打败、生擒吕布，救出刘备的妻儿，并且…</p><p>表先主(刘备)为左将军，礼之愈重，出则同舆，坐则同席。袁术欲经徐州北就袁绍，曹公遗先主督朱灵、路招要击术。未至，术病死。</p><p>先主未出时，献帝舅车骑将军董承受帝衣带中秘诏，当诛曹公。先主未发。是时曹公从容谓先主曰：<strong>“今天下英雄，唯使君与操耳。本初之徒，不足数也。”<strong>先主方食，失匕箸。遂与承及长水校尉钟辑、将军吴子兰、王子服等同谋。会见使，未发。事觉，承等皆伏诛。</strong></strong></p><p>也就是说，不仅刘备去打袁术，不是刘备自己要求的，而是曹操派的，而且董承最初找刘备时，刘备并没有答应。但“碰巧”在此时，曹操找刘备，“从容”说出了“今天下英雄，唯使君与操耳。本初之徒，不足数也。”的话，刘备才“遂与承及长水校尉钟辑、将军吴子兰、王子服等同谋”。 《三国志》的这个“从容”二字用得很好，明显是在暗示，一切尽在曹操掌握之中。</p><p>按照易中天的解读，这两个又是“碰巧”，之所以罗贯中在《三国演义》中做了改动，是因为觉得太巧了，巧得“不合逻辑”，于是便调整了一下，把与董承密谋安排在了煮酒之前，而出去打袁术，则变成了刘备请命。至于曹操为什么会从容说出这样一段话，易中天说了几种可能：比如说曹操当时尚不够“奸雄”。我想这一点看一下吕伯奢一家的下场和曹操幼时是如何坑他叔叔的，便不会有人相信这一说法。再比如说，认为是一种“火力侦察”。但这就又不合逻辑了，如果是试探，更证明曹操已经起疑，那又怎么会这么快就放刘备离去？还借兵给他呢？而如果是刘备主动要求离开的，那不就正中曹操之计吗？刚说你是英雄，你就想跑？曹操就更不可能放他走了，相信刘备也绝不会这么幼稚，直接暴露自己的企图。还有一个说法，是曹操虽然认为刘备是英雄，但无用武之地，所以不会构成威胁。这就有点意思了，怕他没有用武之地？所以借兵借将给他，放他出去？</p><p>回过头来，我们再看，仅仅是因为觉得太“碰巧”了，值得罗贯中绕那么大的圈子？况且，即使减去这两个“碰巧”，其它的“碰巧”之处，又还少吗？好象只会更不合逻辑。显然这不是问题的关键所在。最重要的是，如果加上这两个“碰巧”，基本上可以认定，这一切，根本就不存在什么“碰巧”。这些看似不合逻辑的事件的总导演，既不是陈寿也不是罗贯中，他的名字，叫“曹操”。于是，一切便符合逻辑了!</p><p>先是用许田围猎使汉献帝的死忠们结盟；刘备不想加入，于是封给刘备一个“英雄称号”，吓刘备一下。傻子也能听出这句话的意思“你装什么装？你以为不跟董承结盟，假装在那里种菜，我就不拿你当竞争对手了？”吓得刘备不得不立刻加入曹操反对者的阵营而与董承之流结盟；然后曹操再主动借兵马给刘备，派刘备出去打一个根本不需要打的敌人(事实上袁术也确实已经很不经打了，《演义》中说是打了一下，《三国志》干脆说，还没来得及打，穷途末路的袁公路竟然为了想喝一口蜂蜜喝不到，便气得吐血而亡了)；刘备前脚儿一走，曹操就把董承等人灭了。不用什么“英雄”，任何人，在这种情况下，也不可能再回来接着种菜了!</p><p>于是，自此刘备就背着这样一个“英雄称号”、一个“皇叔称号”和汉献帝的所谓“衣带诏”开始了它的“英雄历程”。用现在的话讲，刘备的这个“英雄”，是曹丞相“赏识教育”的结果。也就是说，刘皇叔是在曹丞相的不断赏识教育与逼迫之下，走上的这条“英雄之路”的。</p><p>这太影响刘皇叔的英雄形象了，看起来，倒有点儿象曹公手中的一颗棋子儿了。要是这样写，《三国演义》的整个思路，都不得不调整了。所以，罗贯中，必需对这部分内容，进行改动。</p><h2 id="“英雄”是怎样炼成的？"><a href="#“英雄”是怎样炼成的？" class="headerlink" title="“英雄”是怎样炼成的？"></a>“英雄”是怎样炼成的？</h2><p>但是，尽管罗贯中调整了这部分内容，在《三国演义》中，曹操为打造刘备这样一个“英雄”，所做出的不懈努力，仍旧是清晰可见。</p><p>那么刘备，究竟是不是英雄呢？</p><p>玄德以一织席贩履之辈，成就一代帝业，卧龙凤雏，争相依附，关羽、张飞、赵云更是以兄弟相称，怎么能说不算是英雄呢？</p><p>然而在其28岁尚一事无成，在招军榜前“慨然长叹”之时，以及之后讨黄巾军，几经曲折，直至后面托同学公孙瓒保举，也不过是个默默无闻的平原县令。袁术就曾经说过“术生年以来，不知有刘备”；孔融曾经向刘备求救兵，引得玄德公“敛容答曰：‘孔北海知世间有刘备耶？’”。长期的不得志，打击着刘备的自信，只怕连他自己都会怀疑，是否仅是一个志大才疏之辈了。毕竟，刘备和当时的众豪杰相比，起点太低了。</p><p>中国人喜欢讲，“是金子就一定会发光的”。然而，从物理学的角度，金子本身，并不发光，它的所谓“ 发光”，不过是因为有光，照到了它。物理学上，称之为，“反射”。那缕照到“刘英雄”身上的光，究竟来自何处呢？</p><p>按照《三国演义》的说法，刘备与关张结义起兵于镇压黄巾起义，虽有战功，却无所获。之所以后面能够让“孔北海知世间有刘备”，只怕还是要归因于各路诸侯讨董卓时的“重在参与”。刘备三兄弟在众诸侯面前第一次出场时，并不叫座儿：</p><blockquote><p><strong><i><code>绍举目遍视，见公孙瓒背后立着三人，容貌异常，都在那里冷笑。绍问曰：“公孙太守背后何人？”瓒呼玄德出曰：“此吾自幼同舍兄弟，平原令刘备是也。”曹操曰：“莫非破黄巾刘玄德呼？”瓒曰：“然”。即令刘玄德拜见。瓒将玄德功劳，并其出身，细说一遍。绍曰：“既是汉室宗派，取座来。”命坐。备逊谢。绍曰：“吾非敬汝名爵，吾敬汝是帝室之胄耳。”玄德乃坐于末位，关、张叉手侍立于后。</code></i></strong></p><footer><strong>《三国演义》</strong><cite>第五回 发矫诏诸镇应曹公 破关兵三英战吕布</cite></footer></blockquote><p>从这里可以看出，直到这里，刘、关、张也只能算是列席了一下诸侯的聚会，接下来如果不是曹操的力挺，便不会有关羽的温酒斩华雄以及后面的三英战吕布。而那位袁公路在关羽斩了华雄之后的表现，只能用“可笑”二字形容：</p><blockquote><p><strong><i><code>曹操曰：“得功者赏，何计贵贱呼？”袁术曰：“既然公等只重一县令，我当告退。” 。</code></i></strong></p><footer><strong>《三国演义》</strong><cite>第五回 发矫诏诸镇应曹公 破关兵三英战吕布</cite></footer></blockquote><p>由此便清楚地看出曹操、袁绍 、袁术看待天下英雄的态度了。直到三英战吕布，实际上刘备已经很露出了些“英雄的范儿”，但诸侯们，并不买账，反倒是一个“帝室之胄”的虚名，可以在袁绍那里轻松混得一席之地。这也就决定了袁绍的宿命，本初，就是本初，既不是董卓，更非孟德。而曹操正是抓住了袁绍的这一弱点，最终打败了他，这是后话。</p><p>以上是曹操与刘备的初遇，由此形成刘备的重大转机。而真正的大机会，来自陶谦的三让徐州。为什么陶谦会三让徐州？还不是因为刘备仅一封信，便为陶谦退去了敌兵。什么时候，刘备变得这么有面子了？是谁仅凭一封信，便送了刘玄德如此大的人情？又正是那个曹操。当然，按照《演义》的说法，这个人情，仍旧来自于“碰巧”，“碰巧”吕布攻打曹操的后方兖州，才使得曹操不得不给了刘备这个充当英雄的机会。无数的“碰巧”，反复的发生在这两个人身上，你信吗？反正我信了。</p><p>刘备平白得了徐州，却守不住，最终便宜了吕布，还丢了自己的家小，又是谁“帮刘备”打败吕布，夺回家少？前面已经提到过，却又，正是这个曹操。此时的曹操已经非同小可，他已经是挟天子以令诸侯的大汉丞相了，而他对待刘备却仍旧那样的“够意思”，不仅推荐刘备为左将军，礼之愈重，而且出则同舆，坐则同席。这里值得一提的是，《三国志》明确讲是曹操“表先主为左将军”而在《演义》中，则变成了汉献帝“遂拜玄德为左将军、宜城亭侯”，还叙了“叔侄之礼”。这一点其实很不正常，即便是刘备姓刘，即便是他看似与帝室沾亲，可这个与曹操“出则同舆，坐则同席”的宗室，如果不是曹操的意思，汉献帝主动把他推到“皇叔”的位置上，对自己又能有什么好处呢？更何况，曹操这个“实际控制人”不点头儿，汉献帝一个连自己的皇后都保不住的皇帝，又有什么能力封出一个“皇叔”来呢？</p><p>而曹操当时对刘备的器重，几乎表现在了各个方面，就连如何处理那个“人中之吕布”，也甚尊重刘备的意见，为了给玄德公出一口恶气，竟然杀掉了这个天下无敌的大将! 其实细想起来，不过就是给刘备一个面子，从曹操此后的表现来看，哪个咬过旧主一次的，在曹操这里逃得活命了，更何况是个连杀两个干爹的三姓家奴？</p><p>我们重点要分析的是，如果我们从另一个角度来看，刘备在对吕布和张辽两个人的处理意见上，充分表现了与曹操的“英雄所见略同”，如果是有异心，而不是真心投靠，会如此替曹操着想吗？</p><p>《后汉书•吕布传》对这部分内容的记载是这样的：</p><blockquote><p><strong><i><code>布见操曰：“今日已往，天下定矣。”操曰：“何以言之？”布曰：“明公之所患不过于布，今已服矣。令布将骑，明公将步，天下不足定也。”顾谓刘备曰：“玄德，卿为坐上客，我为降虏，绳缚我急，独不可一言邪？”操笑曰：“缚虎不得不急。”乃令缓布缚。刘备曰：“不可。明公不见吕布事丁建阳、董太师乎？”操颔之。</code></i></strong></p><footer><strong>《后汉书•吕布传》</strong></footer></blockquote><p>《三国演义》中这部分情节的描写，显然不是来自《三国志》 ，而基本上忠于《后汉书》的记载，唯一的调整，便是把刘备主动阻止给吕布“缓缚”，并主动对曹操进言，改为了“操回顾玄德曰：‘何如？’玄德答曰：‘公不见丁建阳、董卓之事乎？’”(《三国演义》)</p><p>这两者差别很大，因为如果是曹操问及，还可以讲是刘备怕曹操起疑，不敢不实言相告，但如果是主动提醒曹操，以刘备的城府，如果不是极度忠心，或是感激曹操，一心只想成为曹丞相手下一员大将的话，会主动去抖机灵儿，提醒曹操这个吗？</p><p>更何况，曹操谋臣无数，有这个见识的，也怕不过几人而矣，即使是曹操问及，你刘备如果无意屈居人下，有辕门射戟的往事在那里，你就算是给吕布讲情了，曹操又会疑你多少？难怪罗贯中最终仍觉得无法自圆其说，于是在《三国演义》也不得不提出这样的疑问：</p><blockquote><p><strong><i><code>“伤人饿虎缚体宽，董卓丁原血未干。玄德既知能啖父，争如留取害曹瞒？”</code></i></strong></p><footer><strong>《三国演义》</strong></footer></blockquote><p>这算是给后人找出真相的一点线索吧？世人皆认为吕布之死证明了刘备“枭雄”的一面，而我认为，这恰恰证明了刘备“厚道”的一面。刘备当时为什么会如此厚道呢？显然当时的刘备并没有动与曹公争雄之心，只要是曹操不赶他走，他刘备只怕就会象荀彧(后面会详细说这个荀彧)那样，终生把曹操当作大汉丞相来辅佐了。</p><p>这也就从侧面证明了《三国志》的说法，刘备的争雄之心，是后来“青梅煮酒”时，被曹操吓出来的!刘备最终没有成为曹操手下大将，并非是刘备不愿，而是曹操不肯。显然，如果不是后来曹操不停的折腾他，或许刘、关、张，真的能够成为曹操手下的大将呢。而曹操居然不仅置如此之大的利益于不顾，不仅费尽心机把刘备培养成为一个“英雄”、“手握皇帝诏书的皇叔”，之后竟然是把他挤兑成自己最主要的竞争对手？常人皆知多一员大将好过少一员大将；少一个竞争对手，好过多一个竞争对手，难道这个曹操竟然间，是个傻瓜？或者是疯了不成？</p><p>也或许曹丞相，并非是那种“常人”吧？</p><h2 id="刘备与曹操的竞争"><a href="#刘备与曹操的竞争" class="headerlink" title="刘备与曹操的竞争"></a>刘备与曹操的竞争</h2><p>的确，从刘皇叔后来的表现来看，他似乎成为了曹丞相的一大竞争对手，很有点阻碍曹丞相统一天下的嫌疑。但如果仔细分析，没有刘皇叔的竞争，曹操就能统一天下吗？只怕未必。这一点，我们可以从后来诸葛亮的《隆中对》中得到佐证：</p><blockquote><p><strong><i><code>“自董卓以来，豪杰并起，跨州联郡者不可胜数。曹操比于袁绍，则名微而众寡，然操遂能克绍，以弱为强者，非惟天时，抑亦人谋也。今操已拥百万之众，挟天子而令诸侯，此诚不可与争锋。孙权据有江东，已历三世，国险而民附，贤能为之用，此可以为援而不可图也。</code></i></strong></p><footer><strong>《隆中对》</strong></footer></blockquote><p>我们一句句的看：</p><p>“自董卓以来，豪杰并起跨州联郡者不可胜数”，什么意思？市场太大了，市场参与者太多了，一时间，谁都无法拿到垄断份额，更不要说一统天下了!</p><p>“曹操比于袁绍，则名微而众寡，然操遂能克绍，以弱为强者，非惟天时，抑亦人谋也。”当初实力最强的袁氏兄弟，终究输在人心所向上。</p><p>“今操已拥百万之众，挟天子而令诸侯，此诚不可与争锋。”“不可与争锋”的原因不仅在于“拥百万之众”，更在于“挟天子而令诸侯”，这才是此时的曹操与当初的袁绍间，最本质的区别，也就是前面所说的人心所向的根源。否则人家“四世三公”，你曹操出身低下，群众如何会支持你？还不是因为你手里有汉献帝这张“牌”？除了这张“牌”外，你当初的地盘儿可比人家小多了! 也就是说，曹操取得今天的成绩，得益于其所挟之天子，且，不仅到了三顾茅庐的时候，甚至应该说，曹操致死，没有能力丢掉这张“王牌”。</p><p>就拿那个荀彧来说，堪称曹操的“顶梁柱”了。荀彧自小被世人称作“王佐之才”（《三国志·魏书·荀彧传》）。作为曹操统一北方的首席谋臣和功臣，荀彧在战略上为曹操制定并规划了统一北方的蓝图和军事路线，曾多次修正曹操的战略方针而得到曹操的赞赏；战术方面曾面对吕布叛乱而保全兖州三城，奇谋扼袁绍于官渡，献出宛、叶而间行轻进以掩其不意奇袭荆州等诸多建树；政治方面为曹操举荐了钟繇，荀攸，陈群，杜袭，司马懿，郭嘉等大量人才。荀彧在建计，密谋，匡弼，举人多有建树，被曹操称为“吾之子房”（《三国志·魏书·荀彧传》）。说荀彧是曹操的张良，其实一点都不为过。司马懿就曾经说过：<strong>“书传远事，吾自耳目所从闻见，逮百数十年间，贤才未有及荀令君者也。”(《彧别传》)</strong></p><p>而荀彧这样的举足轻重的人物，他所忠于的究竟是你曹操，还是“大汉”呢？</p><p>曹操晚年欲进爵国公、加封九锡（九锡是古代帝王对大臣的九种赏赐，有车马、衣服、乐器、武士、弓矢等，这是对大臣的最高礼遇，而后来却逐渐演变为废帝自立的前奏）。荀彧马上表示：<strong>“（曹操）本兴义兵以匡朝宁国，秉忠贞之诚，守退让之实；君子爱人以德，不宜如此”。（《三国志·魏书·荀彧传》）</strong></p><p>曹操已经苦心经营了那么多年，所谓加九锡，本就是试探，不想却是这样的结果。连他的最得力，也最亲信的荀彧都马上告诉他，你的本分是“匡朝宁国”，而不是改朝换代。可想而知，早在“煮酒”之时，曹操何来的垄断市场的实力？如果当时袁氏兄弟另立新君，也打起“匡朝宁国”的旗号，而不是鬼迷心窍一心想自立的话，用四世三公所立之君PK逆贼董卓所立、出身低下的曹操为实际控制人的汉献帝，曹丞相手中的这张“王牌”立刻就会贬值，到时只怕胜负之数，就说不定了。更何况，不仅袁氏兄弟，象孙策、张绣、张鲁、韩遂这样的地方势力，还有刘表、刘璋这样的汉室宗亲，如果一人立一个新君，都在那里“匡朝宁国”，只怕“国”就永无宁日了，后汉也就不是三国，而是春秋战国了。你曹操的竞争力，还能剩下几何呢？</p><p>而诸葛亮正是清楚地看到了这一点，曹丞相尽管很强势，但暂时还没有能力，拿到绝对垄断的市场份额，这，就是机会。那么以奸雄著称的曹丞相，又何尝会看不到这一点呢？所以，既然确定无法获得全部的市场份额，甚至无法拿到大部分份额，那么把自己暂时拿不到的市场份额，究竟分散到什么人手中，对自己最有利，就是一个很值得考虑的问题了。</p><p>董卓、袁术之流的愚蠢，便在于他们认为“黄巾”一过，天下大乱，汉室势微，他们便可以胡作非为了，最终必然落得个可耻、可悲的下场。曹操与董卓、袁术那样的蠢货所不同的，便是时机不成熟，绝不蛮干；而他与袁绍所不同的是，不蛮干，不等于什么都不干。既然没能力立个皇帝，就抢个皇帝过来；而尽管皇帝人人可立，立个献帝皇叔出来，却是曹丞相的专利，别人想学也学不来的，于是，刘皇叔，出场了。</p><p>曹操不遗余力地扶植了一个竞争对手，但看一下刘备拿下的那些地盘儿，哪块儿是曹操的？相反，这些曹丞相鞭长莫及的市场份额如果不是被刘备所得，而是被四世三公的袁氏兄弟拿了，那还有出身低下的曹丞相什么事儿呢？留给被诸葛亮称之为“据有江东，已历三世，国险而民附，贤能为之用，此可以为援而不可图也。”的孙权吗？那样一旦南北对峙局面形成，双方势均力敌，曹丞相就真的只能寄希望于“养子当如孙仲谋”了。于是，如果此时有人跳出来，从自己的竞争对手手中，抢去部分市场份额，曹丞相，当然是很乐于支持他一下的。因而，可以看出，在暂时谁都没有能力统一天下的情况下，“三分天下”不仅是刘备，同时也是曹操比较理想的一个局面。</p><h2 id="回到煮酒论英雄"><a href="#回到煮酒论英雄" class="headerlink" title="回到煮酒论英雄"></a>回到煮酒论英雄</h2><p>退回煮酒论英雄的那个时点上，<strong>“名微而众寡”</strong>的曹丞相与他自称并不看好的四世三公的袁氏兄弟，甚至是刘表、刘璋相比，可以讲出身、社会地位、人脉资源都相去甚远，唯一的优势就只是手里有一个汉献帝。但你要注意，这个汉献帝的合法地位能否被大众接受是存在问题的，首先他是逆贼董卓废了汉少帝所立，最要命的是，当时曹操最主要的竞争对手袁绍，一直以来，就是在承认汉献帝与不承认汉献帝之间徘徊。一旦要是与曹操闹翻了，随时可能立出一个新君来。而当时，黄巾四起，天下大乱，群雄分立，少帝被废后不久，被董卓所杀，此时最有实力再行废立之事的，却恰恰是这位四世三公的袁本初! 而且袁绍另立新君，并不是完全没有考虑过。</p><p>当初董卓立献帝时，唯一征求意见的，便是这个袁绍，证明当时只有四世三公的袁氏才有这个废立的实力(有废立的实力，不等于说也有自立的实力，这就是袁氏兄弟的愚蠢之处)。</p><blockquote><p><strong><i><code>“董卓呼绍，议欲废帝，立陈留王。”</code></i></strong></p><footer><strong>《三国志》</strong></footer></blockquote><p>袁绍也真就没给面子，于是闹翻了，单骑出奔，很快就凭他四世三公的号召力，聚起人马，获得了大块儿地盘儿。</p><p>到了各路诸侯讨董卓的时候，袁绍更是成了当然的盟主，期间便曾动过另立幽州牧刘虞为帝的念头，由于袁术、曹操等人的坚决反对(当然要反对了)，才暂时作罢。</p><p>后来董卓派人给袁绍送去过汉献帝的诏书，袁绍竟然干脆让人把使者杀了。</p><p>所以再后来，汉献帝从董卓那儿逃出来，虽然最有迎驾条件的，正是袁绍，但袁绍很犹豫。袁绍犹豫的很重要的一个原因就是，此前，这么没有给这位皇帝面子，现在想不好，要不要承认这个由逆贼董卓立的皇帝。他的犹豫，正是因为他有另立的实力。然而正如曹操所说，此人<strong>“色厉胆薄，好谋无断；干大事而惜身，见小利而忘命”</strong>。自立是死路一条。所以，要么另立，要么迎立，这样的“大事”，哪里容得你反复犹豫？想吃，又怕烫？</p><p>结果让曹操占了这个先。曹操之所以毫不犹豫，而是主动抢汉献帝过来，也正是因为他很清楚，自己没有废立之能，如果你曹操立，袁绍便不会再犹豫。</p><p>曹操以汉献帝的名义加封袁绍为邺侯，袁绍还是没有接受。可以这样讲，暂时没有再提另立新君，只是看在与你曹操过去的情份上，至于将来撕破脸，之后，会怎样？曹操心里会不清楚吗？而一旦袁绍另立新君，以其四世三公的号召力，逆贼董卓所立，曹操为实际控制人的汉献帝的公信力，立刻就会受到挑战。一旦曹操手中的这张“王牌”大为贬值，曹操与袁绍间的实力差距，就会一下子被拉大。更有甚者，万一搞得天下诸侯，一人手里有一个皇帝，还能留给你“名微而众寡”的曹孟德，多少市场份额呢？</p><p>而刘皇叔无论将来怎么“英雄”，他至少会知道，他的这个“皇叔”本源在哪里，汉献帝存在一天，他就得全力维护，所以天下绝不会动另立念头的，只有这位刘皇叔。而维护了汉献帝，必然也就被动地起到了维护汉献帝“实际控制人”曹丞相的作用。甚至曹丞相有失，刘皇叔地位便可能不保。因此曹操、刘备心里都清楚，没有了汉献帝这块金字招牌，天下单靠自己打？自己便优势全无了。从这个角度讲，刘备与曹操仍旧是“自己人”，是一荣俱荣，一损俱损的关系。这一点，从华容道上刘备的处理来看，他也是心知肚明的。(当然主流仍旧可以讲，是“碰巧”，“碰巧”刘备派去截杀曹贼的，正是那个义薄云天的关羽，于是，曹操侥幸得脱。应该说刘备的“英雄”主要体现在识人上，平生极少看错人，而对那个接触不多的马谡的几句简短评价，足以看出此人识人的眼是多么的“毒”，如何会偏偏看错自己结拜的二弟呢？其实道理很简单，曹丞相完了，刘备的这个皇叔，还值几个钱呢？)</p><p>回过头来，再看，曹操的青梅煮酒之言， 尽管他可能的确很赏识刘备，尽管他可能觉得刘备是个“英雄”，但他真正害怕的，却正是那位“非英雄”的袁本初! 如果让曹操选择竞争对手，他宁可选刘备，也决不愿意选择处处都可以压曹操一头的袁绍! 这就是真相。这可能也得算是曹操“在战略上藐视敌人，在战术上重视敌人”吧？所以他才会不遗余力地炒作“刘英雄”，当发现“刘英雄”很有点在许都养老的架势时，没别的，先是借喝酒吓你一下，然后派你带兵出去，之后把你的后路断了。而刘备此时还做着在徐州当他的皇叔的白日梦，结果曹操放下手里的所有工作，一个照面儿，就把刘备赶到袁绍那儿去了。</p><h2 id="刘备对袁绍等诸侯的打击"><a href="#刘备对袁绍等诸侯的打击" class="headerlink" title="刘备对袁绍等诸侯的打击"></a>刘备对袁绍等诸侯的打击</h2><p>为什么非要急着把刘皇叔赶到袁绍那去？因为这个时候，曹操急需这样一个人加入到游戏中来了。这个人与自己相比，存在明显劣势，甚至比自己的劣势(出身不好)还要劣很多，最好是个卖草鞋的出身；但他最好与袁本初等高高在上的世家子弟相比，又有极大的优势，比如说是帝室之胄(袁绍吃这套)，最好是个皇叔。而曹操之所以很卖力气地炒作刘皇叔的“英雄范儿”，原因就更简单了。皇叔是汉献帝的“衍生品”，没有汉献帝，哪里来的“皇叔”之说？而那个年头，皇帝谁都可以立，属无序竞争，但是汉献帝的衍生品，曹丞相是有垄断能力的。特别是那个所谓的“衣带诏”，后来被炒作得什么似的，怎么就没人想一想，那个时候，献帝诏书的发行权都在曹操手中，曹丞相只要打开印刷机，想印多少，印什么内容，有人想要，可以按批发价给你!</p><p>所以说，炒作刘皇叔，炒作衣带诏，就是炒作汉献帝。袁绍只要是沿着敌人和敌人便是朋友这样常人的思路去考虑问题，就一定会中计。</p><p>按照《三国志》的说法，建安五年（公元200年）正月，董承等谋泄，皆伏诛。曹操决定亲自东征刘备，虽然曹军中将领都认为袁绍才是大敌，但曹操却觉得刘备是人杰，必要先行讨伐，刘备战败，北投袁绍。</p><p>其实诸将哪里知道，正是因为袁绍才是大敌，所以必需要先讨伐刘备。只有刘备投靠了袁绍，曹操才可能打败袁绍。</p><p>据易中天讲，刘备当时想都没想过曹操在这个时候，怎么会有工夫跑过来打他，这也太看得起他刘玄德了？手下人来报说是曹操来了，刘备说，“不可能，这时候，只有袁绍才会被曹操放在眼里，他哪里会看得上我？”，可是远远儿地看到曹操的旌旗，别说打，连家都没顾上回，家小都不要了，这位“人杰”就直接从后门儿跑了。</p><p>在这个环节上，可以说袁绍没有借机攻打曹操，是无能的表现，但站在袁绍的立场上，以常人的观点，他也的确是想不明白，这个跟自己从小儿玩到大的曹阿瞒，如何竟然会在这样的一个关键时刻，将自己置之不理，而去打那个“刘皇叔”？莫非这个“刘皇叔”真的如此了得？还是曹阿瞒设的什么圈套骗我去进攻？</p><p>结果刘备战败，投奔袁绍。袁绍果然中计，出城200里相迎，这和讨董卓时的态度对比，已经是一天一地了，除了因为刘备此时头上多了一块“大汉皇叔”的金字招牌外，他已经被曹操将其炒作为“刘英雄”了。而放着另立新君的实力犹豫不决，一会儿想着捡袁术送来的便宜皇帝，这会儿却又去捡这个送上门来的“皇叔”、“衣带诏”，这就是曹操所说的，<strong>“干大事而惜身，见小利而忘命”</strong>。因为你只要是承认了刘皇叔，承认了玉带诏，便等于是承认了汉献帝。于是刘皇叔被炒得越高，汉献帝就越值钱；汉献帝越值钱，作为汉献帝“实际控制人”的曹丞相的地位也就越高，你袁绍就越不值钱。 而卖草鞋出身的皇叔是对出身不好的丞相最好的“分谤”，敌对阵营中再有人说起“出身”问题，便要投鼠忌器，于是，“英雄不问出身”，便很容易，达成共识。谁会吃亏呢？当然仍旧是四世三公的袁本初。相反，如果把刘备留在曹操身边，只会引来“蛇鼠一窝”考评。既然留在身边看起来很可能会是“蛇”，放出去，却很象是件“器”，可以为曹丞相这只“过街老鼠”抵挡无数枪林弹雨，那当然应该放他出去。</p><p>更何况，这样做的直接后果，便是使刘备分化了袁绍的支持者，并使得袁绍出师无名了。陈琳的《为袁绍檄豫州文》或许有些文学价值，但写来写去，无非是说曹操出身低下，且品行不端，但无论曹操出身多么低下，品行如何不端，只要坐实了汉献帝的合法地位，曹操的“大汉丞相”就是合法的，你袁绍所攻击的，就是王师、就是大汉的王权，就是你袁绍以下犯上。大汉朝毕竟百足之虫，坐实这一点，袁绍便已经输了!</p><p>如果用现代营销眼光去看这个问题，当时的市场可以分为汉献帝的支持者与反对者(以袁绍为代表的各路诸侯势力)；而汉献帝的支持者中，又可以分为支持曹丞相的与反对曹丞相的；以袁绍为代表的汉献帝的反对者都是曹丞相的竞争对手，其实力远非许都的势力范围可比。许都的护城河不可谓不深，但支持汉献帝的曹派，只要是离了许都 ，天下之大，便再无立锥之地。以曹丞相当时的“奸名”远播，无论他是对，是错，天下人，都会争相群起而攻之。显然曹丞相离垄断市场，相去甚远。相反， 支持汉献帝的非曹派则有所不同。以刘皇叔为例，如果放在曹丞相身边，则很有可能成为曹丞相的反对者，而应当被消灭；相反，如果把他放出许都，然后大张旗鼓地吹捧他，那些看广告选择立场的人，就会转入刘皇叔的支持阵营，这必然会有力地起到分化汉献帝反对者的作用，拓展汉献帝支持者的市场份额，从而削弱各路诸侯的势力。而天下之人，一旦从抵触与抗拒汉献帝的立场上转变过来，则仍旧会分化为曹丞相的反对者与支持者。即使这部分市场，最终大部分演变为了刘皇叔的支持者，只有少部分变了曹丞相的支持者，曹丞相与刘皇叔一样，也都是赢家。市场格局也会由“宦官之后”与“四世三公”的PK，演变为“汉献帝实际控制人”与“汉献帝皇叔”之间的PK。 显然，尽管刘备看似是凭空获得了戏码，捡了一个大便宜，但曹操也由劣势，转为了优势。至于袁绍，却已经出局了。而其它诸侯，再没有人敢于再起另立新君之议。对曹操而言，这个利益，又哪里是收刘备一员大将，或收回“皇叔”称号比得了的呢？</p><p>于是，原本属于各路诸侯的市场份额，最终被曹操、刘备所瓜分。曹丞相，何乐而不为呢？如果看到别人占了便宜，便认为是自己吃了亏，那也就没有资格称为“乱世之奸雄了”。如果曹操“据理力争”，想让汉献帝废去刘备的皇叔之尊，那岂不是再简单不过的一件事？一纸诏书，告知天下即可。合理、合法，刘皇叔想投诉，都没地儿去。曹操为什么没有那么做呢？显然，如果所谓据“理”力争来的，不是“利益”，曹丞相，是没有兴趣的。</p><p>然而，正是曹操的这一决策，使刘备的命运，由此而巨大改变。正是刘备成为皇叔的那时起，他自己或许还并不知道，他就已经不可能以曹操手下大将的身份参与这场游戏了，接下来，他所唯一能做的，就是成为汉献帝的义务广告宣传员，去渡过他与曹丞相一荣俱荣一损俱损的生涯。从事后来看，刘备确实没有让曹丞相失望，这位刘皇叔的“造势”能力，远非曹操可比，迅速便粉丝如云，各地方势力的支持者，纷纷在这位皇叔的感召下，加入支持献帝的行列，于是，袁绍、刘表、刘璋、张鲁等，先后土崩瓦解。至于说到刘皇叔对曹操的竞争力？象刘备那个规格的皇叔，一个下午曹操就能封出几十个来。据说中山靖王光儿子就生了一百二十多个，大汉朝最不缺的就是“中山靖王之后”。点石成金是曹丞相的专利，只点一个，是怕点多了，贬值，而不是缺少“石头”。后来的事实也证明，他与曹操间的竞争是有限的(在华容道甚至还放了曹操一马)，但他对各诸侯势力的杀伤力，却是巨大的。</p><p>在这个环节中，曹操与刘备，都是胜出者。至于谁会是最终的胜利者？那就只能取决于下一代的教育了。这，就不是本文要讨论的范畴了。(完)</p>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂谈 </tag>
            
            <tag> 三国 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>今日头条视频爬虫</title>
      <link href="/2018/11/20/jiritoutiao-1/"/>
      <url>/2018/11/20/jiritoutiao-1/</url>
      
        <content type="html"><![CDATA[<h1 id="今日头条视频页"><a href="#今日头条视频页" class="headerlink" title="今日头条视频页"></a>今日头条视频页</h1><p><a href="https://www.365yg.com/" target="_blank" rel="noopener">https://www.365yg.com/</a></p><h2 id="1、首先打开今日头条视频列表页"><a href="#1、首先打开今日头条视频列表页" class="headerlink" title="1、首先打开今日头条视频列表页"></a>1、首先打开今日头条视频列表页</h2><p>往下刷新的时候获取观察请求链接情况获取到视频列表的请求链接</p><h3 id="链接如下"><a href="#链接如下" class="headerlink" title="链接如下"></a>链接如下</h3><p><a href="https://www.365yg.com/api/pc/feed/?max_behot_time=1542351388&amp;category=video_new&amp;utm_source=toutiao&amp;widen=1&amp;tadrequire=true&amp;as=A1D57BBEAE87838&amp;cp=5BEE7798D358EE1&amp;_signature=RU1MfhAUHqXfJZp0ysi3V0VNTG" target="_blank" rel="noopener">https://www.365yg.com/api/pc/feed/?max_behot_time=1542351388&amp;category=video_new&amp;utm_source=toutiao&amp;widen=1&amp;tadrequire=true&amp;as=A1D57BBEAE87838&amp;cp=5BEE7798D358EE1&amp;_signature=RU1MfhAUHqXfJZp0ysi3V0VNTG</a></p><p>获取视频列表如下<br><img src="/images/toutiao_1.png" alt=""></p><table><thead><tr><th>参数名</th><th>取值</th><th>说明</th></tr></thead><tbody><tr><td>max_behot_time</td><td>1542351388</td><td>变</td></tr><tr><td>category</td><td>video_new</td><td>变</td></tr><tr><td>utm_source</td><td>toutiao</td><td>不变</td></tr><tr><td>widen</td><td>1</td><td>不变</td></tr><tr><td>tadrequire</td><td>true</td><td>不变</td></tr><tr><td>as</td><td>A1D57BBEAE87838</td><td>变</td></tr><tr><td>cp</td><td>5BEE7798D358EE1</td><td>变</td></tr><tr><td>_signature</td><td>RU1MfhAUHqXfJZp0ysi3V0VNTG</td><td>变</td></tr></tbody></table><p>一个一个的看</p><h3 id="1、max-behot-time"><a href="#1、max-behot-time" class="headerlink" title="1、max_behot_time"></a>1、max_behot_time</h3><p>从参数的数看应该是一个时间戳，暂时可以不用管</p><h3 id="2、category"><a href="#2、category" class="headerlink" title="2、category"></a>2、category</h3><p>从字段的意思看是视频的频道（分类），video_new 应该是推荐页面，但是从页面上看不到任何分类信息，所以第一个需要找的参数就是视频的频道列表。</p><p><img src="/images/toutiao_2.png" alt=""></p><p>这个参数比较简单，可以直接拿video_new 参数值去视频js文件中搜索一下</p><p><img src="/images/toutiao_3.png" alt=""></p><p>整理如下：</p><table><thead><tr><th>频道id</th><th>频道名称</th></tr></thead><tbody><tr><td>video_new</td><td>推荐</td></tr><tr><td>subv_voice</td><td>音乐</td></tr><tr><td>subv_funny</td><td>搞笑</td></tr><tr><td>subv_society</td><td>社会</td></tr><tr><td>subv_comedy</td><td>小品</td></tr><tr><td>subv_life</td><td>生活</td></tr><tr><td>subv_movie</td><td>影视</td></tr><tr><td>subv_entertainment</td><td>娱乐</td></tr><tr><td>subv_cute</td><td>呆萌</td></tr><tr><td>subv_game</td><td>游戏</td></tr><tr><td>subv_boutique</td><td>原创</td></tr><tr><td>subv_broaden_view</td><td>开眼</td></tr></tbody></table><h4 id="3、as、cp"><a href="#3、as、cp" class="headerlink" title="3、as、cp"></a>3、as、cp</h4><p>按照上面的方法还是去js文件中搜索，不过由于该参数每次变化，所以只能搜索参数名。<br>搜索cp，发现cp和as都找到了，一下逮住俩</p><p><img src="/images/toutiao_4.png" alt=""></p><p>执行的时候，发现找不到<code>s</code>，断点走一遍发现<code>(0, s.default)(t)</code>就是把<code>t</code>做了一遍<code>md5</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">i</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> t = <span class="built_in">Math</span>.floor((<span class="keyword">new</span> <span class="built_in">Date</span>).getTime() / <span class="number">1e3</span>),</span><br><span class="line">            e = t.toString(<span class="number">16</span>).toUpperCase(),</span><br><span class="line">            n = (<span class="number">0</span>, s.default)(t).toString().toUpperCase(); <span class="comment">// 直接换成自己对t做md5操作就可以了</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="number">8</span> != e.length)</span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line">                <span class="keyword">as</span>: <span class="string">"479BB4B7254C150"</span>,</span><br><span class="line">                cp: <span class="string">"7E0AC8874BB0985"</span></span><br><span class="line">            &#125;;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> r = n.slice(<span class="number">0</span>, <span class="number">5</span>), i = n.slice(<span class="number">-5</span>), o = <span class="string">""</span>, a = <span class="number">0</span>; a &lt; <span class="number">5</span>; a++)</span><br><span class="line">            o += r[a] + e[a];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> u = <span class="string">""</span>, l = <span class="number">0</span>; l &lt; <span class="number">5</span>; l++)</span><br><span class="line">            u += e[l + <span class="number">3</span>] + i[l];</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="keyword">as</span>: <span class="string">"A1"</span> + o + e.slice(<span class="number">-3</span>),</span><br><span class="line">            cp: e.slice(<span class="number">0</span>, <span class="number">3</span>) + u + <span class="string">"E1"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="4、signature"><a href="#4、signature" class="headerlink" title="4、signature"></a>4、signature</h4><p>继续搜索</p><p><img src="/images/toutiao_5.png" alt=""></p><p>看一看到<code>_signature</code>这个参数就是<code>r</code>，而<code>var r = (0, m.sign)(n + &quot;&quot;);</code>然后打断点继续找<code>m</code>，<br>一步一步往上找，最后在下图位置找到</p><p><img src="/images/toutiao_6.png" alt=""></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Function</span>(<span class="function"><span class="keyword">function</span>(<span class="params">t</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'e(e,a,r)&#123;(b[e]||(b[e]=t("x,y","x "+e+" y")(r,a)&#125;a(e,a,r)&#123;(k[r]||(k[r]=t("x,y","new x[y]("+Array(r+1).join(",x[y]")(1)+")")(e,a)&#125;r(e,a,r)&#123;n,t,s=&#123;&#125;,b=s.d=r?r.d+1:0;for(s["$"+b]=s,t=0;t&lt;b;t)s[n="$"+t]=r[n];for(t=0,b=s=a;t&lt;b;t)s[t]=a[t];c(e,0,s)&#125;c(t,b,k)&#123;u(e)&#123;v[x]=e&#125;f&#123;g=,ting(bg)&#125;l&#123;try&#123;y=c(t,b,k)&#125;catch(e)&#123;h=e,y=l&#125;&#125;for(h,y,d,g,v=[],x=0;;)switch(g=)&#123;case 1:u(!)4:f5:u((e)&#123;a=0,r=e;&#123;c=a&lt;r;c&amp;&amp;u(e[a]),c&#125;&#125;(6:y=,u((y8:if(g=,lg,g=,y===c)b+=g;else if(y!==l)y9:c10:u(s(11:y=,u(+y)12:for(y=f,d=[],g=0;g&lt;y;g)d[g]=y.charCodeAt(g)^g+y;u(String.fromCharCode.apply(null,d13:y=,h=delete [y]14:59:u((g=)?(y=x,v.slice(x-=g,y:[])61:u([])62:g=,k[0]=65599*k[0]+k[1].charCodeAt(g)&gt;&gt;&gt;065:h=,y=,[y]=h66:u(e(t[b],,67:y=,d=,u((g=).x===c?r(g.y,y,k):g.apply(d,y68:u(e((g=t[b])&lt;"&lt;"?(b--,f):g+g,,70:u(!1)71:n72:+f73:u(parseInt(f,3675:if()&#123;bcase 74:g=&lt;&lt;16&gt;&gt;16g76:u(k[])77:y=,u([y])78:g=,u(a(v,x-=g+1,g79:g=,u(k["$"+g])81:h=,[f]=h82:u([f])83:h=,k[]=h84:!085:void 086:u(v[x-1])88:h=,y=,h,y89:u(&#123;e&#123;r(e.y,arguments,k)&#125;e.y=f,e.x=c,e&#125;)90:null91:h93:h=0:;default:u((g&lt;&lt;16&gt;&gt;16)-16)&#125;&#125;n=this,t=n.Function,s=Object.keys||(e)&#123;a=&#123;&#125;,r=0;for(c in e)a[r]=c;a=r,a&#125;,b=&#123;&#125;,k=&#123;&#125;;r'</span>.replace(<span class="regexp">/[-]/g</span>, <span class="function"><span class="keyword">function</span>(<span class="params">e</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> t[<span class="number">15</span> &amp; e.charCodeAt(<span class="number">0</span>)]</span><br><span class="line">        &#125;)</span><br><span class="line">    &#125;(<span class="string">"v[x++]=v[--x]t.charCodeAt(b++)-32function return ))++.substrvar .length(),b+=;break;case ;break&#125;"</span>.split(<span class="string">""</span>)))()(<span class="string">'gr$Daten Иb/s!l y͒yĹg,(lfi~ah`&#123;mv,-n|jqewVxp&#123;rvmmx,&amp;effkx[!cs"l".Pq%widthl"@q&amp;heightl"vr*getContextx$"2d[!cs#l#,*;?|u.|uc&#123;uq$fontl#vr(fillTextx$$龘ฑภ경2&lt;[#c&#125;l#2q*shadowBlurl#1q-shadowOffsetXl#$$limeq+shadowColorl#vr#arcx88802[%c&#125;l#vr&amp;strokex[ c&#125;l"v,)&#125;eOmyoZB]mx[ cs!0s$l$Pb&lt;k7l l!r&amp;lengthb%^l$1+s$jl  s#i$1ek1s$gr#tack4)zgr#tac$! +0o![#cj?o ]!l$b%s"o ]!l"l$b*b^0d#&gt;&gt;&gt;s!0s%yA0s"l"l!r&amp;lengthb&lt;k+l"^l"1+s"jl  s&amp;l&amp;z0l!$ +["cs\'(0l#i\'1ps9wxb&amp;s() &amp;&#123;s)/s(gr&amp;Stringr,fromCharCodes)0s*yWl ._b&amp;s o!])l l Jb&lt;k$.aj;l .Tb&lt;k$.gj/l .^b&lt;k&amp;i"-4j!+&amp; s+yPo!]+s!l!l Hd&gt;&amp;l!l Bd&gt;&amp;+l!l &lt;d&gt;&amp;+l!l 6d&gt;&amp;+l!l &amp;+ s,y=o!o!]/q"13o!l q"10o!],l 2d&gt;&amp; s.&#123;s-yMo!o!]0q"13o!]*Ld&lt;l 4d#&gt;&gt;&gt;b|s!o!l q"10o!],l!&amp; s/yIo!o!].q"13o!],o!]*Jd&lt;l 6d#&gt;&gt;&gt;b|&amp;o!]+l &amp;+ s0l-l!&amp;l-l!i\'1z141z4b/@d&lt;l"b|&amp;+l-l(l!b^&amp;+l-l&amp;zl\'g,)gk&#125;ejo&#123;cm,)|yn~Lij~em["cl$b%@d&lt;l&amp;zl\'l $ +["cl$b%b|&amp;+l-l%8d&lt;@b|l!b^&amp;+ q$sign '</span>, [<span class="built_in">Object</span>.defineProperty(e, <span class="string">"__esModule"</span>, &#123;</span><br><span class="line">        value: !<span class="number">0</span></span><br><span class="line">    &#125;)])</span><br></pre></td></tr></table></figure><p>看不懂，所以先执行一下，结果如下，报错<code>e is not defined</code> ，e没有定义，把e的模块单独拿出来</p><p><img src="/images/toutiao_7.png" alt=""></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="built_in">Object</span>.defineProperty(e, <span class="string">"__esModule"</span>, &#123;<span class="attr">value</span>: !<span class="number">0</span> &#125;)]</span><br></pre></td></tr></table></figure><p>搜了一下方法<code>Object.defineProperty</code> 如下：<br><a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Object/defineProperty" target="_blank" rel="noopener">https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Object/defineProperty</a></p><p><code>Object.defineProperty() 方法会直接在一个对象上定义一个新属性，或者修改一个对象的现有属性， 并返回这个对象。</code></p><p>简单说意思就是，<code>e.__esModule=!0</code>，对于单独获取这一个参数来看，好像没啥用，那就先删掉看看。</p><p><img src="/images/toutiao_8.png" alt=""></p><p>没报错，不过什么也没有<br>简化一下代码，把字符串都去掉，如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Function</span>(<span class="function"><span class="keyword">function</span>(<span class="params">t</span>) </span>&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="string">'str'</span>.replace(<span class="regexp">/[-]/g</span>, <span class="function"><span class="keyword">function</span>(<span class="params">e</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> t[<span class="number">15</span> &amp; e.charCodeAt(<span class="number">0</span>)]</span><br><span class="line">        &#125;)</span><br><span class="line">&#125;(<span class="string">"str"</span>.split(<span class="string">"str"</span>)))()(<span class="string">'str'</span>, [&#123;&#125;])</span><br></pre></td></tr></table></figure><p>这样就清晰了很多，一点一点看，看里面</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span>(<span class="params">t</span>) </span>&#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="string">'str'</span>.replace(<span class="regexp">/[-]/g</span>, <span class="function"><span class="keyword">function</span>(<span class="params">e</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> t[<span class="number">15</span> &amp; e.charCodeAt(<span class="number">0</span>)]</span><br><span class="line">        &#125;)</span><br><span class="line">&#125;(<span class="string">"str"</span>.split(<span class="string">"str"</span>))</span><br></pre></td></tr></table></figure><p>相当于把 <code>&quot;str&quot;.split(&quot;str&quot;)</code>这个数组传入函数，然后返回一个字符串。再简化如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Function</span>(</span><br><span class="line"> <span class="keyword">return</span> str</span><br><span class="line">)()(<span class="string">'str'</span>, [&#123;&#125;])</span><br></pre></td></tr></table></figure><p><code>Function(return str)()</code> 执行结果应该返回一个包含两个参数的的<code>function</code></p><p>所以再简化</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span>(<span class="params">a,b</span>)(<span class="params"><span class="string">'str'</span>, [&#123;&#125;]</span>)</span></span><br></pre></td></tr></table></figure><p>第一个参数是一个字符串，所以返回的东西应该在第二个参数里，即<code>function(a,b)(&#39;str&#39;, [a={}])</code></p><p><img src="/images/toutiao_9.png" alt=""></p><p>从上图看，已经找到了<code>sign</code>函数，回到<code>var r = (0, m.sign)(n + &quot;&quot;);</code>，把<code>n</code>传入该方法就可以了</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> e = (<span class="number">0</span>, p.default)(),</span><br><span class="line">    n = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">this</span>.url = <span class="keyword">this</span>._url, <span class="string">"refresh"</span> === t ? (n = <span class="keyword">this</span>.list.length &gt; <span class="number">0</span> ? <span class="keyword">this</span>.list[<span class="number">0</span>].behot_time : <span class="number">0</span>, <span class="keyword">this</span>.url += <span class="string">"min_behot_time="</span> + n) : (n = <span class="keyword">this</span>.list.length &gt; <span class="number">0</span> ? <span class="keyword">this</span>.list[<span class="keyword">this</span>.list.length - <span class="number">1</span>].behot_time : <span class="number">0</span>, <span class="keyword">this</span>.url += <span class="string">"max_behot_time="</span> + n);</span><br><span class="line"><span class="keyword">var</span> r = (<span class="number">0</span>, m.sign)(n + <span class="string">""</span>);</span><br><span class="line">(<span class="number">0</span>, o.default)(<span class="keyword">this</span>.params, &#123;</span><br><span class="line">    <span class="keyword">as</span>: e.as,</span><br><span class="line">    cp: e.cp,</span><br><span class="line">    _signature: r</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>可以看到<code>n</code>就是参数<code>min_behot_time</code>，冤家路窄啊。取一个时间戳就行，顺着js往上找一下也行，找到一个<code>behot_time: Math.floor((new Date).getTime() / 1e3)</code>，确实是一个时间戳。</p><p>终于凑够了，执行的时候提示没有<code>userAgent</code>信息。设置一下就ok了。<br>最终版本js就出来了，如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">navigator = &#123;&#125;;</span><br><span class="line">navigator.userAgent = <span class="string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.62 Safari/537.36"</span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getsign</span>(<span class="params">userid</span>) </span>&#123;</span><br><span class="line"><span class="built_in">Function</span>(</span><br><span class="line"><span class="function"><span class="keyword">function</span>(<span class="params">t</span>) </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="string">'e(e,a,r)&#123;(b[e]||(b[e]=t("x,y","x "+e+" y")(r,a)&#125;a(e,a,r)&#123;(k[r]||(k[r]=t("x,y","new x[y]("+Array(r+1).join(",x[y]")(1)+")")(e,a)&#125;r(e,a,r)&#123;n,t,s=&#123;&#125;,b=s.d=r?r.d+1:0;for(s["$"+b]=s,t=0;t&lt;b;t)s[n="$"+t]=r[n];for(t=0,b=s=a;t&lt;b;t)s[t]=a[t];c(e,0,s)&#125;c(t,b,k)&#123;u(e)&#123;v[x]=e&#125;f&#123;g=,ting(bg)&#125;l&#123;try&#123;y=c(t,b,k)&#125;catch(e)&#123;h=e,y=l&#125;&#125;for(h,y,d,g,v=[],x=0;;)switch(g=)&#123;case 1:u(!)4:f5:u((e)&#123;a=0,r=e;&#123;c=a&lt;r;c&amp;&amp;u(e[a]),c&#125;&#125;(6:y=,u((y8:if(g=,lg,g=,y===c)b+=g;else if(y!==l)y9:c10:u(s(11:y=,u(+y)12:for(y=f,d=[],g=0;g&lt;y;g)d[g]=y.charCodeAt(g)^g+y;u(String.fromCharCode.apply(null,d13:y=,h=delete [y]14:59:u((g=)?(y=x,v.slice(x-=g,y:[])61:u([])62:g=,k[0]=65599*k[0]+k[1].charCodeAt(g)&gt;&gt;&gt;065:h=,y=,[y]=h66:u(e(t[b],,67:y=,d=,u((g=).x===c?r(g.y,y,k):g.apply(d,y68:u(e((g=t[b])&lt;"&lt;"?(b--,f):g+g,,70:u(!1)71:n72:+f73:u(parseInt(f,3675:if()&#123;bcase 74:g=&lt;&lt;16&gt;&gt;16g76:u(k[])77:y=,u([y])78:g=,u(a(v,x-=g+1,g79:g=,u(k["$"+g])81:h=,[f]=h82:u([f])83:h=,k[]=h84:!085:void 086:u(v[x-1])88:h=,y=,h,y89:u(&#123;e&#123;r(e.y,arguments,k)&#125;e.y=f,e.x=c,e&#125;)90:null91:h93:h=0:;default:u((g&lt;&lt;16&gt;&gt;16)-16)&#125;&#125;n=this,t=n.Function,s=Object.keys||(e)&#123;a=&#123;&#125;,r=0;for(c in e)a[r]=c;a=r,a&#125;,b=&#123;&#125;,k=&#123;&#125;;r'</span></span><br><span class="line">.replace(<span class="regexp">/[-]/g</span>, <span class="function"><span class="keyword">function</span>(<span class="params">e</span>) </span>&#123;</span><br><span class="line"><span class="keyword">return</span> t[<span class="number">15</span> &amp; e.charCodeAt(<span class="number">0</span>)]</span><br><span class="line">&#125;)</span><br><span class="line">&#125;</span><br><span class="line">(<span class="string">"v[x++]=v[--x]t.charCodeAt(b++)-32function return ))++.substrvar .length(),b+=;break;case ;break&#125;"</span></span><br><span class="line">.split(<span class="string">""</span>)))</span><br><span class="line">()</span><br><span class="line">(</span><br><span class="line"><span class="string">'gr$Daten Иb/s!l y͒yĹg,(lfi~ah`&#123;mv,-n|jqewVxp&#123;rvmmx,&amp;effkx[!cs"l".Pq%widthl"@q&amp;heightl"vr*getContextx$"2d[!cs#l#,*;?|u.|uc&#123;uq$fontl#vr(fillTextx$$龘ฑภ경2&lt;[#c&#125;l#2q*shadowBlurl#1q-shadowOffsetXl#$$limeq+shadowColorl#vr#arcx88802[%c&#125;l#vr&amp;strokex[ c&#125;l"v,)&#125;eOmyoZB]mx[ cs!0s$l$Pb&lt;k7l l!r&amp;lengthb%^l$1+s$jl  s#i$1ek1s$gr#tack4)zgr#tac$! +0o![#cj?o ]!l$b%s"o ]!l"l$b*b^0d#&gt;&gt;&gt;s!0s%yA0s"l"l!r&amp;lengthb&lt;k+l"^l"1+s"jl  s&amp;l&amp;z0l!$ +["cs\'(0l#i\'1ps9wxb&amp;s() &amp;&#123;s)/s(gr&amp;Stringr,fromCharCodes)0s*yWl ._b&amp;s o!])l l Jb&lt;k$.aj;l .Tb&lt;k$.gj/l .^b&lt;k&amp;i"-4j!+&amp; s+yPo!]+s!l!l Hd&gt;&amp;l!l Bd&gt;&amp;+l!l &lt;d&gt;&amp;+l!l 6d&gt;&amp;+l!l &amp;+ s,y=o!o!]/q"13o!l q"10o!],l 2d&gt;&amp; s.&#123;s-yMo!o!]0q"13o!]*Ld&lt;l 4d#&gt;&gt;&gt;b|s!o!l q"10o!],l!&amp; s/yIo!o!].q"13o!],o!]*Jd&lt;l 6d#&gt;&gt;&gt;b|&amp;o!]+l &amp;+ s0l-l!&amp;l-l!i\'1z141z4b/@d&lt;l"b|&amp;+l-l(l!b^&amp;+l-l&amp;zl\'g,)gk&#125;ejo&#123;cm,)|yn~Lij~em["cl$b%@d&lt;l&amp;zl\'l $ +["cl$b%b|&amp;+l-l%8d&lt;@b|l!b^&amp;+ q$sign '</span>,</span><br><span class="line">[ TAC = &#123;&#125; ])</span><br><span class="line"><span class="keyword">var</span> data = TAC.sign(userid + <span class="string">'0'</span>);</span><br><span class="line"><span class="keyword">return</span> data</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="具体视频链接"><a href="#具体视频链接" class="headerlink" title="具体视频链接"></a>具体视频链接</h2><p>上面的链接拼接完成之后，视频列表可以正常请求了，请求回来的数据取一条看一下。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"single_mode"</span>: <span class="literal">true</span>,</span><br><span class="line"><span class="attr">"abstract"</span>: <span class="string">"八卦象棋：想重炮将死我，只能对炮了，仅此一步棋可以化解"</span>,</span><br><span class="line"><span class="attr">"middle_mode"</span>: <span class="literal">true</span>,</span><br><span class="line"><span class="attr">"more_mode"</span>: <span class="literal">false</span>,</span><br><span class="line"><span class="attr">"tag"</span>: <span class="string">"video_sports"</span>,</span><br><span class="line"><span class="attr">"has_gallery"</span>: <span class="literal">false</span>,</span><br><span class="line"><span class="attr">"tag_url"</span>: <span class="string">"video"</span>,</span><br><span class="line"><span class="attr">"title"</span>: <span class="string">"八卦象棋：想重炮将死我，只能对炮了，仅此一步棋可以化解"</span>,</span><br><span class="line"><span class="attr">"has_video"</span>: <span class="literal">true</span>,</span><br><span class="line"><span class="attr">"chinese_tag"</span>: <span class="string">"视频"</span>,</span><br><span class="line"><span class="attr">"source"</span>: <span class="string">"八卦讲棋"</span>,</span><br><span class="line"><span class="attr">"group_source"</span>: <span class="number">2</span>,</span><br><span class="line"><span class="attr">"image_url"</span>: <span class="string">"http://p99.pstatp.com/list/190x124/111d9000bc384a1e7c376"</span>,</span><br><span class="line"><span class="attr">"media_url"</span>: <span class="string">"/c/user/63387812477/"</span>,</span><br><span class="line"><span class="attr">"media_avatar_url"</span>: <span class="string">"http://p1.pstatp.com/large/9062000424ee2d9e7539"</span>,</span><br><span class="line"><span class="attr">"video_duration_str"</span>: <span class="string">"15:33"</span>,</span><br><span class="line"><span class="attr">"source_url"</span>: <span class="string">"/group/6622421805481067012/"</span>,</span><br><span class="line"><span class="attr">"article_genre"</span>: <span class="string">"video"</span>,</span><br><span class="line"><span class="attr">"is_feed_ad"</span>: <span class="literal">false</span>,</span><br><span class="line"><span class="attr">"video_id"</span>: <span class="string">"v02004740000bfjp2a8m4cim9gian7o0"</span>,</span><br><span class="line"><span class="attr">"behot_time"</span>: <span class="number">1542366341</span>,</span><br><span class="line"><span class="attr">"comments_count"</span>: <span class="number">11</span>,</span><br><span class="line"><span class="attr">"video_play_count"</span>: <span class="number">3630</span>,</span><br><span class="line"><span class="attr">"group_id"</span>: <span class="string">"6622421805481067012"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>发现并没有视频链接。打开视频详情页。找到一个链接<a href="http://ib.365yg.com/video/urls/v/1/toutiao/mp4/v020041d0000bfl6fafrri6cjb9b5rg0?r=990702939595272&amp;s=2968355509&amp;aid=1364&amp;callback=axiosJsonpCallback1&amp;`_`=1542366691315" target="_blank" rel="noopener">http://ib.365yg.com/video/urls/v/1/toutiao/mp4/v020041d0000bfl6fafrri6cjb9b5rg0?r=990702939595272&amp;s=2968355509&amp;aid=1364&amp;callback=axiosJsonpCallback1&amp;`_`=1542366691315</a></p><p><img src="/images/toutiao_10.png" alt=""><br>在返回的数据中看到字段<code>main_url</code>和<code>backup_url_1</code>，这是一个base64加密的链接，解密过后发现正是视频的地址</p><p><a href="http://v11-tt.ixigua.com/14adfc0ca3b2f89aaf37e5eb3a64527b/5beeb5b4/video/m/220a890707eded14f439467e0c47f660c15115ed0f000005bcde4968bf8/?rc=M3VlZWZsdWQ5aTMzZzczM0ApQHRAbzk6Njo3MzUzMzY0NDQ0NDVvQGgzdSlAZjN1KWRzcmd5a3VyZ3lybHh3Zjc2QGQyNmczb2NjaV8tLS4tL3NzLW8jbyMxMjEtMC0tLi4uNjMuNS06I28jOmEtcSM6YHZpXGJmK2BeYmYrXnFsOiMzLl4%3D" target="_blank" rel="noopener">http://v11-tt.ixigua.com/14adfc0ca3b2f89aaf37e5eb3a64527b/5beeb5b4/video/m/220a890707eded14f439467e0c47f660c15115ed0f000005bcde4968bf8/?rc=M3VlZWZsdWQ5aTMzZzczM0ApQHRAbzk6Njo3MzUzMzY0NDQ0NDVvQGgzdSlAZjN1KWRzcmd5a3VyZ3lybHh3Zjc2QGQyNmczb2NjaV8tLS4tL3NzLW8jbyMxMjEtMC0tLi4uNjMuNS06I28jOmEtcSM6YHZpXGJmK2BeYmYrXnFsOiMzLl4%3D</a></p><p>接下来的任务就是解析获取视频信息的链接，继续拆分参数</p><table><thead><tr><th>参数名</th><th>取值</th><th>说明</th></tr></thead><tbody><tr><td>r</td><td>990702939595272</td><td>变</td></tr><tr><td>s</td><td>2968355509</td><td>变</td></tr><tr><td>aid</td><td>1364</td><td>未知</td></tr><tr><td>callback</td><td>axiosJsonpCallback1</td><td>未知</td></tr><tr><td>_</td><td>1542366691315</td><td>变</td></tr></tbody></table><p>继续上面的过程，找参数</p><h4 id="搜索参数"><a href="#搜索参数" class="headerlink" title="搜索参数"></a>搜索参数</h4><p>搜索r，由于太多，搜<code>?r</code> ，找到的各个可疑位置打断点，跟一下。如下图</p><p><img src="/images/toutiao_11.png" alt=""><br>发现都在这，不仅有<code>r</code>和<code>s</code>，而且最后直接返回了链接。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> e = <span class="built_in">document</span>.createElement(<span class="string">"a"</span>);</span><br><span class="line">e.href = t;</span><br><span class="line"><span class="keyword">var</span> n = <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> t = <span class="number">0</span>, e = <span class="keyword">new</span> <span class="built_in">Array</span>(<span class="number">256</span>), n = <span class="number">0</span>; <span class="number">256</span> !== n; ++n)</span><br><span class="line">            t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = n) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>, e[n] = t;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"undefined"</span> != <span class="keyword">typeof</span> <span class="built_in">Int32Array</span> ? <span class="keyword">new</span> <span class="built_in">Int32Array</span>(e) : e</span><br><span class="line">    &#125;(),</span><br><span class="line">    r = e.pathname + <span class="string">"?r="</span> + <span class="built_in">Math</span>.random().toString(<span class="number">10</span>).substring(<span class="number">2</span>);</span><br><span class="line"><span class="string">"/"</span> !== r[<span class="number">0</span>] &amp;&amp; (r = <span class="string">"/"</span> + r);</span><br><span class="line"><span class="keyword">var</span> i = <span class="function"><span class="keyword">function</span>(<span class="params">t</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> e, r, i = <span class="number">-1</span>, o = <span class="number">0</span>, a = t.length; o &lt; a;)</span><br><span class="line">        (e = t.charCodeAt(o++)) &lt; <span class="number">128</span> ? i = i &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ e)] : e &lt; <span class="number">2048</span> ? i = (i = i &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">192</span> | e &gt;&gt; <span class="number">6</span> &amp; <span class="number">31</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | <span class="number">63</span> &amp; e))] : e &gt;= <span class="number">55296</span> &amp;&amp; e &lt; <span class="number">57344</span> ? (e = <span class="number">64</span> + (<span class="number">1023</span> &amp; e), r = <span class="number">1023</span> &amp; t.charCodeAt(o++), i = (i = (i = (i = i &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">240</span> | e &gt;&gt; <span class="number">8</span> &amp; <span class="number">7</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | e &gt;&gt; <span class="number">2</span> &amp; <span class="number">63</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | r &gt;&gt; <span class="number">6</span> &amp; <span class="number">15</span> | (<span class="number">3</span> &amp; e) &lt;&lt; <span class="number">4</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | <span class="number">63</span> &amp; r))]) : i = (i = (i = i &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">224</span> | e &gt;&gt; <span class="number">12</span> &amp; <span class="number">15</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | e &gt;&gt; <span class="number">6</span> &amp; <span class="number">63</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | <span class="number">63</span> &amp; e))];</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span> ^ i</span><br><span class="line">&#125;(r) &gt;&gt;&gt; <span class="number">0</span>;</span><br><span class="line"><span class="keyword">return</span> (location.protocol.indexOf(<span class="string">"http"</span>) &gt; <span class="number">-1</span> ? [location.protocol, e.hostname] : [<span class="string">"http:"</span>, e.hostname]).join(<span class="string">"//"</span>) + r + <span class="string">"&amp;s="</span> + i</span><br></pre></td></tr></table></figure><p>看上面代码发现<code>r</code>、<code>s</code>、<code>_</code>三个参数都有了，然后继续往下找<code>aid</code>，然后断点，发现<code>aid</code>是一个定值</p><p><img src="/images/toutiao_12.png" alt=""></p><p>搜索<code>axiosJsonpCallback</code>发现变化也不大。</p><p><img src="/images/toutiao_13.png" alt=""><br>这样链接就凑够了，简单梳理一下js。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">get_url</span>(<span class="params">t</span>) </span>&#123;</span><br><span class="line"><span class="keyword">var</span> index = <span class="number">1</span>,aid=<span class="number">1364</span></span><br><span class="line"><span class="keyword">var</span> url_split=t.split(<span class="string">"ib.365yg.com"</span>)</span><br><span class="line">    <span class="keyword">var</span> n = <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">var</span> t = <span class="number">0</span>, e = <span class="keyword">new</span> <span class="built_in">Array</span>(<span class="number">256</span>), n = <span class="number">0</span>; <span class="number">256</span> !== n; ++n)</span><br><span class="line">                t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = <span class="number">1</span> &amp; (t = n) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>) ? <span class="number">-306674912</span> ^ t &gt;&gt;&gt; <span class="number">1</span> : t &gt;&gt;&gt; <span class="number">1</span>, e[n] = t;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"undefined"</span> != <span class="keyword">typeof</span> <span class="built_in">Int32Array</span> ? <span class="keyword">new</span> <span class="built_in">Int32Array</span>(e) : e</span><br><span class="line">        &#125;(),</span><br><span class="line"></span><br><span class="line">        r = url_split[<span class="number">1</span>] + <span class="string">"?r="</span> + <span class="built_in">Math</span>.random().toString(<span class="number">10</span>).substring(<span class="number">2</span>);</span><br><span class="line">    <span class="string">"/"</span> !== r[<span class="number">0</span>] &amp;&amp; (r = <span class="string">"/"</span> + r);</span><br><span class="line">    print(r)</span><br><span class="line">    <span class="keyword">var</span> i = <span class="function"><span class="keyword">function</span>(<span class="params">t</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> e, r, i = <span class="number">-1</span>, o = <span class="number">0</span>, a = t.length; o &lt; a;)</span><br><span class="line">            (e = t.charCodeAt(o++)) &lt; <span class="number">128</span> ? i = i &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ e)] : e &lt; <span class="number">2048</span> ? i = (i = i &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">192</span> | e &gt;&gt; <span class="number">6</span> &amp; <span class="number">31</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | <span class="number">63</span> &amp; e))] : e &gt;= <span class="number">55296</span> &amp;&amp; e &lt; <span class="number">57344</span> ? (e = <span class="number">64</span> + (<span class="number">1023</span> &amp; e), r = <span class="number">1023</span> &amp; t.charCodeAt(o++), i = (i = (i = (i = i &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">240</span> | e &gt;&gt; <span class="number">8</span> &amp; <span class="number">7</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | e &gt;&gt; <span class="number">2</span> &amp; <span class="number">63</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | r &gt;&gt; <span class="number">6</span> &amp; <span class="number">15</span> | (<span class="number">3</span> &amp; e) &lt;&lt; <span class="number">4</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | <span class="number">63</span> &amp; r))]) : i = (i = (i = i &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">224</span> | e &gt;&gt; <span class="number">12</span> &amp; <span class="number">15</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | e &gt;&gt; <span class="number">6</span> &amp; <span class="number">63</span>))]) &gt;&gt;&gt; <span class="number">8</span> ^ n[<span class="number">255</span> &amp; (i ^ (<span class="number">128</span> | <span class="number">63</span> &amp; e))];</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span> ^ i</span><br><span class="line">    &#125;(r) &gt;&gt;&gt; <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">var</span> _ = (<span class="keyword">new</span> <span class="built_in">Date</span>).getTime()</span><br><span class="line">    <span class="keyword">var</span> callback = <span class="string">"axiosJsonpCallback"</span>+index</span><br><span class="line">    <span class="keyword">return</span>  <span class="string">"http://ib.365yg.com"</span>+r + <span class="string">"&amp;s="</span> + i+<span class="string">"&amp;aid="</span>+aid+<span class="string">"&amp;callback="</span>+callback+<span class="string">"&amp;_="</span>+_</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 爬虫 </tag>
            
            <tag> 视频 </tag>
            
            <tag> 今日头条 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>gif图片资源</title>
      <link href="/2018/07/17/navigation_gif/"/>
      <url>/2018/07/17/navigation_gif/</url>
      
        <content type="html"><![CDATA[<p><strong>免责声明: 以下网站皆收集于互联网,若无意触犯相关法律,告知立即删除.</strong></p><h1 id="gif动图资源"><a href="#gif动图资源" class="headerlink" title="gif动图资源"></a>gif动图资源</h1><table><thead><tr><th style="text-align:left">网站名</th><th style="text-align:left">网址</th></tr></thead><tbody><tr><td style="text-align:left">GIF垂直搜索引擎、风格众多</td><td style="text-align:left"><a href="http://www.giphy.com" target="_blank" rel="noopener">http://www.giphy.com</a></td></tr><tr><td style="text-align:left">Gifparanoia小众</td><td style="text-align:left"><a href="http://www.gifparanoia.org/index.php#" target="_blank" rel="noopener">http://www.gifparanoia.org/index.php#</a></td></tr><tr><td style="text-align:left">Julian Glander幽默插画式</td><td style="text-align:left"><a href="http://glander.co/" target="_blank" rel="noopener">http://glander.co/</a></td></tr><tr><td style="text-align:left">Kotaiguchi-gif汉字和立体空间结合起来，营造出古风古韵的同时还有满满的现代感</td><td style="text-align:left"><a href="http://kotaiguchi-gif.tumblr.com/" target="_blank" rel="noopener">http://kotaiguchi-gif.tumblr.com/</a></td></tr><tr><td style="text-align:left">Golden Wolf热情年轻</td><td style="text-align:left"><a href="http://goldenwolf.tv/" target="_blank" rel="noopener">http://goldenwolf.tv/</a></td></tr><tr><td style="text-align:left">Scorpiondagger恶搞、讽刺、宗教、文化、性</td><td style="text-align:left"><a href="http://scorpiondagger.tumblr.com/" target="_blank" rel="noopener">http://scorpiondagger.tumblr.com/</a></td></tr><tr><td style="text-align:left">Rafael-varona文艺清新、小巧精美、轻幽默</td><td style="text-align:left"><a href="http://www.rafael-varona.com/" target="_blank" rel="noopener">http://www.rafael-varona.com/</a></td></tr><tr><td style="text-align:left">GIF酷</td><td style="text-align:left"><a href="http://www.gifcool.com/" target="_blank" rel="noopener">http://www.gifcool.com/</a></td></tr><tr><td style="text-align:left">打字轨迹特效GIF</td><td style="text-align:left"><a href="http://www.livetyping.com" target="_blank" rel="noopener">http://www.livetyping.com</a></td></tr></tbody></table><p>持续更新……</p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 资源 </tag>
            
            <tag> 图片 </tag>
            
            <tag> git动图 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>互联网使用小工具</title>
      <link href="/2018/07/17/navigation_tools/"/>
      <url>/2018/07/17/navigation_tools/</url>
      
        <content type="html"><![CDATA[<p><strong>免责声明: 以下网站皆收集于互联网,若无意触犯相关法律,告知立即删除.</strong></p><h1 id="小工具、大用途"><a href="#小工具、大用途" class="headerlink" title="小工具、大用途"></a>小工具、大用途</h1><table><thead><tr><th style="text-align:left">网站名</th><th style="text-align:left">网址</th></tr></thead><tbody><tr><td style="text-align:left">PDF转PPT、转word</td><td style="text-align:left"><a href="https://smallpdf.com/cn" target="_blank" rel="noopener">https://smallpdf.com/cn</a></td></tr><tr><td style="text-align:left">youtobe视频下载</td><td style="text-align:left"><a href="http://www.clipconverter.cc/" target="_blank" rel="noopener">http://www.clipconverter.cc/</a></td></tr><tr><td style="text-align:left">字体转换器在线转换</td><td style="text-align:left"><a href="http://www.diyiziti.com/" target="_blank" rel="noopener">http://www.diyiziti.com/</a></td></tr><tr><td style="text-align:left">去除水印</td><td style="text-align:left"><a href="http://xiuxiu.web.meitu.com/" target="_blank" rel="noopener">http://xiuxiu.web.meitu.com/</a></td></tr><tr><td style="text-align:left">配色方案查询</td><td style="text-align:left"><a href="http://nipponcolors.com/#fujisusutake" target="_blank" rel="noopener">http://nipponcolors.com/#fujisusutake</a></td></tr><tr><td style="text-align:left">语音转文字：讯飞听见</td><td style="text-align:left"><a href="https://www.iflyrec.com/" target="_blank" rel="noopener">https://www.iflyrec.com/</a></td></tr><tr><td style="text-align:left">免费好看PPT、word、excel模板</td><td style="text-align:left"><a href="http://www.officeplus.cn/Template/Home.shtml" target="_blank" rel="noopener">http://www.officeplus.cn/Template/Home.shtml</a></td></tr><tr><td style="text-align:left">资源搜索：胖次</td><td style="text-align:left"><a href="http://panc.cc/" target="_blank" rel="noopener">http://panc.cc/</a></td></tr><tr><td style="text-align:left">百度识图</td><td style="text-align:left"><a href="http://image.baidu.com/?fr=shitu" target="_blank" rel="noopener">http://image.baidu.com/?fr=shitu</a></td></tr><tr><td style="text-align:left">价格对比：比一比价</td><td style="text-align:left"><a href="http://www.b1bj.com/" target="_blank" rel="noopener">http://www.b1bj.com/</a></td></tr><tr><td style="text-align:left">店铺宝贝排名查询</td><td style="text-align:left"><a href="http://www.chapaiming.com/" target="_blank" rel="noopener">http://www.chapaiming.com/</a></td></tr><tr><td style="text-align:left">腾讯移动分析</td><td style="text-align:left"><a href="http://mta.qq.com/mta/" target="_blank" rel="noopener">http://mta.qq.com/mta/</a></td></tr><tr><td style="text-align:left">百度指数</td><td style="text-align:left"><a href="http://index.baidu.com/" target="_blank" rel="noopener">http://index.baidu.com/</a></td></tr><tr><td style="text-align:left">友盟数据</td><td style="text-align:left"><a href="http://www.umindex.com/" target="_blank" rel="noopener">http://www.umindex.com/</a></td></tr><tr><td style="text-align:left">易观数据</td><td style="text-align:left"><a href="http://www.analysys.cn/view/home/home.html" target="_blank" rel="noopener">http://www.analysys.cn/view/home/home.html</a></td></tr><tr><td style="text-align:left">中国互联网数据平台</td><td style="text-align:left"><a href="http://www.cnidp.cn/enteruser/checkCookie.do?flag=1" target="_blank" rel="noopener">http://www.cnidp.cn/enteruser/checkCookie.do?flag=1</a></td></tr><tr><td style="text-align:left">市场研究数据报告：企鹅智酷</td><td style="text-align:left"><a href="http://re.qq.com/" target="_blank" rel="noopener">http://re.qq.com/</a></td></tr><tr><td style="text-align:left">协同写作：石墨</td><td style="text-align:left"><a href="https://shimo.im/" target="_blank" rel="noopener">https://shimo.im/</a></td></tr><tr><td style="text-align:left">脑图制作：百度脑图</td><td style="text-align:left"><a href="http://naotu.baidu.com/" target="_blank" rel="noopener">http://naotu.baidu.com/</a></td></tr><tr><td style="text-align:left">脑图制作：幕布</td><td style="text-align:left"><a href="https://mubu.com/" target="_blank" rel="noopener">https://mubu.com/</a></td></tr><tr><td style="text-align:left">团队协作：Tower</td><td style="text-align:left"><a href="https://tower.im/" target="_blank" rel="noopener">https://tower.im/</a></td></tr><tr><td style="text-align:left">小程序制作、网站搭建：上线了</td><td style="text-align:left"><a href="https://www.sxl.cn/" target="_blank" rel="noopener">https://www.sxl.cn/</a></td></tr><tr><td style="text-align:left">H5制作：人人秀</td><td style="text-align:left"><a href="https://www.rrxiu.net/" target="_blank" rel="noopener">https://www.rrxiu.net/</a></td></tr></tbody></table><p>持续更新……</p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 资源 </tag>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>有了这些资源，还需要ui吗？</title>
      <link href="/2018/07/17/navigation_img/"/>
      <url>/2018/07/17/navigation_img/</url>
      
        <content type="html"><![CDATA[<p><strong>免责声明: 以下网站皆收集于互联网,若无意触犯相关法律,告知立即删除.</strong></p><h1 id="图片资源网站"><a href="#图片资源网站" class="headerlink" title="图片资源网站"></a>图片资源网站</h1><table><thead><tr><th style="text-align:left">网站名</th><th style="text-align:left">网址</th></tr></thead><tbody><tr><td style="text-align:left">设计导航网</td><td style="text-align:left"><a href="http://hao.shejidaren.com/" target="_blank" rel="noopener">http://hao.shejidaren.com/</a></td></tr><tr><td style="text-align:left">矢量图标</td><td style="text-align:left"><a href="http://www.iconfont.cn/plus" target="_blank" rel="noopener">http://www.iconfont.cn/plus</a></td></tr><tr><td style="text-align:left">免费高分辨率摄影图片库</td><td style="text-align:left"><a href="http://www.gratisography.com" target="_blank" rel="noopener">http://www.gratisography.com</a></td></tr><tr><td style="text-align:left">免费复古照片公共档案库</td><td style="text-align:left"><a href="http://nos.twnsnd.co/" target="_blank" rel="noopener">http://nos.twnsnd.co/</a></td></tr><tr><td style="text-align:left">清新精致图片个人网站</td><td style="text-align:left"><a href="http://cargocollective.com/" target="_blank" rel="noopener">http://cargocollective.com/</a></td></tr><tr><td style="text-align:left">免费高清壁纸分享网</td><td style="text-align:left"><a href="https://unsplash.com/" target="_blank" rel="noopener">https://unsplash.com/</a></td></tr><tr><td style="text-align:left">Raumrot免费高分辨率无版权图片</td><td style="text-align:left"><a href="http://publicdomainarchive.com/" target="_blank" rel="noopener">http://publicdomainarchive.com/</a></td></tr><tr><td style="text-align:left">Magdeleine免费高清灵感系图片</td><td style="text-align:left"><a href="http://magdeleine.co/" target="_blank" rel="noopener">http://magdeleine.co/</a></td></tr><tr><td style="text-align:left">免费无版权欧美生活图片</td><td style="text-align:left"><a href="http://www.lifeofpix.com/" target="_blank" rel="noopener">http://www.lifeofpix.com/</a></td></tr><tr><td style="text-align:left">博客图片</td><td style="text-align:left"><a href="http://photopin.com/" target="_blank" rel="noopener">http://photopin.com/</a></td></tr><tr><td style="text-align:left">在线免费高质量商用图片素材</td><td style="text-align:left"><a href="https://picjumbo.com/" target="_blank" rel="noopener">https://picjumbo.com/</a></td></tr><tr><td style="text-align:left">Freeimages免费商业图片素材</td><td style="text-align:left"><a href="http://cn.freeimages.com/" target="_blank" rel="noopener">http://cn.freeimages.com/</a></td></tr><tr><td style="text-align:left">免费的无版权图像</td><td style="text-align:left"><a href="https://pixabay.com/" target="_blank" rel="noopener">https://pixabay.com/</a></td></tr><tr><td style="text-align:left">Death to the Stock Photo 会每月向你发邮件，推荐高质图片</td><td style="text-align:left"><a href="http://deathtothestockphoto.com/" target="_blank" rel="noopener">http://deathtothestockphoto.com/</a></td></tr><tr><td style="text-align:left">FoodiesFeed免费高分辨率食品摄影图片</td><td style="text-align:left"><a href="http://premium.foodiesfeed.com/" target="_blank" rel="noopener">http://premium.foodiesfeed.com/</a></td></tr><tr><td style="text-align:left">SuperFamous:在线高清摄影图片分享网</td><td style="text-align:left"><a href="http://images.superfamous.com/" target="_blank" rel="noopener">http://images.superfamous.com/</a></td></tr><tr><td style="text-align:left">Jay Mantri 拍摄自然风景和人文地理类的摄影作品</td><td style="text-align:left"><a href="http://jaymantri.com/" target="_blank" rel="noopener">http://jaymantri.com/</a></td></tr><tr><td style="text-align:left">weheartit文艺灵感系美图</td><td style="text-align:left"><a href="http://weheartit.com/" target="_blank" rel="noopener">http://weheartit.com/</a></td></tr><tr><td style="text-align:left">morgue file高质量免费照片</td><td style="text-align:left"><a href="https://morguefile.com/search/morguefile/1/pop" target="_blank" rel="noopener">https://morguefile.com/search/morguefile/1/pop</a></td></tr><tr><td style="text-align:left">stockvault高质量优雅与现代照片</td><td style="text-align:left"><a href="http://www.stockvault.net/" target="_blank" rel="noopener">http://www.stockvault.net/</a></td></tr><tr><td style="text-align:left">Raumrot复古风格照片</td><td style="text-align:left"><a href="http://raumrot.com/" target="_blank" rel="noopener">http://raumrot.com/</a></td></tr><tr><td style="text-align:left">Im Free按钮、模板、图标、体育健康</td><td style="text-align:left"><a href="http://www.imcreator.com/free" target="_blank" rel="noopener">http://www.imcreator.com/free</a></td></tr><tr><td style="text-align:left">点播图像与用户摄影分享社区</td><td style="text-align:left"><a href="https://freerangestock.com/" target="_blank" rel="noopener">https://freerangestock.com/</a></td></tr><tr><td style="text-align:left">导航式图片素材搜索器</td><td style="text-align:left"><a href="http://photorack.net/index.php" target="_blank" rel="noopener">http://photorack.net/index.php</a></td></tr><tr><td style="text-align:left">freepixels导航式图片素材</td><td style="text-align:left"><a href="http://www.freepixels.com/" target="_blank" rel="noopener">http://www.freepixels.com/</a></td></tr><tr><td style="text-align:left">免费数字照片</td><td style="text-align:left"><a href="http://www.freedigitalphotos.net/" target="_blank" rel="noopener">http://www.freedigitalphotos.net/</a></td></tr><tr><td style="text-align:left">导航式搜索图片合集</td><td style="text-align:left"><a href="http://www.freephotosbank.com/" target="_blank" rel="noopener">http://www.freephotosbank.com/</a></td></tr><tr><td style="text-align:left">高分辨率图片</td><td style="text-align:left"><a href="http://www.rgbstock.com/" target="_blank" rel="noopener">http://www.rgbstock.com/</a></td></tr><tr><td style="text-align:left">免费图片库</td><td style="text-align:left"><a href="http://www.stockphotosforfree.com/" target="_blank" rel="noopener">http://www.stockphotosforfree.com/</a></td></tr><tr><td style="text-align:left">找图就来这</td><td style="text-align:left"><a href="http://www.stockfreeimages.com/" target="_blank" rel="noopener">http://www.stockfreeimages.com/</a></td></tr><tr><td style="text-align:left">优秀图片聚集地</td><td style="text-align:left"><a href="https://www.dreamstime.com/free-photos" target="_blank" rel="noopener">https://www.dreamstime.com/free-photos</a></td></tr><tr><td style="text-align:left">各式图片总有一款适合你</td><td style="text-align:left"><a href="https://500px.com/" target="_blank" rel="noopener">https://500px.com/</a></td></tr><tr><td style="text-align:left">花瓣网</td><td style="text-align:left"><a href="http://huaban.com/" target="_blank" rel="noopener">http://huaban.com/</a></td></tr><tr><td style="text-align:left">站酷旗下正版图片</td><td style="text-align:left"><a href="http://www.hellorf.com/" target="_blank" rel="noopener">http://www.hellorf.com/</a></td></tr></tbody></table><p>持续更新……</p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 资源 </tag>
            
            <tag> 图片 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>优质公众号必备工具</title>
      <link href="/2018/07/17/navigation_wx_tools/"/>
      <url>/2018/07/17/navigation_wx_tools/</url>
      
        <content type="html"><![CDATA[<p><strong>免责声明: 以下网站皆收集于互联网,若无意触犯相关法律,告知立即删除.</strong></p><h1 id="你距离优质公众号还有多远？"><a href="#你距离优质公众号还有多远？" class="headerlink" title="你距离优质公众号还有多远？"></a>你距离优质公众号还有多远？</h1><table><thead><tr><th style="text-align:left">网站名</th><th style="text-align:left">网址</th></tr></thead><tbody><tr><td style="text-align:left">10款好用的神器</td><td style="text-align:left"><a href="http://mp.weixin.qq.com/s/_76OWDlgopBEQfaNjg76Hw" target="_blank" rel="noopener">http://mp.weixin.qq.com/s/_76OWDlgopBEQfaNjg76Hw</a></td></tr><tr><td style="text-align:left">著名icon搜索引擎、海量图标素材</td><td style="text-align:left"><a href="http://iconfinder.com" target="_blank" rel="noopener">http://iconfinder.com</a></td></tr><tr><td style="text-align:left">颜文字素材</td><td style="text-align:left"><a href="http://emot.es" target="_blank" rel="noopener">http://emot.es</a></td></tr><tr><td style="text-align:left">公众号文字特效生成器</td><td style="text-align:left"><a href="http://megaemoji.com/cn" target="_blank" rel="noopener">http://megaemoji.com/cn</a></td></tr><tr><td style="text-align:left">平铺背景图片素材</td><td style="text-align:left"><a href="http://thepatternlibrary.com" target="_blank" rel="noopener">http://thepatternlibrary.com</a></td></tr><tr><td style="text-align:left">图片制作：创客贴</td><td style="text-align:left"><a href="https://www.chuangkit.com/" target="_blank" rel="noopener">https://www.chuangkit.com/</a></td></tr><tr><td style="text-align:left">微信插件：新媒体管家</td><td style="text-align:left"><a href="https://xmt.cn/index" target="_blank" rel="noopener">https://xmt.cn/index</a></td></tr><tr><td style="text-align:left">微信编辑：135编辑器</td><td style="text-align:left"><a href="http://www.135editor.com/" target="_blank" rel="noopener">http://www.135editor.com/</a></td></tr><tr><td style="text-align:left">一键多平台分发：简媒</td><td style="text-align:left"><a href="http://www.ejianmedia.com/s/home" target="_blank" rel="noopener">http://www.ejianmedia.com/s/home</a></td></tr><tr><td style="text-align:left">艺术二维码制作</td><td style="text-align:left"><a href="http://www.9thws.com/" target="_blank" rel="noopener">http://www.9thws.com/</a></td></tr><tr><td style="text-align:left">二维码生成</td><td style="text-align:left"><a href="https://cli.im/" target="_blank" rel="noopener">https://cli.im/</a></td></tr><tr><td style="text-align:left">短链生成</td><td style="text-align:left"><a href="http://sina.lt/" target="_blank" rel="noopener">http://sina.lt/</a></td></tr><tr><td style="text-align:left">短链生成</td><td style="text-align:left"><a href="http://dwz.cn/" target="_blank" rel="noopener">http://dwz.cn/</a></td></tr></tbody></table><p>持续更新……</p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 资源 </tag>
            
            <tag> 工具 </tag>
            
            <tag> 微信公众号 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>偿一代&amp;偿二代体系下的内含价值计算</title>
      <link href="/2018/04/18/baoxian-6/"/>
      <url>/2018/04/18/baoxian-6/</url>
      
        <content type="html"><![CDATA[<p>首先需要搞明白什么是偿一代和偿二代？</p><p>偿一代和偿二代是两种计算内含价值的体系。2005年保监会编制的《人身保险内含价值报告编制指引》，就是我们常说的偿一代体系。不过2016年保监会放开限制后，当年11月有中国精算师协会编制的《精算实践标准》成为了新的内含价值计算的新依据，这个标准就是偿二代体系。</p><hr><p>偿一代体系：<br><a href="http://www.51wf.com/print-law?id=190247" target="_blank" rel="noopener">http://www.51wf.com/print-law?id=190247</a><br>偿二代体系：<br><a href="http://www.e-caa.org.cn/systemNews/show/8a7da90a584878e4015884bd60135306?str=%E4%B8%93%E4%B8%9A%E6%A0%87%E5%87%86" target="_blank" rel="noopener">http://www.e-caa.org.cn/systemNews/show/8a7da90a584878e4015884bd60135306?str=%E4%B8%93%E4%B8%9A%E6%A0%87%E5%87%86</a></p><hr>]]></content>
      
      
      <categories>
          
          <category> 保险 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 保险 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark on yarn 在集群资源充足的时候任务提交不上去</title>
      <link href="/2018/04/18/yarn-1/"/>
      <url>/2018/04/18/yarn-1/</url>
      
        <content type="html"><![CDATA[<h1 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h1><p>在跑spark on yarn提交任务的时候，集群资源还有很多，但是一直在排队，始终提交不上去</p><h1 id="原因排查"><a href="#原因排查" class="headerlink" title="原因排查"></a>原因排查</h1><p>发现虽然集群中还有很多资源，但是有几台机器的cpu已经用完了</p><p>查看yarn的配置文件发现,yarn的资源比较器使用的是DefaultResourceCalculator。<br>配置文件中的注解是说：<br>Capacity Scheduler有两种比较器用以比较两个资源的大小（比如比较用户当前使用的资源量是否超过了设置的上限资源量），默认是DefaultResourceCalculator，它只考虑内存资源。另外一种是DominantResourceCalculator，它采用了DRF比较算法，同时考虑内存和CPU两种资源。</p><p>如：在spark on yarn上面进行资源申请，我们申请了10个container(每个container都是1G内存，1个core)，这是集群中有一个nodemanager，有10G内存，5个core。<br>在默认配置情况下，yarn就有可能将这10个container都发送到这个nodemanager上（即使集群上还有其他nodemanager有资源空闲），这就会导致，有5个container需要等到另外5个container用完core之后才能执行其自己的任务。</p><p>这样就很容易确定问题了，应该是有些机器内存空间充足，cpu占用严重，但是yarn去分配container的时候，不去管cpu的情况，而只去找内存充足的机器，<br>所以就会出现集群资源充足的情况下，有一部分container在空等core的情况。</p><p>capacity-scheduler.xml配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;name&gt;yarn.scheduler.capacity.resource-calculator&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator&lt;/value&gt;</span><br><span class="line">   &lt;description&gt;</span><br><span class="line">     The ResourceCalculator implementation to be used to compare</span><br><span class="line">     Resources in the scheduler.</span><br><span class="line">     The default i.e. DefaultResourceCalculator only uses Memory while</span><br><span class="line">     DominantResourceCalculator uses dominant-resource to compare</span><br><span class="line">     multi-dimensional resources such as Memory, CPU etc.</span><br><span class="line">   &lt;/description&gt;</span><br><span class="line"> &lt;/property&gt;</span><br></pre></td></tr></table></figure></p><h1 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h1><p>我们应该考虑使用DominantResourceCalculator，该资源计算器在计算资源的时候会综合考虑cpu和内存的情况，来决定yarn最后的调度。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.scheduler.capacity.resource-calculator&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.yarn.util.resource.DominantResourceCalculator&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> yarn </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>保险学习笔记5： 财险公司是如何通过承保业务赚钱的？（上）</title>
      <link href="/2018/04/16/baoxian-5/"/>
      <url>/2018/04/16/baoxian-5/</url>
      
        <content type="html"><![CDATA[<p>从财险公司的盈利来看，即使不考虑用保险准备金投资带来的投资收益，财险业务本身就可以盈利，即用保费收入扣除赔付支出和其它费用支出后，业务质量较好的财险公司就可以获得承保利润。</p><p>这正是财险公司与其它金融中介如商业银行、信托公司、基金公司、资产管理公司的不同之处。<br>金融中介：主要功能是将资金从盈余方转移至需求方，其中商业银行从储户获取资金时，需要支付固定利率的利息；<br>其它金融中介通常不承诺固定利率的利息，但是会向资金提供者收取资产管理费，或者对投资收益进行分成；<br>也就是说，金融中介公司一般需要为资金提供者支付利息或创造投资价值，但是财险公司却无需为资金提供者支付利息和创造投资收益。</p><p>巴菲特喜欢财险公司，主要是可以使用大量的低成本保险准备金进行投资而获利。</p><p>这部分主要讨论，在不考虑投资收益的情况下，财险公司是如何赚钱或盈利的？</p><h1 id="一个简化的财险承保业务分析模型"><a href="#一个简化的财险承保业务分析模型" class="headerlink" title="一个简化的财险承保业务分析模型"></a>一个简化的财险承保业务分析模型</h1><p>一个简单的案例：</p><blockquote><p>假定美能达财险公司只从事1年期财险业务，2015年，其所有保险业务都是2015年1月1日凌晨0点承保生效的，生效时收到保费总额为100亿元，所有保单都是2015年12月31日24时到期。为了获得这些保险业务，2015年初支出手续费及佣金20亿元，当年公司支出业务管理费15亿元，上交营业税及附加5亿元，当年赔付55亿元，当年所有保险事故的赔款均已全部支付给了客户。</p></blockquote><p>在不考虑投资收益的情况下，公司的承保利润有多少？如何度量该公司承保业务的绩效呢？<br>1、 承保利润的计算<br>承保利润=保费-赔付-（手续费佣金+业务管理费+营业税及附加）<br>=100-55-（20+15+5）=5（亿元）</p><p>2、 承保业务绩效指标<br>可以用赔付率、成本率和承保利润率来测算承保绩效，即<br>赔付率=赔付/保费=55/100=55%<br>成本率=（赔付+其它各种支出）/保费=95/100=95%<br>承保利润率=1-成本率=5%<br>说明，美能达财险公司没收100元保费，赔付支出55元，其它支出40元，承保利润5元。</p><p>显然，赔付率越低、成本率越低，承保利润越高，业绩就越好</p><p>3、 实际情况下<br>实际情况下，财险公司比上面的案例更复杂一些，主要是三点：<br>第一，财险公司的业务，不止有保险业务，也有非保险业务（保户储金及投资款业务），我们计算承保业务的收入、支出、利润时，通常只考虑保险业务，不考虑非保险业务。</p><p>第二，财险公司有分出、分入业务。在计算保费收入时需要增加分入保费、扣除分出保费在计算赔付支出的时候，需要扣除从分入人哪里得到的“摊回赔付支出”；此外，分入、分出业务回带来分保费用和摊回分保费用，即财险公司做为分入人要为分出人支付分保费用（分保佣金），做为分出人则可以从分入人那里收到或摊回分保费用</p><p>第三，除少量保险外，绝大多数保险都是1年期的，基本都是跨会计年度的，因此，按照权责发生制，在计算承保业务收入时，需要将未到期责任准备金扣除</p><h1 id="承保收入：已赚保费"><a href="#承保收入：已赚保费" class="headerlink" title="承保收入：已赚保费"></a>承保收入：已赚保费</h1><p>1、理解已赚保费<br>考虑到分入、分出因素和保险合同跨会计年度需要适用责权发生制的因素，我们将对应于当期的实际保费收入称为“已赚保费”</p><blockquote><p>已赚保费=保费收入+（分入保费-分出保费）-（期末未到期责任准备金-期初未到期责任准备金）=保费收入+分入保费-分出保费-提提取未到期责任准备金</p></blockquote><p>其中，提取未到期责任准备金=期末未到期责任准备金-期初未到期责任准备金。可以这样理解，因为财险基本都是1年的合同，所以期初未到期的责任准备金，今年全部都可以到期，然后转化称收入，而期末未到期的基本都是今年交的，这部分在算已赚保费的时候需要扣除。</p><p>2、已赚保费案例</p>]]></content>
      
      
      <categories>
          
          <category> 保险 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 保险 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>保险学习笔记3：保险负债的计量上</title>
      <link href="/2018/04/14/baoxian-3/"/>
      <url>/2018/04/14/baoxian-3/</url>
      
        <content type="html"><![CDATA[<p>保险公司的负债主要分为以下三种负债：</p><table><thead><tr><th>保费收入</th><th></th><th>负债</th></tr></thead><tbody><tr><td>原保险保费收入</td><td>保险合同准备金</td><td>未到期责任准备金、未决赔款准备金、寿险责任准备金、长期健康险责任准备金</td></tr><tr><td>保户投资款新增交费</td><td></td><td>保户储金及投资款</td></tr><tr><td>投连险独立账户新增交费</td><td></td><td>独立账户负债</td></tr></tbody></table><p>那这三类负债在保险公司负债表中是怎么计量的呢？</p><h1 id="独立账户负债的计量"><a href="#独立账户负债的计量" class="headerlink" title="独立账户负债的计量"></a>独立账户负债的计量</h1><p>由于投连险的投资账户，是有客户承担全部风险，保险公司只收取资产管理费，所以，独立账户负债按公允价值进行初始确认，以公允价值进行后续计量，盈亏都是客户的。</p><h1 id="保户储金及投资款的计量"><a href="#保户储金及投资款的计量" class="headerlink" title="保户储金及投资款的计量"></a>保户储金及投资款的计量</h1><p>除投连险之外的所有非保险合同交费都计入保户储金和投资款。<br>对于保户储金来说，保险公司需要逐年/月为客户支付利息，可能是固定利率也可能是浮动利率。因此，保户储金及投资款按公允价值进行初始确认，按摊余成本进行后续计量。</p><h1 id="保险合同准备金的计量方法"><a href="#保险合同准备金的计量方法" class="headerlink" title="保险合同准备金的计量方法"></a>保险合同准备金的计量方法</h1><p>保险合同准备金，由未到期责任准备金、未决赔款准备金、寿险责任准备金（未到期+未决）、长期健康险责任准备金（未到期+未决）<br>保险合同准备金很特殊：一方面是因为投资收益的不确定性带来的支付给客户的利息的不确定性。二是由于客户群死亡率、发病率、退保率的不确定性带来的给付不确定性。</p><p>总的可以将四类保险合同准备金归并为两类：未决赔款准备金和未到期责任准备金。</p><h2 id="未决赔款准备金的计量方法"><a href="#未决赔款准备金的计量方法" class="headerlink" title="未决赔款准备金的计量方法"></a>未决赔款准备金的计量方法</h2><p>未决赔款准备金包括：已发生已报案未决赔款准备金、已发生未报案未决赔款准备金和理赔费用准备金<br>已发生已报案未决赔款准备金，保险公司采用<strong>逐案估损法、案均赔款法</strong>等方法，已最终赔付的合理估值为基础，计量这部分准备金<br>已发生未报案未决赔款准备金，根据<strong>链梯法、案均赔款法、准备金进展法、B－F法</strong>等方法，已最终赔付的合理估计金额为基础，计量这部分准备金</p><p>对于理赔费用准备金，保险公司可以未来必须发生的理赔费用的合理估计为基础，计量理赔费用准备金。</p><h2 id="未到期责任准备金的计量方法"><a href="#未到期责任准备金的计量方法" class="headerlink" title="未到期责任准备金的计量方法"></a>未到期责任准备金的计量方法</h2><p>未到期责任准备金的计算公式：<br>未到期责任准备金=合理估计负债+风险边际+剩余边际</p><ul><li>合理估计负债<br>是指对保单未来预期净现金流出的现值的合理估计，由于未来净现金流出有不确定性，这个合理估计就是指预期净现金流出的期望值。<br>就是自己估计一个未来这些保单可能产生的赔付有多少</li><li>风险边际<br>是指为应对预期现金流不确定性而提取的准备金。同样，由于未来净现金流出有不确定性，在合理估计负债基础上增加一点准备金（风险边际）会让保险公司对未来感觉心里更踏实。<br>在合理负债的基础上多准备一点钱，为了预防不确定风险的发生</li><li>剩余边际<br>是指保单隐含的未来利润，将在未来保险期间逐渐摊销或实现。正常情况下，保险公司销售保单，由于预收保费的原因，保费中实际都包含着一定额度的未来利润。<strong>按照（《保险合同相关会计处理规定》（财会[2009]15号），保险人在保险合同初始确认日不应当确认首日利得，于是就将本来赚到的“首日利得”作为剩余边际放在准备金里</strong></li></ul><hr><blockquote><p>剩余边际的小案例<br>一家寿险公司向一位40岁的客户销售了一份交费100万元的终身年金保险合同，销售费用是5万，销售结束后，落到保险公司口袋里的是95万元。</p></blockquote><p>保险公司对这张保单的未来给付进行合理估计并折现，合理估计负债为88万元，再考虑风险边际2万元，只要准备90万，未来给付就应该足够了。这样保险公司口袋里有95万，多出来的5万就是潜在利润，如果不出意外，保险公司已经赚了5万，因此称为“<strong>首日利得</strong>”</p><p>如果现在就将这5万元确认为利润，保险公司再未来几十年的保单期限内，就无法从这张保单上获取利润了，这显然不合理。因此，《保险合同相关会记处理规定》明确，保险人再保险合同初始确认日不应当确认首日利得。</p><p>于是，保险公司将这5万元作为剩余边际放在未到期责任准备金里，以后在保险期限内逐步释放，逐步确认为利润。</p><hr><p>未确认概念：<br>摊余成本？</p><hr><p>学习资料来自微信公众号：保险神潭</p><hr>]]></content>
      
      
      <categories>
          
          <category> 保险 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 保险 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>保险学习笔记4： 保险负债计量下（保险公司到底欠客户多少钱？）</title>
      <link href="/2018/04/14/baoxian-4/"/>
      <url>/2018/04/14/baoxian-4/</url>
      
        <content type="html"><![CDATA[<p>本文主要还是对未到期责任准备金计量方式进行学习整理。</p><h1 id="未到期责任准备金的计量"><a href="#未到期责任准备金的计量" class="headerlink" title="未到期责任准备金的计量"></a>未到期责任准备金的计量</h1><p>上一篇博客曾说过，未到期责任准备金包括合计估计负债、风险边际和剩余边际，下面分别讨论。</p><h2 id="合理估计负债"><a href="#合理估计负债" class="headerlink" title="合理估计负债"></a>合理估计负债</h2><p>基本含义就是，通过未来法对保险合同产生的预期净现金流出的合理估计</p><p>1、 估计预期净现金流出<br>某一保单年度预期净现金流出= 预期现金流出-预期现金流入<br>预期现金流出=保证利益给付（保险事故赔付、生存给付、满期给付等）+非保证利益给付（保单红利等）+管理费用支出（保单维持、理赔等）</p><p>预期现金流入=保险费</p><p>显然，在计算预期净现金流出时需要根据实际经验和未来发展趋势，作一系列的假设，包括保险事故发生率（如死亡率、发病率、残疾率、狐狸状态发生率、火灾发生率等）、退保率、费用、通货膨胀率、保单红利等</p><p>2、估计折现率<br>对于短险的未到期责任准备金，由于负债实际小于等于1年，因此不考虑货币时间价值</p><p>对于长期未到期责任准备金，即寿险责任准备金和长期健康险责任准备金，负债时间超过1年，需要考虑货币时间价值，其折现率应当以资产负债表日可以获取的当前信息为基础确定。</p><ul><li>普通寿险准备金的折现率<br>普通寿险采用预定利率，因此<br>第一，其未来保单利益和保险公司资产投资收益率无关；<br>第二，保险公司在投资时不能有闪失，所以，投资风格比较保守。于是，普通寿险准备金的折现率在相应期限的国债收益率基础上确定。即<blockquote><p>折现率=基准利率+溢价</p></blockquote></li></ul><p>对于基准利率，保险公司通常选择三年移动平均国债到期收益率确定；此外，保险公司会考虑流动性溢价、税收等因素，在基准利率基础上增加一定的溢价。总体而言，折现率反映了保险公司在投资时的风险偏好</p><ul><li>新型寿险准备金的折现率<br>对于未来保险利益随保险公司资产投资收益变动的保险，如分红险、万能险，折现率根据对应资产组合预期产生的未来投资收益率确定。具体而言，保险公司会在考虑未来宏观经济状况、未来资产组合、投资策略、再投资策略、市场利率变动等因素基础上综合确定，同时反映了保险公司在投资时的风险偏好</li></ul><p>分红、万能险有保底利率，但通常保底利率都低于普通寿险预定利率，所以，投资风险相对可以激进一点，折现率可能相对高一点。</p><h2 id="风险边际"><a href="#风险边际" class="headerlink" title="风险边际"></a>风险边际</h2><p>风险边际指为应对预期现金流的不确定性或风险而在合理估计负债基础上多提的准备金。这里的风险既包括保险风险，也包括投资风险。<br>保险风险主要体现在未来赔付和退保等现金流出的不确定性；<br>投资风险主要是指保险公司的投资收益率会随着宏观经济环境的变化起伏不定，导致折现率假设很可能出现偏差。若折现率假设太高（对未来投资收益率预期过高），就会导致准备金提取不足。</p><blockquote><p>风险边际的计算，常用的方法是：<br>寿险风险边际=不利情境下的负债-基于合理估计假设的负债<br>非寿险风险边际=合理估计负债 * 风险边际率</p></blockquote><p>当然，也有寿险工商所将直接在折现率的假设上考虑率风险边际，即合理估计负债的折现率假设的略微低一点，就可以将负债估计的多一点，这样就直接包含率风险边际，中国人寿就采用的这种计算方法。</p><h2 id="剩余边际"><a href="#剩余边际" class="headerlink" title="剩余边际"></a>剩余边际</h2><p>剩余边际是指保单隐含的未来利润，是为了达到“首日不确认利得”的目的而存在的边际。或者说，既然保险合同首日不缺人盈利，那就只好将盈利起名为“剩余边际”包含在准备金中。<br>事实上，如果保险公司定价保守，自然会产生首日利得，但若定价过于激进，也会产生首日亏损。因此，下面分“存在首日利得”与“存在首日损失”两种情况讨论其剩余边际。</p><p>1、存在首日利得时的剩余边际<br>当“<strong>可观察的保险合同负债的市场价值&gt;（合理估计负债+风险边际）</strong>”时，存在首日利得，首日利得等于前者与后者之差，遵照保险合同首日不确认利得的规定，此时，剩余边际=首日利得。即：</p><blockquote><p>剩余边际=可观察的保险合同负债的市场价值-（合理估计负债+风险边际）<br> 可观察的保险合同负债的市场价值=保费收入-市场一致的保单获取成本</p></blockquote><p><strong>市场一致的保单获取成本</strong>是指保险公司获取这份保险合同所花费的费用，包括销售费用、相关增值税、缴纳的保险保障基金等。</p><p>因此，<strong>可观察的保险合同负债的市场价值</strong>就是指保险公司销售这份保单后，将保费扣除直接费用开销后真正落到自己手里的部分。</p><p>2、存在首日损失时的剩余边际<br>当“<strong>可观察的保险合同负债的市场价值&lt;（合理估计负债+风险边际）</strong>”时，存在首日损失，首日损失等于后者与前者之差，此时，剩余边际=0。<br>你可以考虑到，如果将首日损失计入未到期责任准备金，会导致准备金不足，于是，首日损失不计入准备金，而是直接计入损益表，确认亏损。</p><p>3、剩余边际小结<br>剩余边际其实就是“<strong>过去法计算的准备金</strong>”与“<strong>未来法计算的准备金</strong>”之差。因为，按照过去法，未到期责任准备金=保费收入-市场一直获取成本；按照未来法，未到期责任准备金=未来净现金流出折现=合理估计负债+风险边际<br>如果存在首日利得，将其做为剩余边际，计入准备金。在保险期间，逐步将剩余边际摊销计入当期损益。<br>若存在首日损失，说明保险定价不足，已经造成亏损，将亏损额“首日亏损”计入当期损益表。所谓当期损益表，其实就是在利润表中的营业支出中“<strong>提取保险责任准备金</strong>”计算中，对所有产生首日损失的保单按照“<strong>合理估计负债+风险边际</strong>”来足额计算其准备金。</p><h2 id="未到期责任准备金估计案例"><a href="#未到期责任准备金估计案例" class="headerlink" title="未到期责任准备金估计案例"></a>未到期责任准备金估计案例</h2><p>1、财险未到期责任准备金计量案例</p><blockquote><p>2016年2月1日幸福财产保险公司与革命矿业公司签订了财产保险合同，收取保费20万元，市场一致的保单获取成本为2万元。在合同签订日，幸福财险合理估计未来一年内保单赔款和理赔费用以及保单维持费用的基础上，计算出合理估计负债为16万元，风险边际根据理赔经验按照合理估计负债的4%计算。</p></blockquote><p>计算出幸福财险计算这张保单在签订时的未到期责任准备金。</p><blockquote><p>合理估计负债=16w<br>市场一致的保单获取成本=2w<br>风险边际=16w*4%=0.64w<br>可观察的风险合同负债的市场价值=20w-2w=18w<br>首日利得=18w-（16w+0.64w）=1.36w<br>剩余边际=首日利得=1.36w<br>未到期责任准备金=16w+0.64w+1.36w=18w</p></blockquote><p>案例启示：对短期保险来说：</p><ul><li>剩余边际就是保险公司的预期承保利润</li><li>如果未来现金流出符合预期，风险边际其实也会变成承保利润</li><li>由于在计算准备金时未考虑货币世界价值，所以，未到期责任准备金产生的投资收益也将成为保险公司利润组成部分。即：“<strong>保险公司利润=剩余边际+风险边际+投资收益</strong>”。当然，在不利的条件下，风险边际甚至部分或全部剩余边际都会被用来支付未来赔付和理赔费用。</li></ul><p>2、长期寿险责任准备金计量案例</p><blockquote><p>张先生趸交保费10万元购买来美好生活寿险公司的5年期普通寿险（预定利率5%），该保单的保险责任为：1）被保险人5年内发生意外身故，保险公司给付15万元；2）被保险人生存至5年末，保险公司给付12.5万元。通过对该保单进行重大风险测试，美好生活寿险公司将该保单确认为保险合同。该保单的市场一致获取成本为3000元。</p></blockquote><p>计算出美好生活寿险公司这张保单在签订时的寿险责任准备金。<br>为简化计算，忽略意外身故给付成本。</p><ul><li><p>情形1：存在首日利得</p><blockquote><p>合理估计负债=12.5/1.08^5=8.5（万元）（忽略意外身故给付成本，折现率假定保险公司根据国债收益率曲线确定为8%）<br>风险边际=不利情境下的负债-合理估计负债=12.5/1.06^5-12.5/1.08^5 = 0.83（万元）（不利情境只考虑投资收益率下降带来的折现率下降，忽略意外死亡率增加的不利情形）<br>剩余边际=首日利得=（保费收入-市场一直获取成本）-（合理估计负债+风险边际）=（10-0.3）-（8.5+0.83）=0.37（万元）<br>寿险责任准备金=8.5+0.83+0.37=9.7（万元）</p></blockquote></li><li><p>情形2：存在首日损失</p><blockquote><p>合理估计负债=12.5/1.06^5=9.33（万元）（折现率假定为6%）<br>风险边际=不利情境下的负债（折现率降为5%）-合理估计负债=12.5/1.05^5-12.5/1.06^5=9.77-9.33=0.44（万元）<br>首日损失=（合理估计负债+风险边际）-（保费收入-市场一致获取成本）=（9.33+0.44）-（10-03）=0.07（万元）<br>剩余边际=0<br>寿险责任准备金=9.33+0.44+0=9.77（万元）</p></blockquote></li></ul><p>案例启示：对于长期保险来说，提取合理估计负债后，如果未来与当下的预期相同，未来收支已经平衡了，所以，剩余边际就是未来利润的现职，风险边际其实也会转变成利润。<br>不过，如果未来比预期差，风险边际就会转变成保险公司的支出，如果还不够，剩余边际也得用来满足支出。</p><h2 id="案例：中国人寿的保险合同准备金变化"><a href="#案例：中国人寿的保险合同准备金变化" class="headerlink" title="案例：中国人寿的保险合同准备金变化"></a>案例：中国人寿的保险合同准备金变化</h2><p>因为寿险公司既做短期又做长期，主要有四项保险合同准备金（未到期责任准备金、未决赔款准备金、寿险责任准备金、长期健康险责任准备金），而产险公司通常只做短险，主要有两项保险合同准备金（未到期责任准备金、未决赔款准备金），所以，用寿险公司的保险合同准备金变化就可以理解保险公司的准备金变化原理</p><p>下图是中国人寿2015年年报中的保险合同准备金变化情况</p><p><img src="/images/baoxian-4-1.png" alt=""></p><p>我们可以看出：<br>第一、准备金是一个池子，是存量，会随着资金流入流出发生变化。中国人寿的四项保险合同准备金合计金额，从14年12月31的16034.46亿到15年12月31的17159.85亿元。各项准备金都有所变化。<br>第二、期末未到期责任准备金=期初未到期责任准备金+本年增加额（本新增保费首日准备金）-期初未到期责任准备金（本年全部到期了），因此，中国人寿的未到期责任准备金从年初的72.3亿元变为年底的79.44亿元。<br>第三、期末未决赔款准备金=期初未决赔款准备金+本年增加额（当年年底的未决）-赔付款项（起初未决全部都在当年赔掉了），因此，中国人寿的未决赔款准备金从年初的73.16亿变为年底的92.68亿<br>第四、期末寿险（长期健康险）责任准备金=期初寿险（长期健康险）责任准备金+本年增加额（包括当年入账保费首日准备金、准备金增值）-赔付款项-提前解除合同退保金+准备金调整金额（主要指精算变更导致的调整），由此，中国人寿的寿险责任准备金、长期健康险责任准备金从年初的15589.7亿、299.3亿变为年底的16527.63亿、460.1亿</p><hr><p>学习资料来自微信公众号：保险神潭</p><hr>]]></content>
      
      
      <categories>
          
          <category> 保险 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 保险 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>保险学习笔记2：理解保险负债</title>
      <link href="/2018/04/13/baoxian-2/"/>
      <url>/2018/04/13/baoxian-2/</url>
      
        <content type="html"><![CDATA[<p>保险公司负债形式有很多，我们只讨论最重要的，也是特有负债，由规模保费（包含保险业务保费和非保险合同保费）产生的准备金或类似于准备金的负债，这部分负债在保险公司负债中的占比最大，约80%左右。</p><h1 id="三种保费对应三类负债"><a href="#三种保费对应三类负债" class="headerlink" title="三种保费对应三类负债"></a>三种保费对应三类负债</h1><table><thead><tr><th>保费收入</th><th></th><th>负债</th></tr></thead><tbody><tr><td>原保险保费收入</td><td>保险合同准备金</td><td>未到期责任准备金、未决赔款准备金、寿险责任准备金、长期健康险责任准备金</td></tr><tr><td>保户投资款新增交费</td><td></td><td>保户储金及投资款</td></tr><tr><td>投连险独立账户新增交费</td><td></td><td>独立账户负债</td></tr></tbody></table><p>对于这三种负债，可以这样理解：<br>1、负债是存量不是流量，是历年保险业务累计形成的<br>2、相当于保险公司有三个大水池，分别对应三种负债，每个水池有进水管和出水管，进水管流入的是新保费产生的准备金（或投资款）及其增加值（或将要支付给客户的投资收益）；出水管流出的是保险金给付和退保金；在某一时刻留在水池中的金额就是负债金额。</p><h1 id="对三类负债的具体解释"><a href="#对三类负债的具体解释" class="headerlink" title="对三类负债的具体解释"></a>对三类负债的具体解释</h1><p>1、对于短期纯保障性保险，即各类1年期及1年期以下的保障性保险，保险公司从保费收入中提取准备金，形成资产负债表中的“未到期责任准备金和未决赔款准备金”<br>2、对于经过重大保险风险测试、归类为保险合同的长期保障储蓄性保险（普通寿险和分红险）而言，保险公司会从保费中提取准备金，形成资产负债表中的“寿险责任准备金和长期健康险责任准备金”<br>寿险责任准备金：长期寿险的未到期责任准备金和未决赔款准备金之和；<br>长期健康险责任准备金：长期健康险的未到期责任准备金和未决赔款准备金之和<br>3、对于未经过重大保险风险测试、归类为非保险合同的长期保障储蓄性保险（普通寿险和分红险）而言，保费收入计入保护投资款新增交费，形成负债中的”保户储金及投资款“<br>4、对于可拆分的万能险，将进入个人账户的保费计入投资款，形成负债表中的“保户储金及投资款”<br>5、对于可拆分的投资连结保险，将进入投资账户的保费计入投资款，形成了负债表中的独立账户负债。</p><h1 id="产险公司的负债及其特点"><a href="#产险公司的负债及其特点" class="headerlink" title="产险公司的负债及其特点"></a>产险公司的负债及其特点</h1><h2 id="产险公司负债"><a href="#产险公司负债" class="headerlink" title="产险公司负债"></a>产险公司负债</h2><p>由于纯保障性保险都是短期的，其准备金有两个：未到期责任准备金和未决赔款准备金。</p><ul><li>未到期责任准备金<br>也称为未赚保费，是指在会计年度决算时，对未满期保险单提存的对应于剩余保险期限的保险责任的准备金。<br>就是投保人买的保险还没有到期，你需要提取出一部分钱来准备着，以预防投保人在剩余保险期间有什么问题。</li><li>未决赔款准备金<br>指保险事故已经发生在本会计年度内，但是保险公司因为责任界定、理赔程序未完成等原因尚未赔偿或未给付保险金，这部分资金也需要从保费中提取出来。<h2 id="产险负债的特点（以平安产险为例）"><a href="#产险负债的特点（以平安产险为例）" class="headerlink" title="产险负债的特点（以平安产险为例）"></a>产险负债的特点（以平安产险为例）</h2>在负债表中可以看出，其主要的负债就是未到期责任准备金和未决赔款准备金。</li></ul><h1 id="寿险公司负债及其特点"><a href="#寿险公司负债及其特点" class="headerlink" title="寿险公司负债及其特点"></a>寿险公司负债及其特点</h1><h2 id="保险业务负债"><a href="#保险业务负债" class="headerlink" title="保险业务负债"></a>保险业务负债</h2><p>从保险业务看，寿险公司经营以长期保险业务为主，也经营短期保障性保险。长期保险准备金有两个：寿险责任准备金和长期健康险责任准备金。<br>寿险责任准备金来源于长期寿险业务：两全保险、终身寿险、年金保险等；<br>长期健康险责任准备金来源于长期健康险业务：长期重疾险、长期护理险等；</p><h2 id="非保险业务"><a href="#非保险业务" class="headerlink" title="非保险业务"></a>非保险业务</h2><p>从非保险业务看，万能险的个人帐户的保户储金和投资款负债，投连险投资账户的独立账户负债，以及未经过重大保险风险测试的普通寿险和分红险业务产生的保户储金和投资款负债。</p><h2 id="寿险公司负债特点"><a href="#寿险公司负债特点" class="headerlink" title="寿险公司负债特点"></a>寿险公司负债特点</h2><p>1、多数寿险公司以保险业务为主、非保险业务为辅，所以负债以保险业务带来的保险合同准备金（包括未到期责任准备金、未决赔款准备金、寿险责任准备金和长期健康险责任准备金）为主<br>2、多数寿险公司以长期保险为主、短期保险为辅，因此，负债以保险业务带来的长期负债（寿险责任准备金和长期健康险责任准备金）为主<br>3、多数寿险公司以长期寿险为主、长期健康险为辅，因此，负债都以寿险责任准备金为主</p><hr><p>学习资料来自微信公众号：保险神潭</p><hr>]]></content>
      
      
      <categories>
          
          <category> 保险 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 保险 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>保险学习笔记1：保险公司保费收入</title>
      <link href="/2018/04/12/baoxian-1/"/>
      <url>/2018/04/12/baoxian-1/</url>
      
        <content type="html"><![CDATA[<p><img src="/images/baoxian-1.png" alt=""><br><img src="/images/baoxian-2.png" alt=""></p><h1 id="保费收入"><a href="#保费收入" class="headerlink" title="保费收入"></a>保费收入</h1><p>保险公司的保费收入分为三种</p><ul><li>原保险保费收入</li><li>保户投资款新增交费</li><li>投连险独立账户新增交费<br>对于任何一家保险公司来说，这三者之和称为规模保费，而将原保险收入称为保费收入。</li></ul><p>所有保险的产品分为三类</p><ul><li>纯保障性保险</li><li>保障储蓄性保险</li><li>纯投资性保险<br>那这三类保险都是怎么确认保费收入的呢，是确认为原保险保费收入、保户投资款新增交费，还是投连险独立账户新增交费呢？<br>那我们分别讨论一下。</li></ul><h2 id="纯保障性保险产生原保费收入"><a href="#纯保障性保险产生原保费收入" class="headerlink" title="纯保障性保险产生原保费收入"></a>纯保障性保险产生原保费收入</h2><p>纯保障性保险又称为消费性保险，期限都在1年或1年以下，如各类的财险、意外险、医疗险等。这类保险的特点是只有保障功能，保单没有现金价值或账户价值，即没有任何投资功能。</p><p>对于纯保障性保险，客户缴纳保费后，自然就形成了保险公司的“原保险保费收入”。</p><p>其中财产保险公司主要经营的就是纯保障性保险（也有少量的投资性产品），所以保监会给的财险公司的收入情况中只有原保险保费收入。</p><h2 id="纯投资性保险产生投资款"><a href="#纯投资性保险产生投资款" class="headerlink" title="纯投资性保险产生投资款"></a>纯投资性保险产生投资款</h2><p>纯投资性保险是指没有任何保障功能的保险，对于这类合同，保险公司将其确认为“非保险合同”，将收到的保费确认为投资款。<br>如果合同是投连险，就将其保费计入“投连险独立账户新增交费”；<br>如果是其它保险，就计入”保户投资款新增交费”。</p><p>这类保险规模不会太大，像之前平安保险旗下的万能险就是这样的，归类为非保险合同。</p><h2 id="保障储蓄性保险"><a href="#保障储蓄性保险" class="headerlink" title="保障储蓄性保险"></a>保障储蓄性保险</h2><p>1、保障储蓄性保险的特点<br>保障储蓄性保险既有保障功能，又有储蓄投资功能。期限一般在1年以上。<br>像终身寿险、长期重疾险、两全保险都属于保障储蓄性保险。</p><p>2、保障储蓄性保险的4种形式</p><ul><li>普通寿险<br>为客户的现金价值支付固定利率的复利利息，称为预定利率。由于利率固定，所以保单现金价值在整个保险期限内都是预先确定的。</li><li>分红险<br>为客户的现金价值提供保底利率，当前市场上保底利率多为2.5%左右，每年分红一次，红利主要取决于经营分红险的当年盈余</li><li>万能险（现已取消）<br>为客户的现金价值提供保底利率，当前市场上保底利率多为2.5%左右，每个月公布或调整一次结算利率</li><li>投资连结保险（跟基金公司一个模式）<br>类似于买基金，大部分资金投资于股票市场，客户承担风险，保险公司只收取资产管理费。</li></ul><p>3、保障储蓄性保险的保费收入确认<br>那保障储蓄性保险的保费收入是怎么确认的呢？<br>对于保障储蓄性保险来说，看起来保险公司既可以将其认为是保险合同，进而确认为保费收入；<br>也可以认为是非保险合同，进而产生“投资款”。<br>如果没有相应规范，保险公司往往会将其全部归为保费收入，但是显然政策是不会没有任何规范的。<br>为什么保险公司会希望将所有收入都归为保费收入呢？<br>很简单，规模收入中保费收入占比越高，越可以体现自己是一家保险公司，而且也可以符合监管机构“保险姓保”的要求</p><p>1) 政策规定与保险公司选择<br>2009年12月，财政部颁发了财会[2009]15号文“关于印发《保险合同相关会计处理规定》的通知”，专门明确了保障储蓄性保险的保费确认问题。</p><blockquote><p>《保险合同相关会计处理规定》相关规定（摘录）：</p><ul><li>1、保险人与投保人签订的合同，使保险人既承担保险风险又承担其他风险的，应当分别下列情况进行处理：<br>（1）保险风险部分和其他风险部分能够区分，并且能够单独计量的，应当将保险风险部分和其他风险部分进行分拆。保险风险部分，确定为保险合同；其他风险部分，不确定为保险合同。<br>（2）保险风险部分和其他风险部分不能够区分，或者虽能够区分但不能够单独计量的，如果保险风险重大，应当将整个合同确定为保险合同；如果保险风险不重大，不应当将整个合同确定为保险合同。</li><li>2、保险人与投保人签订的需要进行重大保险风险测试的合同，应当在合同初始确认日进行重大保险风险测试。测试结果表明，发生合同约定的保险事故可能导致保险人支付重大附加利益的，即认定该保险风险重大。附加利益，是指保险人在发生保险事故时的支付额，超过不发生保险事故时的支付额的金额。</li></ul></blockquote><p>什么意思呢，就是说看该保障储蓄性保险能不能将保险部分和其它（投资）部分拆分开，如果可以，就将拆分开的保险分别归入保险合同和非保险合同，这样也就自然确认了“保费收入”和“投资款”；<br>如果不好区分，那就需要看这个保险是保险风险更大还是其它风险更大了。这个就需要进行保险风险测试。</p><p>在上面提到的保障储蓄性保险的4种形式中，其中万能险和投连险比较容易拆分，而普通寿险和分红险需要进行风险测试。<br>2）对万能险和投连险进行拆分<br>万能险为客户设有个人帐户，投连险为客户设置投资账户。<br>客户购买万能险或者投连险之后，进入个人帐户或投资账户的钱，不计入保费收入，确认为“保户投资款新增交费”；<br>未进入的那部分保费，确认为“原保费收入”</p><p>3）对普通寿险和分红险进行重大保险风险测试<br>主要看是保险风险大还是其它风险大。而怎么量化这个大呢，看一下中国人寿的风险测试结果。</p><blockquote><p>中国人寿如何进行重大保险风险测试<br>（摘自中国人寿2014年年报）<br>如果原保险保单“保险风险比例”在保险期间的一个或多个时点大于等于5%，则确认为保险合同。<br>保险风险比例=(保险事故发生情境下保险人支付的金额-保险事故不发生情境下保险人支付的金额)/保险事故不发生情境下的保险人支付的金额×100%</p></blockquote><p>按中国人寿的测试来看，只要把保险产品设计成“保险金超过账户价值或现金价值5%”就可以认为整个合同是保险合同。<br>所以，这样的测试还是非常宽松的。</p><hr><p>学习资料来自微信公众号：保险神潭</p><p>数据来着保监会：<br><a href="http://bxjg.circ.gov.cn/web/site0/tab5202/info4103695.htm" target="_blank" rel="noopener">http://bxjg.circ.gov.cn/web/site0/tab5202/info4103695.htm</a></p><hr>]]></content>
      
      
      <categories>
          
          <category> 保险 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 保险 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>从0到1-读后感（一）</title>
      <link href="/2018/04/03/zero2one1/"/>
      <url>/2018/04/03/zero2one1/</url>
      
        <content type="html"><![CDATA[<p>从1到n的世界里，一切市场博弈都是0和游戏，你的获得是从别人的损失中来的，在这样的游戏中，想要长久获利，只能时刻保持警惕，与一切对手做厮杀，只有打败对手，才能获取多一点点的利润。<br>从0到1的世界里，理论上讲一切市场是无限大的，以至于所有的人、企业都可以从中获利，从0到1开发的是未知的需要，市场是空白的，一旦建立护城河，可以坐着享受利润，不允许经历残酷的竞争。<br>所谓一将功成万骨枯，不过是0和博弈的结果，而从0到1的结果是所有人都找到自己的价值和长久获得价值的权利。</p><h1 id="进步的未来"><a href="#进步的未来" class="headerlink" title="进步的未来"></a>进步的未来</h1><p>进步分为两种：</p><ul><li>水平进步<blockquote><p>水平进步又称为广泛进步，意思是照搬以前的经验，从1到n的过程。</p></blockquote></li><li>垂直进步<blockquote><p>垂直进步又称深入进步，意思是探索新的道路，从0到1的过程。</p></blockquote></li></ul><p>从宏观角度看水平进步就是全球化，垂直进步就是科技进步</p><h2 id="水平进步（完全竞争）"><a href="#水平进步（完全竞争）" class="headerlink" title="水平进步（完全竞争）"></a>水平进步（完全竞争）</h2><p>从企业的角度来看，水平进步其实就是复制，复制现有的商业模式、现有的产品、进入现有的市场，产生完全竞争。<br>所谓的完全竞争市场在供求相当时达到平衡。<br>处于竞争市场中的每个公司之间没有差别，产品同质化严重，对产品没有定价权。当这个市场有钱可以赚的时候，就会有很多公司进入，然后供应量上升，价格回落，利润就会荡然无存。如果进入的公司太多，就会有公司亏损，甚至倒闭，然后慢慢的供求关系回到平衡状态。<br>长期来看，没有公司会获得经济利益。<br>很明显的例子，大学门口的煎饼果子，当只有一家煎饼果子摊时，供不应求，天天有人排队；<br>这时候有人看到这个生意赚钱，由于这个生意过于简单，可以很容易的复制，所以很快就在不远处再开一家煎饼果子摊，可能还会赚钱，但是肯定没有那么多了；<br>如果这时再来几个人，每个人都开一个，供给远远大于需求，这时候每天的收入可能就在成本附近了，或者根本不赚钱，一天也卖不了多少；<br>这时候肯定会有人退出，因为没有利润可以赚了，慢慢的退出几家之后，会剩下2-3家，每家的利润能勉强接受，但是肯定没有超额的利润空间了；<br>所以完全竞争会吞噬利润，完全竞争的市场也没有多大的经济利益空间。</p><h2 id="垂直进步（垄断）"><a href="#垂直进步（垄断）" class="headerlink" title="垂直进步（垄断）"></a>垂直进步（垄断）</h2><p>与完全竞争相反的就是垄断。垄断的公司都拥有自己的市场，拥有产品的定价权，没有竞争，可以自己决定供给量和价格，以实现利润最大化。<br>垄断企业企业可能来着与国家的特殊经营权，也可能是靠不断创新，远远甩开对手，在市场竞争中最终胜出。</p><blockquote><p>对竞争的理解<br>在整个社会中，竞争成为了一种观念。我们宣扬竞争，内化竞争的必要性；结果就是竞争越来越激烈，我们为了竞争付出了非常多的努力，但往往获得的却越来越少，我们把自己困在了竞争中。<br>学校教育也在内化竞争，用彼得蒂尔的话就是，无法安静地一直坐在书桌前学习的学生，在环境的影响下感觉自己好像低人一等；而在考试和作业上出类拔萃的孩子最终都是在这个怪异的、与现实世界没有任何交集的学术界找到个人定位。<br>优秀的学生”往高处走”，直到竞争激烈到把他们的梦想吞噬殆尽。高等教育是一场困局，在高中时对未来有宏伟规划的学生，最后却陷入了与智力程度不相上下的同学在传统职场上的竞争，如企业管理咨询和投资银行业务。<br>最后甚至为了获得把自己转变成一个墨守成规之人的特权，要支付数十万。</p></blockquote><h1 id="垄断企业的特征"><a href="#垄断企业的特征" class="headerlink" title="垄断企业的特征"></a>垄断企业的特征</h1><p>垄断的企业这么多好处，那他们的共同点是什么呢？</p><ol><li>专利技术<br>要想通过专利技术达到垄断的效果，只有优于现在的产品10倍才能拥有垄断的效果。<br>而想创造出优于现在技术十倍的产品，必然需要从0到1的创新，创造新的事物，才能是公司的价值无限增长。<br>如果你能做到10倍的优势，就可以避开竞争。</li><li>网络效应<br>不要一开始就进入大的市场，先寻找非常小的市场，为用户提供有价值的产品，然后逐渐扩大市场，使之产生网络效应。<br>像facebook一样，从哈佛学生开始，在到其他高校，然后到全球所有人。</li><li>规模经济<br>规模经济来自于好的商业模式。你的产品是不是会随着你市场占有率的增加而增需要加更多的投入。这个很重要。优秀的商业模式不会随着使用人数的增加而增加成本的投入。<br>如：在线教育，只有10个人听你讲课的时候和有10万个人听课的时候，你需要付出的精力、时间、成本几乎不需要变化。这样的模式形成的规模优势可以创造更多的利润。</li><li>品牌优势<br>好的品牌会占领你心里的某一个认知，一旦提起，你第一个就会想到它。深入人心的品牌形成强势的品牌垄断。<br>苹果手机、格力空调都是这样的产品。</li></ol><h1 id="如何创造垄断的企业"><a href="#如何创造垄断的企业" class="headerlink" title="如何创造垄断的企业"></a>如何创造垄断的企业</h1><p>每一个垄断的企业都来自于一个秘密（未知的需求），一个其他人都不知道，或者跟其他人看法都不一样的秘密，然后偷偷的对这个秘密进行挖掘开发，产生产品，通过这个产品建立一个垄断的企业，这是一个从0到1的创造过程。</p><p>总的来说，从0到1的创新可以创造出垄断的产品，而垄断的产品可以产生超额的利润。<br>从1到n的复制只会是产生同质化的产品，同质化的产品产生竞争，激烈的竞争会吞噬利润，甚至导致公司的破产。<br>个人来说也一样，如果可以找到自己的优势，避开竞争（至少不要去主动寻找竞争），找到属于自己的垄断区域，获取垄断带来的丰厚的回报。</p>]]></content>
      
      
      <categories>
          
          <category> 读书看报 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 从0到1 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>互联网人常用的网站</title>
      <link href="/2018/02/10/navigation_ad/"/>
      <url>/2018/02/10/navigation_ad/</url>
      
        <content type="html"><![CDATA[<p><strong>免责声明: 以下网站皆收集于互联网,若无意触犯相关法律,告知立即删除.</strong></p><h1 id="国内"><a href="#国内" class="headerlink" title="国内"></a>国内</h1><table><thead><tr><th style="text-align:left">网站名</th><th style="text-align:left">网址</th></tr></thead><tbody><tr><td style="text-align:left">adexchanger.cn (广告技术流)</td><td style="text-align:left"><a href="http://www.adexchanger.cn/" target="_blank" rel="noopener">http://www.adexchanger.cn/</a></td></tr><tr><td style="text-align:left">morketing (专注移动营销)</td><td style="text-align:left"><a href="http://morketing.cn/" target="_blank" rel="noopener">http://morketing.cn/</a></td></tr><tr><td style="text-align:left">梅花网 (营销者的信息中心)</td><td style="text-align:left"><a href="http://www.meihua.info/" target="_blank" rel="noopener">http://www.meihua.info/</a></td></tr><tr><td style="text-align:left">疯狂简报 (关注创意与生意)</td><td style="text-align:left"><a href="http://madbrief.com/" target="_blank" rel="noopener">http://madbrief.com/</a></td></tr><tr><td style="text-align:left">199it (互联网数据中心)</td><td style="text-align:left"><a href="http://www.199it.com/" target="_blank" rel="noopener">http://www.199it.com/</a></td></tr><tr><td style="text-align:left">Topmarketing (新锐营销价值平台)</td><td style="text-align:left"><a href="http://itopmarketing.com/" target="_blank" rel="noopener">http://itopmarketing.com/</a></td></tr><tr><td style="text-align:left">RTBchina (程序化广告新闻)</td><td style="text-align:left"><a href="http://www.rtbchina.com/" target="_blank" rel="noopener">http://www.rtbchina.com/</a></td></tr><tr><td style="text-align:left">好奇心日报 (好奇驱动你的世界)</td><td style="text-align:left"><a href="http://www.qdaily.com/" target="_blank" rel="noopener">http://www.qdaily.com/</a></td></tr><tr><td style="text-align:left">虎嗅网 (独立科技媒体)</td><td style="text-align:left"><a href="http://www.huxiu.com/" target="_blank" rel="noopener">http://www.huxiu.com/</a></td></tr><tr><td style="text-align:left">雷锋网 (读懂移动互联网)</td><td style="text-align:left"><a href="http://www.leiphone.com/" target="_blank" rel="noopener">http://www.leiphone.com/</a></td></tr><tr><td style="text-align:left">钛媒体 (网络天下创新事)</td><td style="text-align:left"><a href="http://www.tmtpost.com/" target="_blank" rel="noopener">http://www.tmtpost.com/</a></td></tr><tr><td style="text-align:left">品玩 (有品好玩的科技)</td><td style="text-align:left"><a href="http://www.pingwest.com/" target="_blank" rel="noopener">http://www.pingwest.com/</a></td></tr><tr><td style="text-align:left">36氪 (创业者平台)</td><td style="text-align:left"><a href="http://36kr.com/" target="_blank" rel="noopener">http://36kr.com/</a></td></tr><tr><td style="text-align:left">爱运营 (运营人的胜地)</td><td style="text-align:left"><a href="http://www.iyunying.org/" target="_blank" rel="noopener">http://www.iyunying.org/</a></td></tr><tr><td style="text-align:left">果壳网 (科技有意思)</td><td style="text-align:left"><a href="http://www.guokr.com/" target="_blank" rel="noopener">http://www.guokr.com/</a></td></tr><tr><td style="text-align:left">爱范儿 (连接热爱)</td><td style="text-align:left"><a href="http://www.ifanr.com/" target="_blank" rel="noopener">http://www.ifanr.com/</a></td></tr><tr><td style="text-align:left">极客公园 (发现产品的机制)</td><td style="text-align:left"><a href="http://www.geekpark.net/" target="_blank" rel="noopener">http://www.geekpark.net/</a></td></tr><tr><td style="text-align:left">亿欧网 (驱动创业创新)</td><td style="text-align:left"><a href="http://www.iyiou.com/" target="_blank" rel="noopener">http://www.iyiou.com/</a></td></tr><tr><td style="text-align:left">网站分析在中国 (从基础到前沿)</td><td style="text-align:left"><a href="http://www.chinawebanalytics.cn/" target="_blank" rel="noopener">http://www.chinawebanalytics.cn/</a></td></tr><tr><td style="text-align:left">鸟哥笔记 (移动互联网干货分享)</td><td style="text-align:left"><a href="http://www.niaogebiji.com/" target="_blank" rel="noopener">http://www.niaogebiji.com/</a></td></tr><tr><td style="text-align:left">青瓜传媒 (移动互联网营销者的信息中心)</td><td style="text-align:left"><a href="http://www.opp2.com/" target="_blank" rel="noopener">http://www.opp2.com/</a></td></tr><tr><td style="text-align:left">91运营 (运营人的训练营)</td><td style="text-align:left"><a href="http://www.91yunying.com/" target="_blank" rel="noopener">http://www.91yunying.com/</a></td></tr><tr><td style="text-align:left">人人都是产品经理 (产品人的必备利器)</td><td style="text-align:left"><a href="http://www.woshipm.com/" target="_blank" rel="noopener">http://www.woshipm.com/</a></td></tr><tr><td style="text-align:left">姑婆那些事（运营推广必看的网站）</td><td style="text-align:left"><a href="http://www.gupowang.com/" target="_blank" rel="noopener">http://www.gupowang.com/</a></td></tr><tr><td style="text-align:left">网络广告人社区（广告人不能错过的地方）</td><td style="text-align:left"><a href="http://iwebad.com/" target="_blank" rel="noopener">http://iwebad.com/</a></td></tr><tr><td style="text-align:left">砍柴网（有态度的科技媒体）</td><td style="text-align:left"><a href="http://www.ikanchai.com/" target="_blank" rel="noopener">http://www.ikanchai.com/</a></td></tr><tr><td style="text-align:left">网络人广告社区</td><td style="text-align:left"><a href="http://iwebad.com/" target="_blank" rel="noopener">http://iwebad.com/</a></td></tr><tr><td style="text-align:left">广告门</td><td style="text-align:left"><a href="http://www.adquan.com/" target="_blank" rel="noopener">http://www.adquan.com/</a></td></tr></tbody></table><h1 id="国外"><a href="#国外" class="headerlink" title="国外"></a>国外</h1><table><thead><tr><th style="text-align:left">网站名</th><th style="text-align:left">网址</th></tr></thead><tbody><tr><td style="text-align:left">adexchanger (程序化交易资讯)</td><td style="text-align:left"><a href="http://adexchanger.com/" target="_blank" rel="noopener">http://adexchanger.com/</a></td></tr><tr><td style="text-align:left">adage (营销行业新闻)</td><td style="text-align:left"><a href="http://adage.com/" target="_blank" rel="noopener">http://adage.com/</a></td></tr><tr><td style="text-align:left">businessinsider (IT 技术、产品、趋势、业内动态)</td><td style="text-align:left"><a href="http://www.businessinsider.com/" target="_blank" rel="noopener">http://www.businessinsider.com/</a></td></tr><tr><td style="text-align:left">displayadtech (美国交易广告动态图及公司大全)</td><td style="text-align:left"><a href="http://www.displayadtech.com/" target="_blank" rel="noopener">http://www.displayadtech.com/</a></td></tr><tr><td style="text-align:left">econsultancy (电商及营销分析&amp;报告)</td><td style="text-align:left"><a href="https://econsultancy.com/" target="_blank" rel="noopener">https://econsultancy.com/</a></td></tr><tr><td style="text-align:left">techmeme (科技新闻聚合，扎克伯格也爱看)</td><td style="text-align:left"><a href="https://econsultancy.com/" target="_blank" rel="noopener">https://econsultancy.com/</a></td></tr><tr><td style="text-align:left">TechCrunch (最新科技新闻)</td><td style="text-align:left"><a href="http://techcrunch.com/" target="_blank" rel="noopener">http://techcrunch.com/</a></td></tr><tr><td style="text-align:left">emarketer (数字广告报告及洞察)</td><td style="text-align:left"><a href="http://www.emarketer.com/" target="_blank" rel="noopener">http://www.emarketer.com/</a></td></tr><tr><td style="text-align:left">L2 (商业情报)</td><td style="text-align:left"><a href="http://l2inc.com/" target="_blank" rel="noopener">http://l2inc.com/</a></td></tr><tr><td style="text-align:left">digitalmarketingmagazine (数字营销杂志)</td><td style="text-align:left"><a href="http://digitalmarketingmagazine.co.uk/" target="_blank" rel="noopener">http://digitalmarketingmagazine.co.uk/</a></td></tr><tr><td style="text-align:left">marketingland (数字营销趋势)</td><td style="text-align:left"><a href="http://marketingland.com/" target="_blank" rel="noopener">http://marketingland.com/</a></td></tr><tr><td style="text-align:left">mobiforge (移动网页设计及开发)</td><td style="text-align:left"><a href="http://mobiforge.com/" target="_blank" rel="noopener">http://mobiforge.com/</a></td></tr></tbody></table><h1 id="常用工具"><a href="#常用工具" class="headerlink" title="常用工具"></a>常用工具</h1><table><thead><tr><th style="text-align:left">网站名</th><th style="text-align:left">网址</th></tr></thead><tbody><tr><td style="text-align:left">百度指数 (搜索指数热度)</td><td style="text-align:left"><a href="http://index.baidu.com/" target="_blank" rel="noopener">http://index.baidu.com/</a></td></tr><tr><td style="text-align:left">adbug (针对广告的爬虫及搜索)</td><td style="text-align:left"><a href="http://www.adbug.cn/" target="_blank" rel="noopener">http://www.adbug.cn/</a></td></tr><tr><td style="text-align:left">爱站网 (站长工具，网站 seo 分析)</td><td style="text-align:left"><a href="http://www.aizhan.com/" target="_blank" rel="noopener">http://www.aizhan.com/</a></td></tr><tr><td style="text-align:left">google 趋势 (google 搜索指数)</td><td style="text-align:left"><a href="http://www.google.com/trends" target="_blank" rel="noopener">http://www.google.com/trends</a></td></tr><tr><td style="text-align:left">微博指数 (微博话题关注度)</td><td style="text-align:left"><a href="http://data.weibo.com/" target="_blank" rel="noopener">http://data.weibo.com/</a></td></tr><tr><td style="text-align:left">淘宝指数 (热卖商品)</td><td style="text-align:left"><a href="http://shu.taobao.com/" target="_blank" rel="noopener">http://shu.taobao.com/</a></td></tr><tr><td style="text-align:left">阿里指数 (采购趋势分析)</td><td style="text-align:left"><a href="http://index.1688.com/" target="_blank" rel="noopener">http://index.1688.com/</a></td></tr><tr><td style="text-align:left">移动 app 趋势 (跟踪百万应用)</td><td style="text-align:left"><a href="http://www.asou.com/" target="_blank" rel="noopener">http://www.asou.com/</a></td></tr><tr><td style="text-align:left">电视收视率</td><td style="text-align:left"><a href="http://eye.kuyun.com/web/" target="_blank" rel="noopener">http://eye.kuyun.com/web/</a></td></tr><tr><td style="text-align:left">旅游预测</td><td style="text-align:left"><a href="http://trends.baidu.com/tour/" target="_blank" rel="noopener">http://trends.baidu.com/tour/</a></td></tr><tr><td style="text-align:left">it 桔子 (国内互联网公司大事记)</td><td style="text-align:left"><a href="https://www.itjuzi.com/" target="_blank" rel="noopener">https://www.itjuzi.com/</a></td></tr><tr><td style="text-align:left">Crunchbase (国外公司大事记)</td><td style="text-align:left"><a href="https://www.crunchbase.com/" target="_blank" rel="noopener">https://www.crunchbase.com/</a></td></tr><tr><td style="text-align:left">deeplink (deeplink 试用)</td><td style="text-align:left"><a href="http://deeplink.me/" target="_blank" rel="noopener">http://deeplink.me/</a></td></tr><tr><td style="text-align:left">Ghostery (广告跟踪及监测)</td><td style="text-align:left"><a href="http://ghostery.com/" target="_blank" rel="noopener">http://ghostery.com/</a> (有各版本浏览器插件)</td></tr><tr><td style="text-align:left">百度 echarts (国内最好的数据可视化工具)</td><td style="text-align:left"><a href="http://echarts.baidu.com/" target="_blank" rel="noopener">http://echarts.baidu.com/</a></td></tr><tr><td style="text-align:left">百度 API 服务 (最近开放了用户标签 API)</td><td style="text-align:left"><a href="http://apistore.baidu.com/" target="_blank" rel="noopener">http://apistore.baidu.com/</a></td></tr><tr><td style="text-align:left">网页 abtest  (可视化网站优化)</td><td style="text-align:left"><a href="http://www.abtester.cn/" target="_blank" rel="noopener">http://www.abtester.cn/</a></td></tr><tr><td style="text-align:left">Piwik (开源统计分析工具)</td><td style="text-align:left"><a href="http://piwik.org/" target="_blank" rel="noopener">http://piwik.org/</a></td></tr><tr><td style="text-align:left">affpaying  (国外联盟排行及 offer 查询)</td><td style="text-align:left"><a href="http://www.affpaying.com/" target="_blank" rel="noopener">http://www.affpaying.com/</a></td></tr><tr><td style="text-align:left"><font color="#FF0000"> 大数据导航网站（非常全面的导航网站）</font></td><td style="text-align:left"><a href="http://hao.199it.com/" target="_blank" rel="noopener">http://hao.199it.com/</a></td></tr></tbody></table><p>持续更新……</p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 广告 </tag>
            
            <tag> 资源 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>java io读取超大文件</title>
      <link href="/2018/01/30/java-io-1/"/>
      <url>/2018/01/30/java-io-1/</url>
      
        <content type="html"><![CDATA[<p>日常工作过程中经常使用IO读写文件，但是有时候由于文件过大，导致IO读取时出现内存溢出。<br>这种情况下，我们就可以使用内存映射文件来解决。</p><h1 id="什么是内存映射文件呢？"><a href="#什么是内存映射文件呢？" class="headerlink" title="什么是内存映射文件呢？"></a>什么是内存映射文件呢？</h1><p>内存映射文件，可以理解为将一个文件映射到内存地址，然后可以通过操作内存来访问文件数据。这样既不用担心内存溢出，而且还能获得更高的性能。</p><h1 id="那如何创建和使用内存映射文件呢？"><a href="#那如何创建和使用内存映射文件呢？" class="headerlink" title="那如何创建和使用内存映射文件呢？"></a>那如何创建和使用内存映射文件呢？</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">package com.tzq.utils;</span><br><span class="line"></span><br><span class="line">import java.io.FileInputStream;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.nio.MappedByteBuffer;</span><br><span class="line">import java.nio.channels.FileChannel;</span><br><span class="line">import com.alibaba.fastjson.JSON;</span><br><span class="line">import com.alibaba.fastjson.JSONObject;</span><br><span class="line">/**</span><br><span class="line"> * @author tzq</span><br><span class="line"> */</span><br><span class="line">public class IOUtil &#123;</span><br><span class="line">    private MappedByteBuffer[] mappedBufArray;</span><br><span class="line">    private int count = 0;</span><br><span class="line">    private int number;</span><br><span class="line">    private FileInputStream fileIn;</span><br><span class="line">    private long fileLength;</span><br><span class="line">    private int arraySize;</span><br><span class="line">    private byte[] array;</span><br><span class="line"></span><br><span class="line">    public IOUtil(String fileName, int arraySize) throws IOException &#123;</span><br><span class="line">        this.fileIn = new FileInputStream(fileName);</span><br><span class="line">        FileChannel fileChannel = fileIn.getChannel();</span><br><span class="line">        this.fileLength = fileChannel.size();</span><br><span class="line">        this.number = (int) Math.ceil((double) fileLength / (double) Integer.MAX_VALUE);</span><br><span class="line">        this.mappedBufArray = new MappedByteBuffer[number];// 内存文件映射数组</span><br><span class="line">        long preLength = 0;</span><br><span class="line">        long regionSize = (long) Integer.MAX_VALUE;// 映射区域的大小</span><br><span class="line">        for (int i = 0; i &lt; number; i++) &#123;// 将文件的连续区域映射到内存文件映射数组中</span><br><span class="line">            if (fileLength - preLength &lt; (long) Integer.MAX_VALUE) &#123;</span><br><span class="line">                regionSize = fileLength - preLength;// 最后一片区域的大小</span><br><span class="line">            &#125;</span><br><span class="line">            mappedBufArray[i] = fileChannel.map(FileChannel.MapMode.READ_ONLY, preLength, regionSize);</span><br><span class="line">            preLength += regionSize;// 下一片区域的开始</span><br><span class="line">        &#125;</span><br><span class="line">        this.arraySize = arraySize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int read() throws IOException &#123;</span><br><span class="line">        if (count &gt;= number) &#123;</span><br><span class="line">            return -1;</span><br><span class="line">        &#125;</span><br><span class="line">        int limit = mappedBufArray[count].limit();</span><br><span class="line">        int position = mappedBufArray[count].position();</span><br><span class="line">        if (limit - position &gt; arraySize) &#123;</span><br><span class="line">            array = new byte[arraySize];</span><br><span class="line">            System.out.println(array);</span><br><span class="line">            mappedBufArray[count].get(array);</span><br><span class="line">            return arraySize;</span><br><span class="line">        &#125; else &#123;// 本内存文件映射最后一次读取数据</span><br><span class="line">            array = new byte[limit - position];</span><br><span class="line">            mappedBufArray[count].get(array);</span><br><span class="line">            if (count &lt; number) &#123;</span><br><span class="line">                count++;// 转换到下一个内存文件映射</span><br><span class="line">            &#125;</span><br><span class="line">            return limit - position;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    public void close() throws IOException &#123;</span><br><span class="line">        fileIn.close();</span><br><span class="line">        array = null;</span><br><span class="line">    &#125;</span><br><span class="line">    public byte[] getArray() &#123;</span><br><span class="line">        return array;</span><br><span class="line">    &#125;</span><br><span class="line">    public long getFileLength() &#123;</span><br><span class="line">        return fileLength;</span><br><span class="line">    &#125;</span><br><span class="line">    public static void main(String[] args) throws IOException &#123;</span><br><span class="line">    IOUtil reader = new IOUtil(&quot;/Users/tzq/Downloads/data.log&quot;, 65536);</span><br><span class="line">        long start = System.nanoTime();</span><br><span class="line">        int i = 0 ;</span><br><span class="line">        while (reader.read() != -1)&#123;</span><br><span class="line">        i = i +1;</span><br><span class="line">        String str = new String(reader.getArray());</span><br><span class="line">        String[] lines = str.split(&quot;\r&quot;);</span><br><span class="line">        for(String line : lines)&#123;</span><br><span class="line">        System.out.println(line);</span><br><span class="line">        &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        reader.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark使用多文件输出</title>
      <link href="/2017/12/04/spark-3/"/>
      <url>/2017/12/04/spark-3/</url>
      
        <content type="html"><![CDATA[<h1 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h1><p>最近遇到了这样一个场景，用spark去处理多个数据源的数据，但是这些数据都掺杂在一起，需要根据不同数据源将数据存储在不同的目录中。</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>我们spark处理晚的数据，在存储的时候可以使用saveAsHadoopFile去自定义存储路径和格式。</p><p>具体实例如下：<br>1、首先需要创建一个类，去继承MultipleTextOutputFormat类，并重写它的generateFileNameForKeyValue方法。</p><p>而MultipleTextOutputFormat是何方神圣呢？<br>其实MultipleTextOutputFormat是hadoop的多文件输出类。在写每条记录之前，MultipleOutputFormat将调用generateFileNameForKeyValue方法来确定需要写入的文件名。<br>其中generateFileNameForKeyValue方法的默认实现如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">protected String generateFileNameForKeyValue(K key, V value, String name) &#123;</span><br><span class="line">    return name;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我们可以重写generateFileNameForKeyValue方法，改成根据key存储，或者解析value，根据value中的某一字段进行分目录存储都可以。下例是根据key分目录存储。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 设置根据spark的key进行存储</span><br><span class="line"> */</span><br><span class="line">class RDDMultipleTextOutputFormat[K, V]() extends MultipleTextOutputFormat[K, V]() &#123;</span><br><span class="line">    override def generateFileNameForKeyValue(key: K, value: V, name: String) : String = &#123;</span><br><span class="line">        (key + &quot;/&quot; + name)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>2、然后存储的时候可以使用saveAsHadoopFile存储，并指定存储方式。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">... //处理完的rdd调用saveAsHadoopFile，使用自己定义的存储方式存储</span><br><span class="line">resultRdd.saveAsHadoopFile(</span><br><span class="line">        outputDataPath,</span><br><span class="line">        classOf[String],</span><br><span class="line">        classOf[String],</span><br><span class="line">        classOf[RDDMultipleTextOutputFormat[_,_]])</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spark 任务提交过程</title>
      <link href="/2017/11/29/spark-2/"/>
      <url>/2017/11/29/spark-2/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark任务提交的过程"><a href="#Spark任务提交的过程" class="headerlink" title="Spark任务提交的过程"></a>Spark任务提交的过程</h1><p>试着画图描述一个spark任务提交的完整过程……</p><p>Spark任务提交流程如下图：<br><img src="/images/spark任务提交过程.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JVM</title>
      <link href="/2017/11/21/jvm-1/"/>
      <url>/2017/11/21/jvm-1/</url>
      
        <content type="html"><![CDATA[<h1 id="jvm内存区域"><a href="#jvm内存区域" class="headerlink" title="jvm内存区域"></a>jvm内存区域</h1><ol><li><p>线程隔离的数据区</p><ul><li>程序计数器<br>程序计数器（Program Counter Register）是当前线程所执行的字节码的行号指示器，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。<br>为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，所以程序计数器这类内存区域为“线程私有”的内存<br>如果线程正在执行的是Native方法，这个计数器值则为空（Undefined）。<br>native是与C++联合开发的时候用的！使用native关键字说明这个方法是原生函数，也就是这个方法是用C/C++语言实现的，并且被编译成了DLL，由java去调用</li><li>java虚拟机栈</li><li>本地方法栈<br>他们作用相似，区别只是：虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。<br>每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。<br>程序员人为的分为“堆栈”中的“栈”。</li></ul><p>栈的存储：<br>栈里存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用和指向了一条字节码指令的地址。<br>局部变量表所需的内存空间在编译期间完成分配，其中64位的long和double类型的数据会占2个局部变量空间，其余的数据类型只占用1个。当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。</p></li><li>所有线程共享的数据区<br>java队、方法区<br><img src="/images/jvm-1.png" alt=""></li></ol><h1 id="对象的引用"><a href="#对象的引用" class="headerlink" title="对象的引用"></a>对象的引用</h1><p>java中引用分为：强引用、软引用、弱引用、虚引用（幽灵引用或幻影引用），这4种引用强度逐渐减弱。</p><ul><li>强引用<br>在程序代码中正常的类似于 “Person p = new Person()“这类的引用；垃圾回收器不会回收掉被强引用的对象</li><li>软引用<br>有用但非必须的对象，jdk中提供了SoftReference类来实现软引用<br>系统在发生内存溢出异常时，会把软引用对象进行回收</li><li>弱引用<br>非必须的对象，jdk中提供了WeakReference类来实现弱引用，比软引用弱一些，垃圾回收不论内存是否不足都会回收只被弱引用关联的对象</li><li>虚引用<br>对被引用对象的生存时间不影响；<br>无法通过虚引用来取得一个对象实例；<br>为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知；<br>jdk提供PhantomReference类来实现虚引用</li></ul><h1 id="GC算法"><a href="#GC算法" class="headerlink" title="GC算法"></a>GC算法</h1><h2 id="标记-清除算法（Mark-Sweep）"><a href="#标记-清除算法（Mark-Sweep）" class="headerlink" title="标记-清除算法（Mark-Sweep）"></a>标记-清除算法（Mark-Sweep）</h2><ol><li>标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象<br>该算法的缺点：</li></ol><ul><li>效率问题<br>标记和清除两个过程的效率都不高</li><li>空间问题<br>标记清除后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾回收动作</li></ul><h2 id="复制算法（Copying）"><a href="#复制算法（Copying）" class="headerlink" title="复制算法（Copying）"></a>复制算法（Copying）</h2><ol><li>将可用内存按容量划分为大小相等的两块，每次只是用其中之一</li><li>当这一块的内存用完了，就将还存活的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉<br>该算法的优缺点：</li></ol><ul><li>优点：<br>这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效</li><li>缺点：</li></ul><ol><li>实际可用内存只有原来的一半</li><li>复制算法在对象存活率比较高的情况下需要对较多的对象进行复制操作，效率会变低</li></ol><p>现在的商业虚拟机都使用这种算法来回收新生代。<br>将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中的一块Survivor空间，当回收时，将Eden和Survivor中还存活着的对象一次性复制到另外一块Survivor空间上，最后清理掉Eden和刚刚使用过的Survivor空间。<br>HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，浪费10%</p><p>当Survivor空间不够用的时候，需要依赖其他的内存（这里指老年代）进行分配担保</p><h2 id="标记整理算法（Mark-Compact）"><a href="#标记整理算法（Mark-Compact）" class="headerlink" title="标记整理算法（Mark-Compact）"></a>标记整理算法（Mark-Compact）</h2><ol><li>标记出需要清除的对象</li><li>让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存</li></ol><h2 id="分代收集算法（Generational-Collection）"><a href="#分代收集算法（Generational-Collection）" class="headerlink" title="分代收集算法（Generational Collection）"></a>分代收集算法（Generational Collection）</h2><ol><li>根据对象存活周期将内存划分为几块</li><li>一般是把java堆分为新生代和老年代，这样就可用根据各个年代的特点采用最恰当的收集算法</li><li>在新生代中，每次垃圾回收时都会发现有大量的对象死去，只有少量存活，所以适合复制算法，只需要付出少量存活对象的复制成本就可用完成收集</li><li>老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或者“标记-整理”算法来进行回收</li></ol>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> jvm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>“在别处”症候群</title>
      <link href="/2017/11/18/zawen-1/"/>
      <url>/2017/11/18/zawen-1/</url>
      
        <content type="html"><![CDATA[<p>文章转自：<a href="http://www.xinli001.com/info/100008789" target="_blank" rel="noopener">http://www.xinli001.com/info/100008789</a></p><p>心理导读：生活不一定在别处，当我们将全部希望和幻想寄托在一个虚无的新环境时，可能我们早已忘却“生活在这里”的能力。—— www.xinli001.com<br><img src="/images/zashuo-1.png" alt=""><br>我有一位朋友，年纪长我几岁，工作能力很强，在我所处行业内算是小有名气。</p><p>半年前他辞了职，再之后都在家中赋闲，每天喝茶写字，摆弄各种爱好，至少从社交软件上看，日子过得很充实。我有次跟他聊天，问他有没有工作的计划。他没有直接回答我，而是绕开我的问题说着行业的问题所在，最后他说，没准换个城市心境会改变很多。</p><p>我被绕了进去，追着问，即使换了环境，这些问题不是依然还存在吗？</p><p>他答道，可是如果你的心态变了，看问题的方式也许就会有大不同。</p><p>我说，心态的改变与环境有必要联系吗？</p><p>他盯着我，直到看得我发毛才一脸肯定地说，那是当然的了。</p><p>原本这只是一次闲聊，巧的是，跟他告别两周后，相同的对白又一次发生。我公司里有位实习生试用期结束，对我说想要换一间公司。我第一反应是留住他，因为他在几位同期的实习生当中，能力算是不错的。</p><p>我问他是因为薪水的问题，还是在这里工作得不顺心？</p><p>他坦白说都不是，只是觉得自己每天做最基础的工作，一成不变的日程令他觉得浪费时间。他说，没准换间公司会见识到更多的东西。</p><p>我说，即使换一间公司，以你初入职场的能力，也一样是做同样的事情啊，何必操之过急呢。</p><p>他摇摇头说，正是因为我刚刚毕业，所以才急需多经历新鲜的环境，这样才能看到不同角度的世界，才称得上完整的人生。</p><p>听到这里，我哑口无言，只好在他的辞职函上签字。</p><p>如果说我那位朋友还没有将话点透，实习生的道理则让我切切实实无从反驳。换作我是他的年龄，大概想破头也讲不出这样角度刁钻的观点。我不禁沉思，在大部分人眼中，视界狭窄就代表着见识浅、能力低，沦为弱势群体的想法根深蒂固，而经历不同环境所带来的阅历上的“充电”是正常，且理所应当的。然而，在这个逻辑关系里，人们似乎都刻意在着重“经历”的获取，而忽略了阅历并非只要经历过就会拥有这件事。</p><p>前不久我收到一位朋友从台北寄来明信片，正面是雄伟的一零一大厦，背面却只潦草写着，不多说了，在赶飞机。回来的时候我去机场接她，问到台北的感受如何，她带着一脸倦容说，人太多，行程又紧张，很多景点都只是走马观花，照片都没拍几张。实在难以描述在她语气中的失落，有不甘，有无奈，更多的是累。</p><p>你看，明明是去度假，却让自己累成了一匹马。在此之前，她何尝不是抱着摆脱都市生活躲到远方旅行，换个角度看世界的想法，然而这种急匆匆的经历，除了满心的疲累，我实在想不出可以有什么收获。</p><p>事实上，我认识的许多人都是这样，在城市里一天天觉得毫无乐趣枯燥乏味犹如困兽，却以为去遥远的地方旅行时就会神采焕发活灵活现；相同的工作做上一年半载就开始怀疑是在蹉跎人生，却以为换间公司换个环境就可以寻找到青春的激情、丰富的见闻和源源不断的新鲜感；在感情上，这种毫无逻辑的心理表现得更加淋漓尽致，遇见心仪的对象，睡前辗转反侧脑补无数种同她在一起的甜蜜场景，自以为天造地设，然而真正走到一起却发现她矫情做作，爱慕虚荣，睡觉打呼醒来还有口气，方才如大梦初醒，悔之晚矣。</p><p>“生活在别处”，诗人兰波的这句话自从被米兰·昆德拉弄得世人皆知，就变成了困顿都市人们心中的精神鸦片。在一成不变的生活夹缝中求生存，难免会幻想“在别处”的美好，那儿有清新空气恬静生活，有高薪待遇闲暇时光，更有簇新的梦想，志同道合的人群和无数喜闻乐见的送炮女青年。</p><p>记得念书的时候，我们的天敌是父母口中别人家的孩子，不久你谈恋爱了，天敌变成了恋人言语中别人家的男朋友，没想到不知不觉中，我们自己已经为自己设好了来自同一星球的天敌，别处的生活。看完无数版本的砺志电影和书籍传记，我们自以为掌握改变命运的咒语，学会不停地规劝自己和别人，换个工作，换个女友，换个城市，换种人生，用改变带来的可能性来告解心中的压抑，却从未想过，此刻压抑着你的未必是当下的生活。</p><p>我另一位朋友大学的专业是西班牙语，毕业后去厄瓜多尔援建铁路，在那儿工作了两年决定回国，我问他原因，他说那里的环境过于艰苦，经常睡到一半，发现被窝里有一只巴掌大的毛茸茸蜘蛛，出门走一圈，两米长的鳄鱼满街跑，有时候吃人，有时候被当地人捉走吃，不仅如此，他还遭遇过不下两次持枪入室抢劫。终于有一天他忍无可忍，觉得再待下去可能总有一天会被鳄鱼吃掉或者被无辜枪杀，于是毅然决定回国。</p><p>回来后，他找了一份翻译的工作，薪水在国内也还算不错，但他始终无法适应。在厄瓜多尔的时候，他的工作比较自由，一到假期就买张机票满世界跑，可现在就连附近的旅游城市他也只能望洋兴叹，实在忍不住的时候他就在广州租一辆自行车，漫无目的地满城跑。这种不适应感遍布他生活的方方面面，在国外每天幻想八大菜系梦里都是活色生香，但来到广州，依然每天只在一家茶餐厅用餐，不是他吃不起，而是完全没有了想要吃的欲望。</p><p>就这样，他在国内工作不到三个月，就决定重新去国外工作。比起空虚，他宁愿选择艰苦。</p><p>他的这种情况被我笑称为“在别处症候群”，在同一个环境待的越久，越会产生抵触的情绪和对别处生活的向往。但这种向往，只是你对现实的失望和逃避，即使去到别处，也未必能获得理想中的生活，你只是像个赌徒般沉溺在那无数种可能性之中而已。</p><p>我们习惯了时刻绷紧弦待命，哪怕是周末也像是在与时间赛跑，两点约了朋友喝茶所以一点就要出发，因为怕堵，五点必须吃完晚饭否则就赶不上六点半的电影开场。我们也厌倦这种枯燥的三点一线，以为在别处就可以摆脱所有的烦恼。但别忘了，在同样的城市里，有人下班路上观察蚂蚁搬家都要半小时，也有人甭管在纽约巴黎东京还是公司大厦都一样，拼命赶时间，仿佛浪费一丁点儿就是罪过。</p><p>生活不一定在别处，当我们将全部希望和幻想寄托在一个虚无的新环境时，可能我们早已忘却“生活在这里”的能力。其实，不被生活改变，亦不放过丝毫享受生活的机会，也许这才是生活真正的模样。微博上有人讲现代人个个都选择困难症，在上海向往北京的烤鸭，在北京惦记广州的早茶，在广州垂涎重庆的火锅，在重庆梦到西安的肉夹馍，然而我们在一次次向往和踟蹰中，浪费掉的绝不止是光阴。</p>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂谈 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>人生如棋，不得贪胜</title>
      <link href="/2017/11/18/zawen-2/"/>
      <url>/2017/11/18/zawen-2/</url>
      
        <content type="html"><![CDATA[<p>围棋十决</p><ol><li>不得贪胜</li><li>入界宜缓</li><li>攻彼顾我</li><li>弃子争先</li><li>舍小就大</li><li>逢危须弃</li><li>慎勿轻速</li><li>动须相应</li><li>彼强自保</li><li>势孤取和</li></ol>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂谈 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zookeeper的选举四：Leader选举总结</title>
      <link href="/2017/11/04/zookeeper-6/"/>
      <url>/2017/11/04/zookeeper-6/</url>
      
        <content type="html"><![CDATA[<p>zookeeper在启动时候会进行选主；<br>下面对zookeeper的选主过程做一些总结。</p><h1 id="Zookeeper选主流程"><a href="#Zookeeper选主流程" class="headerlink" title="Zookeeper选主流程"></a>Zookeeper选主流程</h1><p>本文主要描述zookeeper启动时的选主过程，当leader挂掉，重新进行选举的过程与此过程大同小异，这里就不过多赘述。</p><p>zookeeper选主流程如下图：<br><img src="/images/zookeeper选主过程-1.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>复利人生</title>
      <link href="/2017/11/03/fuli/"/>
      <url>/2017/11/03/fuli/</url>
      
        <content type="html"><![CDATA[<p>理解时间，不慌不忙，静待时间的复利<br><img src="/images/fuli-1.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 复利 </tag>
            
            <tag> 杂谈 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zookeeper的选举三：Leader选举的实现细节</title>
      <link href="/2017/11/02/zookeeper-5/"/>
      <url>/2017/11/02/zookeeper-5/</url>
      
        <content type="html"><![CDATA[<h1 id="Leader选举的实现细节"><a href="#Leader选举的实现细节" class="headerlink" title="Leader选举的实现细节"></a>Leader选举的实现细节</h1><p><strong>服务器的状态</strong></p><ul><li>LOOKING：寻找Leader状态，当服务器处于该状态时，会认为当前集群中没有leader，因此需要进入leader选举流程</li><li>FOLLOWING：跟随者状态，当前服务器是Follower</li><li>LEADING：领导者状态，当前服务器为Leader</li><li>OBSERVING：观察者状态，当前服务器角色是Observer</li></ul><p><strong>Vote数据结构说明</strong></p><ul><li>id：被推举的leader的SID值</li><li>zxid：被推举的leader的事务ID</li><li>electionEpoch：用来判断多个投票是否在统一轮选举周期中。该值在服务端是一个自增序列，每次进入新一轮投票，都会对该值进行加1操作</li><li>peerEpoch：被推举leader的epoch</li><li>state：当前服务器的状态</li></ul><h2 id="QuorumCnxManager：网络IO"><a href="#QuorumCnxManager：网络IO" class="headerlink" title="QuorumCnxManager：网络IO"></a>QuorumCnxManager：网络IO</h2><p>每台服务器启动的时候，都会启动一个QuorumCnxManager，负责各台服务器之间的底层leader选举工程中的网络通信。</p><ol><li>消息队列<br>QuorumCnxManager这个类内部维护了一系列的队列，用于保存接收到的、待发送的消息。</li></ol><ul><li>recvQueue：消息接收队列，用于存放那些从其他服务器接收到的消息</li><li>queueSendMap：消息发送队列，用于保存那些待发送的消息；它是一个Map，按SID进行分组，分别为集群中每台机器分配一个单独队列，从而保证各台机器之间的消息发送互不影响</li><li>senderWorkerMap：发送器集合。每个SendWorker消息发送器，都对应一台远程Zookeeper服务器，负责消息的发送。在senderWorkerMap中，也按照SID进行了分组</li><li>lastMessageSent：最近发送过的消息。这个集合中，为每个SID保留最近发送过的一个消息。</li></ul><ol><li>建立连接<br>QuorumCnxManager在启动的时候，会创建一个ServerSocket来监听leader选举的通信端口（默认3888）。开启端口监听后，Zookeeper会不断的接收到来自其他服务器的“创建连接”请求，在接收到其他服务器的TCP连接请求时，会交给receiveConnection函数来处理。<br>为了避免两台机器之间重复创建TCP连接，zookeeper设计了一种建立TCP连接的规则：<blockquote><p>只允许SID大的服务器主动和其他服务器建立连接，否则断开连接。<br>服务器接收到请求后，如果发现当前服务器的SID比接收到的大，就断开连接，然后自己主动去和远程服务器建立连接</p></blockquote></li></ol><p>一旦建立连接，就会根据远程服务器的SID创建相应的消息发送器SendWorker和消息接收器RecvWorker，并启动他们。</p><ol><li><p>消息接收和发送<br>在完成选票的初始化之后，服务器就会发起第一次投票。Zookeeper会将刚刚初始化好的选票放入sendqueue队列中，由发送器WorkerSender负责发送出去</p></li><li><p>接收外部投票<br>每台服务器会不断的从recvqueue队列中获取外部投票。如果服务器发现无法获取到任何的外部投票，那么就会立即确认自己是否和集群中其他服务器保持着有效连接。如果发现没有建立连接，就马上建立连接；如果已经建立了连接，那么就再次发送自己当前的内部投票。</p></li><li><p>判断选举轮次<br>在处理外部投票的时候，会根据选举轮次来进行不同处理。</p></li></ol><ul><li>外部选票的选举轮次大于内部选票<br>当服务器发现自己的选举轮次已经落后与该外部投票对应服务器的选举轮次，那么就会立即更新自己的选举轮次（logicalclock），并且清空所有已经收到的投票，然后使用初始化的投票来进行PK以确定是否变更内部投票，最终再将内部投票发送出去</li><li>外部投票的选举轮次小于内部投票<br>如果接收到的选票的选举轮次落后于自己的，那么就直接忽略该外部投票</li><li>外部投票的选举轮次和内部投票一样<br>直接根据对比逻辑进行PK</li></ul><p>只有在统一选举轮次的投票才是有效的</p><ol><li>选票PK</li></ol><ul><li>如果外部投票中被推举的leader服务器的选举轮次大于内部投票，那么就进行投票变更。小于就忽略</li><li>如果投票轮次一样，就比较两者的SID。如果外部投票的ZXID大于内部投票，就进行投票变更。小于就不变</li><li>如果两者ZXID一样，那么就比对两者的SID。如果外部投票的SID大于内部投票，那么就需要进行投票变更。小于就忽略</li></ul><ol><li><p>变更投票<br>如果PK失败，那么就使用外部投票信息覆盖内部投票信息。变更完成后，再次将这个变更后的内部投票发送出去</p></li><li><p>选票归档<br>无论是否进行了投票更新，都会将刚刚收到的那部分外部投票放入“选票集合” recvset中进行归档。<br>recvset用于记录当前服务器在本轮次的leader选举中收到的所有外部投票，按照对应的SID来区分</p></li><li><p>完成了选票归档之后，就可以开始统计投票了。如果确定已经有过半的服务器认可了该内部投票，就终止投票。</p><blockquote><p>注：服务器发现有过半的服务器认可当前投票时，并不会立即更新服务器状态，而是等待一段时间（默认200毫秒）来确定是否有新的更优的投票</p></blockquote></li><li><p>更新服务器状态<br>终止投票后，就更新服务器状态。leader服务器更新状态为LEADING，follower服务器更新状态FOLLOWEING</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zookeeper的选举一：选举概述</title>
      <link href="/2017/11/02/zookeeper-3/"/>
      <url>/2017/11/02/zookeeper-3/</url>
      
        <content type="html"><![CDATA[<p>leader选举是zookeeper中最重要的技术之一，也是保证分布式数据一致性的关键所在。<br>我们主要从leader选举概述、算法分析和实现细节三个方面来看一下zookereper leader选举的过程。</p><h1 id="Zookeeper选举概述"><a href="#Zookeeper选举概述" class="headerlink" title="Zookeeper选举概述"></a>Zookeeper选举概述</h1><h2 id="服务器启动时leader的选举"><a href="#服务器启动时leader的选举" class="headerlink" title="服务器启动时leader的选举"></a>服务器启动时leader的选举</h2><p>以3台机器为例，当集群中启动一台机器的时候，是无法进行选举的，当第二台机器也启动后，此时这两台机器已经能相互通信，每台机器试图找到一个leader，于是便进入了leader选举流程。<br>1、每个Server会发出一个投票<br>  投票包含的最基本的元素包括：所推举的服务器的myid和ZXID，我们以（myid，ZXID）形式表示。初始阶段，无论是server1还是server2都会投给自己，即server1的选票（1，0），server2的选票（2，0），然后各自将这个投票发送给集群中其他所有机器。<br>2、接收来自各个服务器的投票<br>  每个服务器都会收到其他服务器的投票。收到投票后，首先判断该投票的有效性，包括检查是否是本轮投票、是否来自looking状态的服务器<br>3、处理投票<br>  在接收到来自其他服务器的投票后，针对每一个投票，服务器都需要将别人的投票和自己的投票进行PK。<br>  PK规则如下：<br>  优先检查ZXID。ZXID比较大的服务器优先作为leader。（选择ZXID大的服务器主要是省去了新的leader产生之后，删除其他服务器上比自己ZXID大Proposal(提议)）<br>  如果ZXID相同的话，那么就比较myid。myid比较大的服务器作为leader。</p><p>  按以上规则，server1的投票为（1，0），收到的server2投票为（2，0）；首先对比ZXID，都是0，然后对比myid，收到的投票myid为2，大于自己的，于是就会更新自己的投票为（2，0），然后重新将投票发出去。<br>  对于server2，不需要更新自己的投票信息，只是再一次向集群中所有机器发出上一次的投票信息即可。<br>4、统计投票<br>  每次投票后，服务器都会统计所有投票，判断是否已经有过半的机器接收到相同的投票信息。<br>  对于server1和server2服务器来说，都统计出集群中已经有两台机器接受了（2，0）这个投票信息。就是说集群中已经有过半的机器收到同样的选票（2，0），即可以认为已经选出了leader。<br>  过半：过半的意思是指大于集群机器数量的一半，即大于（n／2）。这也是zookeeper推举为奇数台的原因，3台允许出问题的机器为1台，4台允许出问题的机器也是1台（需要保证存活的机器大于4/2）；而且还增加了选主的时间。<br>5、一旦确定了leader，每个服务器都会更新自己的状态，如果是follower，更新为FOLLOWING，如果是leader，那么就更改为LEADING。</p><h2 id="服务器运行期间leader选举"><a href="#服务器运行期间leader选举" class="headerlink" title="服务器运行期间leader选举"></a>服务器运行期间leader选举</h2><p>在zookeeper集群正常运行时，一旦选出了一个leader，那么所有服务器的集群角色一般不会发生变化。但是一旦leader所在的机器挂了，那么整个集群将暂时无法对外服务，而是进行新一轮的leader选举。<br>服务器运行期间的leader选举和启动时期的leader选举基本一样。<br>假设当前zookeeper服务器为3台，分别为server1，server2，server3，当前leader为server2。假设某一瞬间，leader挂了，此时就开始leader选举。<br>1、首先是变更状态<br>  当leader挂了，余下的非Observer服务器会将自己的服务器状态变更为LOOKING，然后开始进入Leader选举流程<br>2、每个Server会发出一个投票<br>  每个需要投票的server都生成一个投票信息（myid，ZXID），由于是运行期间，因此每个服务器上的ZXID可能不同，假设server1的ZXID为100，而server3的ZXID为99。在第一轮投票中还是都投给自己，分别产生投票（1，100）和（3，99），然后各自将这个投票发送给集群中所有机器。<br>3、接收来自各自服务器的投票<br>4、处理投票<br>  根据上面的处理规则，由于server1的ZXID为100，大于server3的ZXID，那么server3会成为leader<br>5、统计投票<br>6、改变服务器状态</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zookeeper的选举二：Leader选举的算法分析</title>
      <link href="/2017/11/02/zookeeper-4/"/>
      <url>/2017/11/02/zookeeper-4/</url>
      
        <content type="html"><![CDATA[<h1 id="leader选举的算法分析"><a href="#leader选举的算法分析" class="headerlink" title="leader选举的算法分析"></a>leader选举的算法分析</h1><p>在zookeeper中有三种算法，分别是LeaderElection、UDP版本的FastLeaderElection和TCP版本的FastLeaderElection。不过3.4.0之后，就只保留了TCP版本的FastLeaderElection选举算法。<br>介绍FastLeaderElection选举算法算法之前，先对一些专业名次做一下解释。<br><strong>术语科普</strong></p><ul><li>SID：服务器ID<br>SID是一个数字，用来唯一标识一台zookeeper集群中的机器，每台机器不能重复，和myid的值一致。</li><li>ZXID：事务ID<br>ZXID是一个事务ID，用来唯一标识一次服务器状态的变更。在某一时刻，集群中每台机器的ZXID值不一定全都一样。</li><li>Vote：投票<br>leader选举通过投票实现。</li><li>Quorum：过半机器数<br>过半，就是大于集群中机器数的一半。<br>quorum = （n/2+1）</li></ul><h2 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a>算法分析</h2><p>什么情况下会进入leader选举？</p><ul><li>服务器初始化启动的时候</li><li>服务器运行期间无法和leader保持连接（leader挂掉的时候）</li></ul><p>当一台机器进入leader选举流程时，当前集群处于什么状态？</p><ul><li>集群中本来就已经存在一个leader</li><li>集群中确实不存在leader</li></ul><h1 id="开始一次完整的投票"><a href="#开始一次完整的投票" class="headerlink" title="开始一次完整的投票"></a>开始一次完整的投票</h1><p>假设zookeeper由5台机器组成，SID为1、2、3、4、5，ZXID为9、9、9、8、8，并且此时SID为2的机器是leader。某一时刻1、2所在的机器出现故障，集群开始leader选举。</p><blockquote><p>注：如果要当前机器要选举的SID为1，ZXID为9的服务器为leader，那么它的这次投票信息可以表示为（1，9）</p></blockquote><h2 id="第一次投票"><a href="#第一次投票" class="headerlink" title="第一次投票"></a>第一次投票</h2><p>第一次投票时，由于无法检测到集群中其他机器的状态信息，所以每台机器都会投自己。于是SID为3、4、5的机器，投票情况为（3，9）、（4、8）、（5，9）</p><h2 id="变更投票"><a href="#变更投票" class="headerlink" title="变更投票"></a>变更投票</h2><p>每台机器发出投票后，也会收到投票，根据一定规则，来处理其他机器的投票，并以此来决定是否需要更改自己的投票。<br><strong>术语科普</strong></p><ul><li>vote_sid：接收到的投票中所推举leader服务器的SID</li><li>vote_zxid：接收到的投票中所推举leader服务器的ZXID</li><li>self_sid：当前服务器自己的SID</li><li>self_zxid：当前服务器自己的ZXID</li></ul><p>每次对于收到的投票结果都是一个对（vote_sid,vote_zxid）和（self_sid，self_zxid）对比的过程</p><p><strong>对比规则</strong></p><ul><li>如果vote_zxid大于self_zxid，就认可当前收到的投票，（将自己的投票改投收到的SID），并再次将该投票发送出去</li><li>如果vote_zxid小于self_zxid，那么就坚持自己的投票，不做任何变更</li><li>如果vote_zxid等于self_zxid，那么就对比两者SID。vote_sid大于self_sid，就认可当前收到的投票（将自己的投票改投收到的SID），并再次将该投票发送出去</li><li>vote_sid小于self_sid，坚持自己的投票，不做任何变更</li></ul><p><strong>对应机器投票变更情况</strong></p><ul><li>对于server3（3，9）来说，收到（4，8）和（5，8）两个投票，对比后，由于自己的ZXID大于两者，因此不需要变更，最终还是坚持投票（3，9）</li><li>对于server4（4，8）来说，收到（3，9）和（5，8）两个投票，由于（3，9）这个投票的ZXID大于自己的ZXID，因此需要将投票变更为（3，9），然后继续将投票发送给另外两台机器。</li><li>对于server5 （5，8）来说，收到（3，9）和（4，8）两个投票，对比后，（3，9）这个投票的ZXID大于自己，一次需要变更投票为（3，9），然后继续将这个投票发送给另外两台机器</li></ul><h2 id="确定leader"><a href="#确定leader" class="headerlink" title="确定leader"></a>确定leader</h2><p>经过第二轮投票后，集群中的每台机器会再次收到其他机器的投票，然后开始统计投票。当一台机器收到来超过半数相同的投票，那么这个投票对应的SID机器即为leader。<br>这里，server3、server4、server5的投票都是（3，9），所以server3为leader</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>简单来说，就是那台机器的数据越新，就越有可能成为leader，数据越新，ZXID也就越大，也就能够保证数据的恢复。当然，如果集群中有几台服务器有相同的ZXID，那么SID较大的服务器会成为leader。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zookeeper核心算法ZAB</title>
      <link href="/2017/10/27/zookeeper-2/"/>
      <url>/2017/10/27/zookeeper-2/</url>
      
        <content type="html"><![CDATA[<h1 id="ZAB协议概述"><a href="#ZAB协议概述" class="headerlink" title="ZAB协议概述"></a>ZAB协议概述</h1><p>ZAB协议是为分布式协调服务Zookeeper专门设计的一种支持崩溃恢复的原子广播协议，Zookeeper中主要依赖ZAB协议来实现分布式数据一致性。Zookeeper使用一个单一的主进程来接收并处理客户端的所有事务请求，并采用ZAB的原子广播协议，将服务器数据的状态变更以事务Proposal的形式广播到所有的副本进程上去。<br>ZAB协议的核心是定义了对于那些会改变Zookeeper服务器数据状态的事务请求的处理方式，即：<br>所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为leader服务器，而余下的服务器称为follower服务器。leader服务器负责将一个客户端事务请求转换成一个事务Proposal（提议），并将该Proposal分发给集群中所有的follower服务器。之后leader服务器需要等待所有follower服务器的反馈，一旦超过半数的follower服务器进行了正确的反馈后，那么leader就会再次向所有的follower服务器分发commit消息，要求其将前一个Proposal进行提交。</p><h1 id="ZAB协议具体内容"><a href="#ZAB协议具体内容" class="headerlink" title="ZAB协议具体内容"></a>ZAB协议具体内容</h1><p>ZAB协议的具体内容，包括两种模式：崩溃模式和消息广播；<br>当整个服务框架在启动的过程中或是当leader服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB协议就会进入恢复模式并选举产生新的leader服务器。当选举产生了新的leader服务器，同时集群中已经有过半的机器与该leader服务器完成了状态同步（数据同步）之后，ZAB协议就会退出恢复模式。并进入消息广播模式。其中，所谓的状态同步就是指数据同步。<br>若有新的服务器加入集群时，如果此时集群中存在leader在负责消息广播，那么新加入的机器会进入数据恢复模式：找到leader，与leader进行数据同步，然后一起参与到消息广播流程中。<br>当leader服务器出现崩溃或集群中已经不存在过半的服务器与leader服务器保持正常通信时，所有机器首先会使用崩溃恢复协议来使彼此达到一个一致的状态，此时从消息广播模式进入崩溃恢复模式。</p><p>上面介绍了一下两种模式切换时的情况，接下来详细介绍一下这两种模式：</p><h2 id="消息广播"><a href="#消息广播" class="headerlink" title="消息广播"></a>消息广播</h2><p>客户端的事务请求，leader服务器为其生成对应的事务Proposal，并将其发送给其余的所有机器，然后再分别收集各自的选票，最后进行事务提交。</p><p><storage>消息广播的过程</storage></p><ol><li>leader服务器为每个事务请求生成对应的Proposal来进行广播</li><li>在广播事务Proposal之前，leader服务器会首先为这个事务Proposal分配一个全局单调递增的唯一ID，我们称为事务ID（即ZXID）。每一个事务Proposal会按照ZXID的先后顺序进行排序和处理</li><li>在消息广播过程中，leader服务器为每一个follower服务器各自分配一个单独的队列，将需要广播的事务Proposal依次放入这些队列中，并根据FIFO策略进行消息发送</li><li>每一个follower服务器在接收到这个事务Proposal之后，首先将其以事务日志的形式写入本地磁盘。</li><li>写入成功之后反馈给leader服务器一个ACK响应。</li><li>当leader服务器接收到超过半数follower（根据配置文件中配置的机器）的Ack响应后，就会广播一个Commit消息给所有的follower服务器以通知其进行事务提交，同时leader自己也会完成对事务的提交</li><li>每一个follower服务器在接收到Commit消息后，也会完成对事务的提交</li></ol><h2 id="崩溃恢复"><a href="#崩溃恢复" class="headerlink" title="崩溃恢复"></a>崩溃恢复</h2><h3 id="基本特征"><a href="#基本特征" class="headerlink" title="基本特征"></a>基本特征</h3><p>当leader服务器出现崩溃，或者由于网络原因导致leader服务器失去了与过半follower的联系，就会进入崩溃恢复模式；<br>在ZAB协议中，整个恢复过程结束后需要选举新的leader服务器。</p><p><storage>崩溃恢复中可能出现数据不一致的隐患：<storage></storage></storage></p><ol><li>ZAB协议需要确保那些已经在leader服务器上提交的事务最终被所有服务器都提交<br>假设一个Proposel（事务）在leader服务器上被提交了，并且已经得到过半follower服务器的Ack反馈，但是在它将commit消息发送给所有follower机器之前，leader服务器挂了。</li><li>ZAB协议需要确保丢弃那些只在leader服务器上被提出的事务<br>假设当leader服务器提出一个事务之后就崩溃退出来，从而导致集群中其他服务器都没有收到这个事务，于是当该服务器恢复过来再次加入集群的时候，ZAB协议需要确认丢弃这个事务。</li></ol><p>由于上面的两种情况，就需要ZAB协议设计这样一个leader选举算法：能够确保提交已经被leader提交的事务Proposal，同时丢弃已经被跳过的事务Proposal。<br>针对这个要求：<br>如果让leader选举算法能够保证新选举出来的leader服务器拥有集群中所有机器最高编号（即ZXID最大）的事务Proposal，那么就可以保证这个新选举出来的leader一定具有所有已经提交的提案。更重要的是，如果让具有最高编号事务Proposal的机器来成为leader，就可以省去leader服务器检查Proposal的提交和丢弃工作的操作了。</p><h3 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h3><p>在leader选举之后，正式开始工作（即接收客户端的事务请求，然后提出新的提案）之前，leader服务器会首先确认事务日志中的所有Proposal是否都已经被集群中过半的机器提交了（即是否完成数据同步）。</p><p><storage>ZAB协议的数据同步过程<storage></storage></storage></p><ol><li>leader服务器会为每一个follower服务器准备一个队列，并将那些没有被各follower服务器同步的事务以Proposal消息的形式逐个发送给follower服务器，并在每一个Proposal消息后紧接着再发送一个Commit消息，以表示该事务已经被提交</li><li>等到follower服务器将所有其尚未同步的事务Proposal都从leader服务器上同步过来并成功应用到本地数据库中之后，，leader服务器就会将该follower服务器加入到真正可用的follower列表中，并开始之后的其他流程</li></ol><p>上面是正常的数据同步逻辑，那么ZAB协议是如何处理那些需要被丢弃的事务Proposal呢？</p><p><storage>主要是基于ZAB协议的事务编号ZXID设计策略：</storage></p><ul><li>ZXID是一个64位的数字；</li><li>其中低32位可以看作一个简单的单调递增的计数器，针对客户端的每一个事务请求，leader服务器在产生一个新的事务Proposal的时候，都会对该计数器进行加1操作；</li><li>高32位则代表了leader周期epoch的编号，每当选举产生一个新的leader服务器，就会从这个leader服务器上取出其本地日志中最大的事务Proposal的ZXID，并从该ZXID中解析出对应的epoch值，然后再对其进行加1操作，之后就会以此编号作为新的epoch，并将低32位置为0，开始生成新的ZXID。</li><li>ZAB协议中就是通过epoch编号来区分leader周期变化的，这个策略能够有效避免不同的leader服务器错误的使用相同的ZXID编号提出不一样的事务Proposal的异常情况,这对于识别在leader崩溃恢复前后生成的Proposal非常有帮助，大大简化和提升了数据恢复流程</li><li>基于这样的策略，当一个包含了上一个leader周期中尚未提交过的事务Proposal的服务器启动后，其肯定无法成为leader。<br>原因很简单，因为当前集群中一定包含一个Quorum集合，该集合中的机器一定包含了更高epoch的事务Proposal，因此这台机器的事务Proposal肯定不是最高，也就无法成为leader。</li><li>当这台机器加入到集群中，以follower角色连接上leader服务器以后，leader服务器会根据自己服务器上最后被提交的Proposal来和follower服务器的Proposal进行比对，比对的结果当然是leader会要求follower进行回退操作（回退到一个确实已经被集群中过半机器提交的最新的事务Proposal）</li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka史上最详细原理总结</title>
      <link href="/2017/10/25/kafka-2/"/>
      <url>/2017/10/25/kafka-2/</url>
      
        <content type="html"><![CDATA[<p><storage><br>文章转自：<a href="http://www.itkeyword.com/doc/3033455819328241799/kafka-apache-scala" target="_blank" rel="noopener">http://www.itkeyword.com/doc/3033455819328241799/kafka-apache-scala</a><br></storage></p><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h1><p>Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编写，Linkedin于2010年贡献给了Apache基金会并成为顶级开源 项目。</p><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>消息队列的性能好坏，其文件存储机制设计是衡量一个消息队列服务技术水平和最关键指标之一。下面将从Kafka文件存储机制和物理结构角度，分析Kafka是如何实现高效文件存储，及实际应用效果。</p><h2 id="Kafka的特性"><a href="#Kafka的特性" class="headerlink" title="Kafka的特性:"></a>Kafka的特性:</h2><ol><li>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。</li><li>可扩展性：kafka集群支持热扩展</li><li>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</li><li>容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</li><li>高并发：支持数千个客户端同时读写</li></ol><h2 id="Kafka的使用场景："><a href="#Kafka的使用场景：" class="headerlink" title="Kafka的使用场景："></a>Kafka的使用场景：</h2><ol><li>日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。</li><li>消息系统：解耦和生产者和消费者、缓存消息等。</li><li>用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。</li><li>运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。</li><li>流式处理：比如spark streaming和storm</li><li>事件源</li></ol><h2 id="Kakfa的设计思想"><a href="#Kakfa的设计思想" class="headerlink" title="Kakfa的设计思想"></a>Kakfa的设计思想</h2><ul><li>Kakfa Broker Leader的选举：Kakfa Broker集群受Zookeeper管理。所有的Kafka Broker节点一起去Zookeeper上注册一个临时节点，因为只有一个Kafka Broker会注册成功，其他的都会失败，所以这个成功在Zookeeper上注册临时节点的这个Kafka Broker会成为Kafka Broker Controller，其他的Kafka broker叫Kafka Broker follower。（这个过程叫Controller在ZooKeeper注册Watch）。这个Controller会监听其他的Kafka Broker的所有信息，如果这个kafka broker controller宕机了，在zookeeper上面的那个临时节点就会消失，此时所有的kafka broker又会一起去Zookeeper上注册一个临时节点，因为只有一个Kafka Broker会注册成功，其他的都会失败，所以这个成功在Zookeeper上注册临时节点的这个Kafka Broker会成为Kafka Broker Controller，其他的Kafka broker叫Kafka Broker follower。例如：一旦有一个broker宕机了，这个kafka broker controller会读取该宕机broker上所有的partition在zookeeper上的状态，并选取ISR列表中的一个replica作为partition leader（如果ISR列表中的replica全挂，选一个幸存的replica作为leader; 如果该partition的所有的replica都宕机了，则将新的leader设置为-1，等待恢复，等待ISR中的任一个Replica“活”过来，并且选它作为Leader；或选择第一个“活”过来的Replica（不一定是ISR中的）作为Leader），这个broker宕机的事情，kafka controller也会通知zookeeper，zookeeper就会通知其他的kafka broker。<font color="#FF0000"><br>这里曾经发生过一个bug，TalkingData使用Kafka0.8.1的时候，kafka controller在Zookeeper上注册成功后，它和Zookeeper通信的timeout时间是6s，也就是如果kafka controller如果有6s中没有和Zookeeper做心跳，那么Zookeeper就认为这个kafka controller已经死了，就会在Zookeeper上把这个临时节点删掉，那么其他Kafka就会认为controller已经没了，就会再次抢着注册临时节点，注册成功的那个kafka broker成为controller，然后，之前的那个kafka controller就需要各种shut down去关闭各种节点和事件的监听。但是当kafka的读写流量都非常巨大的时候，TalkingData的一个bug是，由于网络等原因，kafka controller和Zookeeper有6s中没有通信，于是重新选举出了一个新的kafka controller，但是原来的controller在shut down的时候总是不成功，这个时候producer进来的message由于Kafka集群中存在两个kafka controller而无法落地。导致数据淤积。</font><br><font color="#FF0000">这里曾经还有一个bug，TalkingData使用Kafka0.8.1的时候，当ack=0的时候，表示producer发送出去message，只要对应的kafka broker topic partition leader接收到的这条message，producer就返回成功，不管partition leader 是否真的成功把message真正存到kafka。当ack=1的时候，表示producer发送出去message，同步的把message存到对应topic的partition的leader上，然后producer就返回成功，partition leader异步的把message同步到其他partition replica上。当ack=all或-1，表示producer发送出去message，同步的把message存到对应topic的partition的leader和对应的replica上之后，才返回成功。但是如果某个kafka controller 切换的时候，会导致partition leader的切换（老的 kafka controller上面的partition leader会选举到其他的kafka broker上）,但是这样就会导致丢数据。</font></li><li>Consumergroup：各个consumer（consumer 线程）可以组成一个组（Consumer group ），partition中的每个message只能被组（Consumer group ）中的一个consumer（consumer 线程）消费，如果一个message可以被多个consumer（consumer 线程）消费的话，那么这些consumer必须在不同的组。Kafka不支持一个partition中的message由两个或两个以上的同一个consumer group下的consumer thread来处理，除非再启动一个新的consumer group。所以如果想同时对一个topic做消费的话，启动多个consumer group就可以了，但是要注意的是，这里的多个consumer的消费都必须是顺序读取partition里面的message，新启动的consumer默认从partition队列最头端最新的地方开始阻塞的读message。它不能像AMQ那样可以多个BET作为consumer去互斥的（for update悲观锁）并发处理message，这是因为多个BET去消费一个Queue中的数据的时候，由于要保证不能多个线程拿同一条message，所以就需要行级别悲观所（for update）,这就导致了consume的性能下降，吞吐量不够。而kafka为了保证吞吐量，只允许同一个consumer group下的一个consumer线程去访问一个partition。如果觉得效率不高的时候，可以加partition的数量来横向扩展，那么再加新的consumer thread去消费。如果想多个不同的业务都需要这个topic的数据，起多个consumer group就好了，大家都是顺序的读取message，offsite的值互不影响。这样没有锁竞争，充分发挥了横向的扩展性，吞吐量极高。这也就形成了分布式消费的概念。<br> 当启动一个consumer group去消费一个topic的时候，无论topic里面有多个少个partition，无论我们consumer group里面配置了多少个consumer thread，这个consumer group下面的所有consumer thread一定会消费全部的partition；即便这个consumer group下只有一个consumer thread，那么这个consumer thread也会去消费所有的partition。因此，最优的设计就是，consumer group下的consumer thread的数量等于partition数量，这样效率是最高的。<br> 同一partition的一条message只能被同一个Consumer Group内的一个Consumer消费。不能够一个consumer group的多个consumer同时消费一个partition。<br> 一个consumer group下，无论有多少个consumer，这个consumer group一定回去把这个topic下所有的partition都消费了。当consumer group里面的consumer数量小于这个topic下的partition数量的时候，如下图groupA,groupB，就会出现一个conusmer thread消费多个partition的情况，总之是这个topic下的partition都会被消费。如果consumer group里面的consumer数量等于这个topic下的partition数量的时候，如下图groupC，此时效率是最高的，每个partition都有一个consumer thread去消费。当consumer group里面的consumer数量大于这个topic下的partition数量的时候，如下图GroupD，就会有一个consumer thread空闲。因此，我们在设定consumer group的时候，只需要指明里面有几个consumer数量即可，无需指定对应的消费partition序号，consumer会自动进行rebalance。<br> 多个Consumer Group下的consumer可以消费同一条message，但是这种消费也是以o（1）的方式顺序的读取message去消费,，所以一定会重复消费这批message的，不能向AMQ那样多个BET作为consumer消费（对message加锁，消费的时候不能重复消费message）</li><li>Consumer Rebalance的触发条件：（1）Consumer增加或删除会触发 Consumer Group的Rebalance（2）Broker的增加或者减少都会触发 Consumer Rebalance</li><li><p>Consumer： Consumer处理partition里面的message的时候是o（1）顺序读取的。所以必须维护着上一次读到哪里的offsite信息。high level API,offset存于Zookeeper中，low level API的offset由自己维护。一般来说都是使用high level api的。Consumer的delivery gurarantee，默认是读完message先commmit再处理message，autocommit默认是true，这时候先commit就会更新offsite+1，一旦处理失败，offsite已经+1，这个时候就会丢message；也可以配置成读完消息处理再commit，这种情况下consumer端的响应就会比较慢的，需要等处理完才行。<br>一般情况下，一定是一个consumer group处理一个topic的message。Best Practice是这个consumer group里面consumer的数量等于topic里面partition的数量，这样效率是最高的，一个consumer thread处理一个partition。如果这个consumer group里面consumer的数量小于topic里面partition的数量，就会有consumer thread同时处理多个partition（这个是kafka自动的机制，我们不用指定），但是总之这个topic里面的所有partition都会被处理到的。。如果这个consumer group里面consumer的数量大于topic里面partition的数量，多出的consumer thread就会闲着啥也不干，剩下的是一个consumer thread处理一个partition，这就造成了资源的浪费，因为一个partition不可能被两个consumer thread去处理。所以我们线上的分布式多个service服务，每个service里面的kafka consumer数量都小于对应的topic的partition数量，但是所有服务的consumer数量只和等于partition的数量，这是因为分布式service服务的所有consumer都来自一个consumer group，如果来自不同的consumer group就会处理重复的message了（同一个consumer group下的consumer不能处理同一个partition，不同的consumer group可以处理同一个topic，那么都是顺序处理message，一定会处理重复的。一般这种情况都是两个不同的业务逻辑，才会启动两个consumer group来处理一个topic）。</p><p>如果producer的流量增大，当前的topic的parition数量=consumer数量，这时候的应对方式就是很想扩展：增加topic下的partition，同时增加这个consumer group下的consumer。<br><img src="/images/kafka-2-1.png" alt=""></p></li><li><p>Delivery Mode : Kafka producer 发送message不用维护message的offsite信息，因为这个时候，offsite就相当于一个自增id，producer就尽管发送message就好了。而且Kafka与AMQ不同，AMQ大都用在处理业务逻辑上，而Kafka大都是日志，所以Kafka的producer一般都是大批量的batch发送message，向这个topic一次性发送一大批message，load balance到一个partition上，一起插进去，offsite作为自增id自己增加就好。但是Consumer端是需要维护这个partition当前消费到哪个message的offsite信息的，这个offsite信息，high level api是维护在Zookeeper上，low level api是自己的程序维护。（Kafka管理界面上只能显示high level api的consumer部分，因为low level api的partition offsite信息是程序自己维护，kafka是不知道的，无法在管理界面上展示 ）当使用high level api的时候，先拿message处理，再定时自动commit offsite+1（也可以改成手动）, 并且kakfa处理message是没有锁操作的。因此如果处理message失败，此时还没有commit offsite+1，当consumer thread重启后会重复消费这个message。但是作为高吞吐量高并发的实时处理系统，at least once的情况下，至少一次会被处理到，是可以容忍的。如果无法容忍，就得使用low level api来自己程序维护这个offsite信息，那么想什么时候commit offsite+1就自己搞定了。</p></li><li><p>Topic &amp; Partition：Topic相当于传统消息系统MQ中的一个队列queue，producer端发送的message必须指定是发送到哪个topic，但是不需要指定topic下的哪个partition，因为kafka会把收到的message进行load balance，均匀的分布在这个topic下的不同的partition上（ hash(message) % [broker数量]  ）。物理上存储上，这个topic会分成一个或多个partition，每个partiton相当于是一个子queue。在物理结构上，每个partition对应一个物理的目录（文件夹），文件夹命名是[topicname]<em>[partition]</em>[序号]，一个topic可以有无数多的partition，根据业务需求和数据量来设置。在kafka配置文件中可随时更高num.partitions参数来配置更改topic的partition数量，在创建Topic时通过参数指定parittion数量。Topic创建之后通过Kafka提供的工具也可以修改partiton数量。<br> 一般来说，（1）一个Topic的Partition数量大于等于Broker的数量，可以提高吞吐率。（2）同一个Partition的Replica尽量分散到不同的机器，高可用。<br>当add a new partition的时候，partition里面的message不会重新进行分配，原来的partition里面的message数据不会变，新加的这个partition刚开始是空的，随后进入这个topic的message就会重新参与所有partition的load balance</p></li><li>Partition Replica：每个partition可以在其他的kafka broker节点上存副本，以便某个kafka broker节点宕机不会影响这个kafka集群。存replica副本的方式是按照kafka broker的顺序存。例如有5个kafka broker节点，某个topic有3个partition，每个partition存2个副本，那么partition1存broker1,broker2，partition2存broker2,broker3。。。以此类推（replica副本数目不能大于kafka broker节点的数目，否则报错。这里的replica数其实就是partition的副本总数，其中包括一个leader，其他的就是copy副本）。这样如果某个broker宕机，其实整个kafka内数据依然是完整的。但是，replica副本数越高，系统虽然越稳定，但是回来带资源和性能上的下降；replica副本少的话，也会造成系统丢数据的风险。<br>（1）怎样传送消息：producer先把message发送到partition leader，再由leader发送给其他partition follower。（如果让producer发送给每个replica那就太慢了）<br>（2）在向Producer发送ACK前需要保证有多少个Replica已经收到该消息：根据ack配的个数而定<br>（3）怎样处理某个Replica不工作的情况：如果这个部工作的partition replica不在ack列表中，就是producer在发送消息到partition leader上，partition leader向partition follower发送message没有响应而已，这个不会影响整个系统，也不会有什么问题。如果这个不工作的partition replica在ack列表中的话，producer发送的message的时候会等待这个不工作的partition replca写message成功，但是会等到time out，然后返回失败因为某个ack列表中的partition replica没有响应，此时kafka会自动的把这个部工作的partition replica从ack列表中移除，以后的producer发送message的时候就不会有这个ack列表下的这个部工作的partition replica了。<br>（4）怎样处理Failed Replica恢复回来的情况：如果这个partition replica之前不在ack列表中，那么启动后重新受Zookeeper管理即可，之后producer发送message的时候，partition leader会继续发送message到这个partition follower上。如果这个partition replica之前在ack列表中，此时重启后，需要把这个partition replica再手动加到ack列表中。（ack列表是手动添加的，出现某个部工作的partition replica的时候自动从ack列表中移除的）</li><li>Partition leader与follower：partition也有leader和follower之分。leader是主partition，producer写kafka的时候先写partition leader，再由partition leader push给其他的partition follower。partition leader与follower的信息受Zookeeper控制，一旦partition leader所在的broker节点宕机，zookeeper会冲其他的broker的partition follower上选择follower变为parition leader。</li><li><p>Topic分配partition和partition replica的算法：（1）将Broker（size=n）和待分配的Partition排序。（2）将第i个Partition分配到第（i%n）个Broker上。（3）将第i个Partition的第j个Replica分配到第（(i + j) % n）个Broker上</p></li><li><p>消息投递可靠性<br>一个消息如何算投递成功，Kafka提供了三种模式：</p></li><li>第一种是啥都不管，发送出去就当作成功，这种情况当然不能保证消息成功投递到broker；</li><li>第二种是Master-Slave模型，只有当Master和所有Slave都接收到消息时，才算投递成功，这种模型提供了最高的投递可靠性，但是损伤了性能；</li><li><p>第三种模型，即只要Master确认收到消息就算投递成功；实际使用时，根据应用特性选择，绝大多数情况下都会中和可靠性和性能选择第三种模型<br>消息在broker上的可靠性，因为消息会持久化到磁盘上，所以如果正常stop一个broker，其上的数据不会丢失；但是如果不正常stop，可能会使存在页面缓存来不及写入磁盘的消息丢失，这可以通过配置flush页面缓存的周期、阈值缓解，但是同样会频繁的写磁盘会影响性能，又是一个选择题，根据实际情况配置。<br>消息消费的可靠性，Kafka提供的是“At least once”模型，因为消息的读取进度由offset提供，offset可以由消费者自己维护也可以维护在zookeeper里，但是当消息消费后consumer挂掉，offset没有即时写回，就有可能发生重复读的情况，这种情况同样可以通过调整commit offset周期、阈值缓解，甚至消费者自己把消费和commit offset做成一个事务解决，但是如果你的应用不在乎重复消费，那就干脆不要解决，以换取最大的性能。</p></li><li><p>Partition ack：当ack=1，表示producer写partition leader成功后，broker就返回成功，无论其他的partition follower是否写成功。当ack=2，表示producer写partition leader和其他一个follower成功的时候，broker就返回成功，无论其他的partition follower是否写成功。当ack=-1[parition的数量]的时候，表示只有producer全部写成功的时候，才算成功，kafka broker才返回成功信息。这里需要注意的是，如果ack=1的时候，一旦有个broker宕机导致partition的follower和leader切换，会导致丢数据。<br><img src="/images/kafka-2-2.png" alt=""></p></li><li><p>message状态：在Kafka中，消息的状态被保存在consumer中，broker不会关心哪个消息被消费了被谁消费了，只记录一个offset值（指向partition中下一个要被消费的消息位置），这就意味着如果consumer处理不好的话，broker上的一个消息可能会被消费多次。</p></li><li>message持久化：Kafka中会把消息持久化到本地文件系统中，并且保持o(1)极高的效率。我们众所周知IO读取是非常耗资源的性能也是最慢的，这就是为了数据库的瓶颈经常在IO上，需要换SSD硬盘的原因。但是Kafka作为吞吐量极高的MQ，却可以非常高效的message持久化到文件。这是因为Kafka是顺序写入o（1）的时间复杂度，速度非常快。也是高吞吐量的原因。由于message的写入持久化是顺序写入的，因此message在被消费的时候也是按顺序被消费的，保证partition的message是顺序消费的。一般的机器,单机每秒100k条数据。</li><li>message有效期：Kafka会长久保留其中的消息，以便consumer可以多次消费，当然其中很多细节是可配置的。</li><li>Produer : Producer向Topic发送message，不需要指定partition，直接发送就好了。kafka通过partition ack来控制是否发送成功并把信息返回给producer，producer可以有任意多的thread，这些kafka服务器端是不care的。Producer端的delivery guarantee默认是At least once的。也可以设置Producer异步发送实现At most once。Producer可以用主键幂等性实现Exactly once</li><li>Kafka高吞吐量： Kafka的高吞吐量体现在读写上，分布式并发的读和写都非常快，写的性能体现在以o(1)的时间复杂度进行顺序写入。读的性能体现在以o(1)的时间复杂度进行顺序读取， 对topic进行partition分区，consume group中的consume线程可以以很高能性能进行顺序读。</li><li>Kafka delivery guarantee(message传送保证)：（1）At most once消息可能会丢，绝对不会重复传输；（2）At least once 消息绝对不会丢，但是可能会重复传输；（3）Exactly once每条信息肯定会被传输一次且仅传输一次，这是用户想要的。</li><li>批量发送：Kafka支持以消息集合为单位进行批量发送，以提高push效率。</li><li>push-and-pull : Kafka中的Producer和consumer采用的是push-and-pull模式，即Producer只管向broker push消息，consumer只管从broker pull消息，两者对消息的生产和消费是异步的。</li><li>Kafka集群中broker之间的关系：不是主从关系，各个broker在集群中地位一样，我们可以随意的增加或删除任何一个broker节点。</li><li>负载均衡方面： Kafka提供了一个 metadata API来管理broker之间的负载（对Kafka0.8.x而言，对于0.7.x主要靠zookeeper来实现负载均衡）。</li><li>同步异步：Producer采用异步push方式，极大提高Kafka系统的吞吐率（可以通过参数控制是采用同步还是异步方式）。</li><li>分区机制partition：Kafka的broker端支持消息分区partition，Producer可以决定把消息发到哪个partition，在一个partition 中message的顺序就是Producer发送消息的顺序，一个topic中可以有多个partition，具体partition的数量是可配置的。partition的概念使得kafka作为MQ可以横向扩展，吞吐量巨大。partition可以设置replica副本，replica副本存在不同的kafka broker节点上，第一个partition是leader,其他的是follower，message先写到partition leader上，再由partition leader push到parition follower上。所以说kafka可以水平扩展，也就是扩展partition。</li><li>离线数据装载：Kafka由于对可拓展的数据持久化的支持，它也非常适合向Hadoop或者数据仓库中进行数据装载。</li><li>实时数据与离线数据：kafka既支持离线数据也支持实时数据，因为kafka的message持久化到文件，并可以设置有效期，因此可以把kafka作为一个高效的存储来使用，可以作为离线数据供后面的分析。当然作为分布式实时消息系统，大多数情况下还是用于实时的数据处理的，但是当cosumer消费能力下降的时候可以通过message的持久化在淤积数据在kafka。</li><li>插件支持：现在不少活跃的社区已经开发出不少插件来拓展Kafka的功能，如用来配合Storm、Hadoop、flume相关的插件。</li><li>解耦:  相当于一个MQ，使得Producer和Consumer之间异步的操作，系统之间解耦</li><li>冗余:  replica有多个副本，保证一个broker node宕机后不会影响整个服务</li><li>扩展性:  broker节点可以水平扩展，partition也可以水平增加，partition replica也可以水平增加</li><li>峰值:  在访问量剧增的情况下，kafka水平扩展, 应用仍然需要继续发挥作用</li><li>可恢复性:  系统的一部分组件失效时，由于有partition的replica副本，不会影响到整个系统。</li><li>顺序保证性：由于kafka的producer的写message与consumer去读message都是顺序的读写，保证了高效的性能。</li><li>缓冲：由于producer那面可能业务很简单，而后端consumer业务会很复杂并有数据库的操作，因此肯定是producer会比consumer处理速度快，如果没有kafka，producer直接调用consumer，那么就会造成整个系统的处理速度慢，加一层kafka作为MQ，可以起到缓冲的作用。</li><li>异步通信：作为MQ，Producer与Consumer异步通信</li></ul><h1 id="Kafka文件存储机制"><a href="#Kafka文件存储机制" class="headerlink" title="Kafka文件存储机制"></a>Kafka文件存储机制</h1><h2 id="Kafka部分名词解释如下："><a href="#Kafka部分名词解释如下：" class="headerlink" title="Kafka部分名词解释如下："></a>Kafka部分名词解释如下：</h2><ul><li>Kafka中发布订阅的对象是topic。我们可以为每类数据创建一个topic，把向topic发布消息的客户端称作producer，从topic订阅消息的客户端称作consumer。Producers和consumers可以同时从多个topic读写数据。一个kafka集群由一个或多个broker服务器组成，它负责持久化和备份具体的kafka消息。</li><li>Broker：Kafka节点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。</li><li>Topic：一类消息，消息存放的目录即主题，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。</li><li>Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列</li><li>Segment：partition物理上由多个segment组成，每个Segment存着message信息</li><li>Producer : 生产message发送到topic</li><li>Consumer : 订阅topic消费message, consumer作为一个线程来消费</li><li>Consumer Group：一个Consumer Group包含多个consumer, 这个是预先在配置文件中配置好的。各个consumer（consumer 线程）可以组成一个组（Consumer group ），partition中的每个message只能被组（Consumer group ） 中的一个consumer（consumer 线程 ）消费，如果一个message可以被多个consumer（consumer 线程 ） 消费的话，那么这些consumer必须在不同的组。Kafka不支持一个partition中的message由两个或两个以上的consumer thread来处理，即便是来自不同的consumer group的也不行。它不能像AMQ那样可以多个BET作为consumer去处理message，这是因为多个BET去消费一个Queue中的数据的时候，由于要保证不能多个线程拿同一条message，所以就需要行级别悲观所（for update）,这就导致了consume的性能下降，吞吐量不够。而kafka为了保证吞吐量，只允许一个consumer线程去访问一个partition。如果觉得效率不高的时候，可以加partition的数量来横向扩展，那么再加新的consumer thread去消费。这样没有锁竞争，充分发挥了横向的扩展性，吞吐量极高。这也就形成了分布式消费的概念。</li></ul><h2 id="kafka一些原理概念"><a href="#kafka一些原理概念" class="headerlink" title="kafka一些原理概念"></a>kafka一些原理概念</h2><p>1.持久化<br>kafka使用文件存储消息(append only log),这就直接决定kafka在性能上严重依赖文件系统的本身特性.且无论任何OS下,对文件系统本身的优化是非常艰难的.文件缓存/直接内存映射等是常用的手段.因为kafka是对日志文件进行append操作,因此磁盘检索的开支是较小的;同时为了减少磁盘写入的次数,broker会将消息暂时buffer起来,当消息的个数(或尺寸)达到一定阀值时,再flush到磁盘,这样减少了磁盘IO调用的次数.对于kafka而言,较高性能的磁盘,将会带来更加直接的性能提升.</p><p>2.性能<br>除磁盘IO之外,我们还需要考虑网络IO,这直接关系到kafka的吞吐量问题.kafka并没有提供太多高超的技巧;对于producer端,可以将消息buffer起来,当消息的条数达到一定阀值时,批量发送给broker;对于consumer端也是一样,批量fetch多条消息.不过消息量的大小可以通过配置文件来指定.对于kafka broker端,似乎有个sendfile系统调用可以潜在的提升网络IO的性能:将文件的数据映射到系统内存中,socket直接读取相应的内存区域即可,而无需进程再次copy和交换(这里涉及到”磁盘IO数据”/“内核内存”/“进程内存”/“网络缓冲区”,多者之间的数据copy).<br>其实对于producer/consumer/broker三者而言,CPU的开支应该都不大,因此启用消息压缩机制是一个良好的策略;压缩需要消耗少量的CPU资源,不过对于kafka而言,网络IO更应该需要考虑.可以将任何在网络上传输的消息都经过压缩.kafka支持gzip/snappy等多种压缩方式.</p><p>3.负载均衡<br>kafka集群中的任何一个broker,都可以向producer提供metadata信息,这些metadata中包含”集群中存活的servers列表”/“partitions leader列表”等信息(请参看zookeeper中的节点信息). 当producer获取到metadata信息之后, producer将会和Topic下所有partition leader保持socket连接;消息由producer直接通过socket发送到broker,中间不会经过任何”路由层”.<br>异步发送，将多条消息暂且在客户端buffer起来,并将他们批量发送到broker;小数据IO太多,会拖慢整体的网络延迟,批量延迟发送事实上提升了网络效率;不过这也有一定的隐患,比如当producer失效时,那些尚未发送的消息将会丢失。</p><p>4.Topic模型<br>其他JMS实现,消息消费的位置是有prodiver保留,以便避免重复发送消息或者将没有消费成功的消息重发等,同时还要控制消息的状态.这就要求JMS broker需要太多额外的工作.在kafka中,partition中的消息只有一个consumer在消费,且不存在消息状态的控制,也没有复杂的消息确认机制,可见kafka broker端是相当轻量级的.当消息被consumer接收之后,consumer可以在本地保存最后消息的offset,并间歇性的向zookeeper注册offset.由此可见,consumer客户端也很轻量级。<br>kafka中consumer负责维护消息的消费记录,而broker则不关心这些,这种设计不仅提高了consumer端的灵活性,也适度的减轻了broker端设计的复杂度;这是和众多JMS prodiver的区别.此外,kafka中消息ACK的设计也和JMS有很大不同,kafka中的消息是批量(通常以消息的条数或者chunk的尺寸为单位)发送给consumer,当消息消费成功后,向zookeeper提交消息的offset,而不会向broker交付ACK.或许你已经意识到,这种”宽松”的设计,将会有”丢失”消息/“消息重发”的危险.</p><p>5.消息传输一致<br>Kafka提供3种消息传输一致性语义：最多1次，最少1次，恰好1次。<br>最少1次：可能会重传数据，有可能出现数据被重复处理的情况;<br>最多1次：可能会出现数据丢失情况;<br>恰好1次：并不是指真正只传输1次，只不过有一个机制。确保不会出现“数据被重复处理”和“数据丢失”的情况。</p><p>at most once: 消费者fetch消息,然后保存offset,然后处理消息;当client保存offset之后,但是在消息处理过程中consumer进程失效(crash),导致部分消息未能继续处理.那么此后可能其他consumer会接管,但是因为offset已经提前保存,那么新的consumer将不能fetch到offset之前的消息(尽管它们尚没有被处理),这就是”at most once”.<br>at least once: 消费者fetch消息,然后处理消息,然后保存offset.如果消息处理成功之后,但是在保存offset阶段zookeeper异常或者consumer失效,导致保存offset操作未能执行成功,这就导致接下来再次fetch时可能获得上次已经处理过的消息,这就是”at least once”.<br>“Kafka Cluster”到消费者的场景中可以采取以下方案来得到“恰好1次”的一致性语义：<br>最少1次＋消费者的输出中额外增加已处理消息最大编号：由于已处理消息最大编号的存在，不会出现重复处理消息的情况。</p><p>6.副本<br>kafka中,replication策略是基于partition,而不是topic;kafka将每个partition数据复制到多个server上,任何一个partition有一个leader和多个follower(可以没有);备份的个数可以通过broker配置文件来设定。leader处理所有的read-write请求,follower需要和leader保持同步.Follower就像一个”consumer”,消费消息并保存在本地日志中;leader负责跟踪所有的follower状态,如果follower”落后”太多或者失效,leader将会把它从replicas同步列表中删除.当所有的follower都将一条消息保存成功,此消息才被认为是”committed”,那么此时consumer才能消费它,这种同步策略,就要求follower和leader之间必须具有良好的网络环境.即使只有一个replicas实例存活,仍然可以保证消息的正常发送和接收,只要zookeeper集群存活即可.<br>选择follower时需要兼顾一个问题,就是新leader server上所已经承载的partition leader的个数,如果一个server上有过多的partition leader,意味着此server将承受着更多的IO压力.在选举新leader,需要考虑到”负载均衡”,partition leader较少的broker将会更有可能成为新的leader.</p><p>7.log<br>每个log entry格式为”4个字节的数字N表示消息的长度” + “N个字节的消息内容”;每个日志都有一个offset来唯一的标记一条消息,offset的值为8个字节的数字,表示此消息在此partition中所处的起始位置..每个partition在物理存储层面,有多个log file组成(称为segment).segment file的命名为”最小offset”.kafka.例如”00000000000.kafka”;其中”最小offset”表示此segment中起始消息的offset.<br>获取消息时,需要指定offset和最大chunk尺寸,offset用来表示消息的起始位置,chunk size用来表示最大获取消息的总长度(间接的表示消息的条数).根据offset,可以找到此消息所在segment文件,然后根据segment的最小offset取差值,得到它在file中的相对位置,直接读取输出即可.<br><img src="/images/kafka-2-4.png" alt=""></p><p>8.分布式<br>kafka使用zookeeper来存储一些meta信息,并使用了zookeeper watch机制来发现meta信息的变更并作出相应的动作(比如consumer失效,触发负载均衡等)<br>Broker node registry: 当一个kafka broker启动后,首先会向zookeeper注册自己的节点信息(临时znode),同时当broker和zookeeper断开连接时,此znode也会被删除.<br>Broker Topic Registry: 当一个broker启动时,会向zookeeper注册自己持有的topic和partitions信息,仍然是一个临时znode.<br>Consumer and Consumer group: 每个consumer客户端被创建时,会向zookeeper注册自己的信息;此作用主要是为了”负载均衡”.一个group中的多个consumer可以交错的消费一个topic的所有partitions;简而言之,保证此topic的所有partitions都能被此group所消费,且消费时为了性能考虑,让partition相对均衡的分散到每个consumer上.<br>Consumer id Registry: 每个consumer都有一个唯一的ID(host:uuid,可以通过配置文件指定,也可以由系统生成),此id用来标记消费者信息.<br>Consumer offset Tracking: 用来跟踪每个consumer目前所消费的partition中最大的offset.此znode为持久节点,可以看出offset跟group_id有关,以表明当group中一个消费者失效,其他consumer可以继续消费.<br>Partition Owner registry: 用来标记partition正在被哪个consumer消费.临时znode。此节点表达了”一个partition”只能被group下一个consumer消费,同时当group下某个consumer失效,那么将会触发负载均衡(即:让partitions在多个consumer间均衡消费,接管那些”游离”的partitions)<br>当consumer启动时,所触发的操作:<br>A) 首先进行”Consumer id Registry”;<br>B) 然后在”Consumer id Registry”节点下注册一个watch用来监听当前group中其他consumer的”leave”和”join”;只要此znode path下节点列表变更,都会触发此group下consumer的负载均衡.(比如一个consumer失效,那么其他consumer接管partitions).<br>C) 在”Broker id registry”节点下,注册一个watch用来监听broker的存活情况;如果broker列表变更,将会触发所有的groups下的consumer重新balance.</p><p>总结:<br>1) Producer端使用zookeeper用来”发现”broker列表,以及和Topic下每个partition leader建立socket连接并发送消息.<br>2) Broker端使用zookeeper用来注册broker信息,已经监测partition leader存活性.<br>3) Consumer端使用zookeeper用来注册consumer信息,其中包括consumer消费的partition列表等,同时也用来发现broker列表,并和partition leader建立socket连接,并获取消息。</p><p>9.Leader的选择<br>Kafka的核心是日志文件，日志文件在集群中的同步是分布式数据系统最基础的要素。<br>如果leaders永远不会down的话我们就不需要followers了！一旦leader down掉了，需要在followers中选择一个新的leader.但是followers本身有可能延时太久或者crash，所以必须选择高质量的follower作为leader.必须保证，一旦一个消息被提交了，但是leader down掉了，新选出的leader必须可以提供这条消息。大部分的分布式系统采用了多数投票法则选择新的leader,对于多数投票法则，就是根据所有副本节点的状况动态的选择最适合的作为leader.Kafka并不是使用这种方法。<br>Kafka动态维护了一个同步状态的副本的集合（a set of in-sync replicas），简称ISR，在这个集合中的节点都是和leader保持高度一致的，任何一条消息必须被这个集合中的每个节点读取并追加到日志中了，才回通知外部这个消息已经被提交了。因此这个集合中的任何一个节点随时都可以被选为leader.ISR在ZooKeeper中维护。ISR中有f+1个节点，就可以允许在f个节点down掉的情况下不会丢失消息并正常提供服。ISR的成员是动态的，如果一个节点被淘汰了，当它重新达到“同步中”的状态时，他可以重新加入ISR.这种leader的选择方式是非常快速的，适合kafka的应用场景。<br>一个邪恶的想法：如果所有节点都down掉了怎么办？Kafka对于数据不会丢失的保证，是基于至少一个节点是存活的，一旦所有节点都down了，这个就不能保证了。<br>实际应用中，当所有的副本都down掉时，必须及时作出反应。可以有以下两种选择:</p><ol><li>等待ISR中的任何一个节点恢复并担任leader。</li><li>选择所有节点中（不只是ISR）第一个恢复的节点作为leader.<br>这是一个在可用性和连续性之间的权衡。如果等待ISR中的节点恢复，一旦ISR中的节点起不起来或者数据都是了，那集群就永远恢复不了了。如果等待ISR意外的节点恢复，这个节点的数据就会被作为线上数据，有可能和真实的数据有所出入，因为有些数据它可能还没同步到。Kafka目前选择了第二种策略，在未来的版本中将使这个策略的选择可配置，可以根据场景灵活的选择。<br>这种窘境不只Kafka会遇到，几乎所有的分布式数据系统都会遇到。</li></ol><p>10.副本管理<br>以上仅仅以一个topic一个分区为例子进行了讨论，但实际上一个Kafka将会管理成千上万的topic分区.Kafka尽量的使所有分区均匀的分布到集群所有的节点上而不是集中在某些节点上，另外主从关系也尽量均衡这样每个几点都会担任一定比例的分区的leader.<br>优化leader的选择过程也是很重要的，它决定了系统发生故障时的空窗期有多久。Kafka选择一个节点作为“controller”,当发现有节点down掉的时候它负责在游泳分区的所有节点中选择新的leader,这使得Kafka可以批量的高效的管理所有分区节点的主从关系。如果controller down掉了，活着的节点中的一个会备切换为新的controller.</p><p>11.Leader与副本同步<br>对于某个分区来说，保存正分区的”broker”为该分区的”leader”，保存备份分区的”broker”为该分区的”follower”。备份分区会完全复制正分区的消息，包括消息的编号等附加属性值。为了保持正分区和备份分区的内容一致，Kafka采取的方案是在保存备份分区的”broker”上开启一个消费者进程进行消费，从而使得正分区的内容与备份分区的内容保持一致。一般情况下，一个分区有一个“正分区”和零到多个“备份分区”。可以配置“正分区+备份分区”的总数量，关于这个配置，不同主题可以有不同的配置值。注意，生产者，消费者只与保存正分区的”leader”进行通信。</p><p>Kafka允许topic的分区拥有若干副本，这个数量是可以配置的，你可以为每个topic配置副本的数量。Kafka会自动在每个副本上备份数据，所以当一个节点down掉时数据依然是可用的。<br>Kafka的副本功能不是必须的，你可以配置只有一个副本，这样其实就相当于只有一份数据。<br>创建副本的单位是topic的分区，每个分区都有一个leader和零或多个followers.所有的读写操作都由leader处理，一般分区的数量都比broker的数量多的多，各分区的leader均匀的分布在brokers中。所有的followers都复制leader的日志，日志中的消息和顺序都和leader中的一致。followers向普通的consumer那样从leader那里拉取消息并保存在自己的日志文件中。<br>许多分布式的消息系统自动的处理失败的请求，它们对一个节点是否着（alive）”有着清晰的定义。Kafka判断一个节点是否活着有两个条件：</p><ol><li>节点必须可以维护和ZooKeeper的连接，Zookeeper通过心跳机制检查每个节点的连接。</li><li>如果节点是个follower,他必须能及时的同步leader的写操作，延时不能太久。<br>符合以上条件的节点准确的说应该是“同步中的（in sync）”，而不是模糊的说是“活着的”或是“失败的”。Leader会追踪所有“同步中”的节点，一旦一个down掉了，或是卡住了，或是延时太久，leader就会把它移除。至于延时多久算是“太久”，是由参数replica.lag.max.messages决定的，怎样算是卡住了，怎是由参数replica.lag.time.max.ms决定的。<br>只有当消息被所有的副本加入到日志中时，才算是“committed”，只有committed的消息才会发送给consumer，这样就不用担心一旦leader down掉了消息会丢失。Producer也可以选择是否等待消息被提交的通知，这个是由参数acks决定的。<br>Kafka保证只要有一个“同步中”的节点，“committed”的消息就不会丢失。</li></ol><p><img src="/images/kafka-2-5.png" alt=""></p><h2 id="kafka拓扑结构"><a href="#kafka拓扑结构" class="headerlink" title="kafka拓扑结构"></a>kafka拓扑结构</h2><p>一个典型的Kafka集群中包含若干Producer（可以是web前端FET，或者是服务器日志等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干ConsumerGroup，以及一个Zookeeper集群。Kafka通过Zookeeper管理Kafka集群配置：选举Kafka broker的leader，以及在Consumer Group发生变化时进行rebalance，因为consumer消费kafka topic的partition的offsite信息是存在Zookeeper的。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。</p><p>分析过程分为以下4个步骤：</p><p>topic中partition存储分布<br>partiton中文件存储方式 (partition在linux服务器上就是一个目录（文件夹）)<br>partiton中segment文件存储结构<br>在partition中如何通过offset查找message<br>通过上述4过程详细分析，我们就可以清楚认识到kafka文件存储机制的奥秘。</p><h2 id="topic中partition存储分布"><a href="#topic中partition存储分布" class="headerlink" title="topic中partition存储分布"></a>topic中partition存储分布</h2><p>假设实验环境中Kafka集群只有一个broker，xxx/message-folder为数据文件存储根目录，在Kafka broker中server.properties文件配置(参数log.dirs=xxx/message-folder)，例如创建2个topic名 称分别为report_push、launch_info, partitions数量都为partitions=4</p><p>存储路径和目录规则为：</p><p>xxx/message-folder</p><p>  |–report_push-0<br>  |–report_push-1<br>  |–report_push-2<br>  |–report_push-3<br>  |–launch_info-0<br>  |–launch_info-1<br>  |–launch_info-2<br>  |–launch_info-3</p><p>在Kafka文件存储中，同一个topic下有多个不同partition，每个partition为一个目录，partiton命名规则为topic名称+有序序号，第一个partiton序号从0开始，序号最大值为partitions数量减1。<br>消息发送时都被发送到一个topic，其本质就是一个目录，而topic由是由一些Partition组成,其组织结构如下图所示：</p><p>我们可以看到，Partition是一个Queue的结构，每个Partition中的消息都是有序的，生产的消息被不断追加到Partition上，其中的每一个消息都被赋予了一个唯一的offset值。</p><p>Kafka集群会保存所有的消息，不管消息有没有被消费；我们可以设定消息的过期时间，只有过期的数据才会被自动清除以释放磁盘空间。比如我们设置消息过期时间为2天，那么这2天内的所有消息都会被保存到集群中，数据只有超过了两天才会被清除。</p><p>Kafka只维护在Partition中的offset值，因为这个offsite标识着这个partition的message消费到哪条了。Consumer每消费一个消息，offset就会加1。其实消息的状态完全是由Consumer控制的，Consumer可以跟踪和重设这个offset值，这样的话Consumer就可以读取任意位置的消息。</p><p>把消息日志以Partition的形式存放有多重考虑，第一，方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；第二就是可以提高并发，因为可以以Partition为单位读写了。</p><p>通过上面介绍的我们可以知道，kafka中的数据是持久化的并且能够容错的。Kafka允许用户为每个topic设置副本数量，副本数量决定了有几个broker来存放写入的数据。如果你的副本数量设置为3，那么一份数据就会被存放在3台不同的机器上，那么就允许有2个机器失败。一般推荐副本数量至少为2，这样就可以保证增减、重启机器时不会影响到数据消费。如果对数据持久化有更高的要求，可以把副本数量设置为3或者更多。</p><p>Kafka中的topic是以partition的形式存放的，每一个topic都可以设置它的partition数量，Partition的数量决定了组成topic的message的数量。Producer在生产数据时，会按照一定规则（这个规则是可以自定义的）把消息发布到topic的各个partition中。上面将的副本都是以partition为单位的，不过只有一个partition的副本会被选举成leader作为读写用。</p><p>关于如何设置partition值需要考虑的因素。一个partition只能被一个消费者消费（一个消费者可以同时消费多个partition），因此，如果设置的partition的数量小于consumer的数量，就会有消费者消费不到数据。所以，推荐partition的数量一定要大于同时运行的consumer的数量。另外一方面，建议partition的数量大于集群broker的数量，这样leader partition就可以均匀的分布在各个broker中，最终使得集群负载均衡。在Cloudera,每个topic都有上百个partition。需要注意的是，kafka需要为每个partition分配一些内存来缓存消息数据，如果partition数量越大，就要为kafka分配更大的heap space。</p><h2 id="partiton中文件存储方式"><a href="#partiton中文件存储方式" class="headerlink" title="partiton中文件存储方式"></a>partiton中文件存储方式</h2><p>Kafka文件存储机制那些事<br>每个partion(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。<br>每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。<br>这样做的好处就是能快速删除无用文件，有效提高磁盘利用率。<br><img src="/images/kafka-2-6.png" alt=""></p><h2 id="partiton中segment文件存储结构"><a href="#partiton中segment文件存储结构" class="headerlink" title="partiton中segment文件存储结构"></a>partiton中segment文件存储结构</h2><p>producer发message到某个topic，message会被均匀的分布到多个partition上（随机或根据用户指定的回调函数进行分布），kafka broker收到message往对应partition的最后一个segment上添加该消息，当某个segment上的消息条数达到配置值或消息发布时间超过阈值时，segment上的消息会被flush到磁盘，只有flush到磁盘上的消息consumer才能消费，segment达到一定的大小后将不会再往该segment写数据，broker会创建新的segment。</p><p>每个part在内存中对应一个index，记录每个segment中的第一条消息偏移。<br>segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件.<br>segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个全局partion的最大offset(偏移message数)。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。</p><p>每个segment中存储很多条消息，消息id由其逻辑位置决定，即从消息id可直接定位到消息的存储位置，避免id到位置的额外映射。<br>下面文件列表是笔者在Kafka broker上做的一个实验，创建一个topicXXX包含1 partition，设置每个segment大小为500MB,并启动producer向Kafka broker写入大量数据,如下图2所示segment文件列表形象说明了上述2个规则：<br><img src="/images/kafka-2-7.png" alt=""><br>Kafka文件存储机制那些事</p><p>以上述图2中一对segment file文件为例，说明segment中index&lt;—-&gt;data file对应关系物理结构如下：</p><p>Kafka文件存储机制那些事</p><p>上述图3中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中message的物理偏移地址。其中以索引文件中 元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton表示第368772个message)、以及该消息的物理偏移 地址为497。</p><p>从上述图3了解到segment data file由许多message组成，下面详细说明message物理结构如下：<br><img src="/images/kafka-2-8.png" alt=""><br>Kafka文件存储机制那些事</p><p>参数说明：<br><img src="/images/kafka-2-13.png" alt=""></p><h2 id="在partition中如何通过offset查找message"><a href="#在partition中如何通过offset查找message" class="headerlink" title="在partition中如何通过offset查找message"></a>在partition中如何通过offset查找message</h2><p>例如读取offset=368776的message，需要通过下面2个步骤查找。</p><p>第一步查找segment file</p><p>上述图2为例，其中00000000000000000000.index表示最开始的文件，起始偏移量(offset)为0.第二个文件 00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.同样，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1，其他后续文件依次类推，以起始偏移量命名并排序这些文件，只要根据offset<strong>二分查找</strong>文件列表，就可以快速定位到具体文件。</p><p>当offset=368776时定位到00000000000000368769.index|log</p><p>第二步通过segment file查找message通过第一步定位到segment file，当offset=368776时，依次定位到00000000000000368769.index的元数据物理位置和 00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到 offset=368776为止。</p><p>segment index file采取稀疏索引存储方式，它减少索引文件大小，通过mmap可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,它 比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。</p><p>kafka会记录offset到zk中。但是，zk client api对zk的频繁写入是一个低效的操作。0.8.2 kafka引入了native offset storage，将offset管理从zk移出，并且可以做到水平扩展。其原理就是利用了kafka的compacted topic，offset以consumer group,topic与partion的组合作为key直接提交到compacted topic中。同时Kafka又在内存中维护了的三元组来维护最新的offset信息，consumer来取最新offset信息的时候直接内存里拿即可。当然，kafka允许你快速的checkpoint最新的offset信息到磁盘上。</p><h1 id="Partition-Replication原则"><a href="#Partition-Replication原则" class="headerlink" title="Partition Replication原则"></a>Partition Replication原则</h1><p>Kafka高效文件存储设计特点</p><p>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。<br>通过索引信息可以快速定位message和确定response的最大大小。<br>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。<br>通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。</p><h2 id="Kafka集群partition-replication默认自动分配分析"><a href="#Kafka集群partition-replication默认自动分配分析" class="headerlink" title="Kafka集群partition replication默认自动分配分析"></a>Kafka集群partition replication默认自动分配分析</h2><p>下面以一个Kafka集群中4个Broker举例，创建1个topic包含4个Partition，2 Replication；数据Producer流动如图所示：<br>(1)<br><img src="/images/kafka-2-9.png" alt=""></p><p>(2)当集群中新增2节点，Partition增加到6个时分布情况如下：<br><img src="/images/kafka-2-10.png" alt=""></p><p>副本分配逻辑规则如下：<br>在Kafka集群中，每个Broker都有均等分配Partition的Leader机会。<br>上述图Broker Partition中，箭头指向为副本，以Partition-0为例:broker1中parition-0为Leader，Broker2中Partition-0为副本。<br>上述图种每个Broker(按照BrokerId有序)依次分配主Partition,下一个Broker为副本，如此循环迭代分配，多副本都遵循此规则。</p><p>副本分配算法如下：<br>将所有N Broker和待分配的i个Partition排序.<br>将第i个Partition分配到第(i mod n)个Broker上.<br>将第i个Partition的第j个副本分配到第((i + j) mod n)个Broker上.</p><h1 id="Kafka-Broker一些特性"><a href="#Kafka-Broker一些特性" class="headerlink" title="Kafka Broker一些特性"></a>Kafka Broker一些特性</h1><h2 id="无状态的Kafka-Broker"><a href="#无状态的Kafka-Broker" class="headerlink" title="无状态的Kafka Broker :"></a>无状态的Kafka Broker :</h2><ol><li>Broker没有副本机制，一旦broker宕机，该broker的消息将都不可用。</li><li>Broker不保存订阅者的状态，由订阅者自己保存。</li><li>无状态导致消息的删除成为难题（可能删除的消息正在被订阅），kafka采用基于时间的SLA(服务水平保证)，消息保存一定时间（通常为7天）后会被删除。</li><li>消息订阅者可以rewind back到任意位置重新进行消费，当订阅者故障时，可以选择最小的offset进行重新读取消费消息。</li></ol><h2 id="message的交付与生命周期-："><a href="#message的交付与生命周期-：" class="headerlink" title="message的交付与生命周期 ："></a>message的交付与生命周期 ：</h2><ol><li>不是严格的JMS， 因此kafka对消息的重复、丢失、错误以及顺序型没有严格的要求。（这是与AMQ最大的区别）</li><li>kafka提供at-least-once delivery,即当consumer宕机后，有些消息可能会被重复delivery。</li><li>因每个partition只会被consumer group内的一个consumer消费，故kafka保证每个partition内的消息会被顺序的订阅。</li><li>Kafka为每条消息为每条消息计算CRC校验，用于错误检测，crc校验不通过的消息会直接被丢弃掉。</li></ol><h2 id="压缩"><a href="#压缩" class="headerlink" title="压缩"></a>压缩</h2><p>Kafka支持以集合（batch）为单位发送消息，在此基础上，Kafka还支持对消息集合进行压缩，Producer端可以通过GZIP或Snappy格式对消息集合进行压缩。Producer端进行压缩之后，在Consumer端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大数据处理上，瓶颈往往体现在网络上而不是CPU。</p><p>那么如何区分消息是压缩的还是未压缩的呢，Kafka在消息头部添加了一个描述压缩属性字节，这个字节的后两位表示消息的压缩采用的编码，如果后两位为0，则表示消息未被压缩。</p><h2 id="消息可靠性"><a href="#消息可靠性" class="headerlink" title="消息可靠性"></a>消息可靠性</h2><p>在消息系统中，保证消息在生产和消费过程中的可靠性是十分重要的，在实际消息传递过程中，可能会出现如下三中情况：</p><ul><li><p>一个消息发送失败</p></li><li><p>一个消息被发送多次</p></li><li><p>最理想的情况：exactly-once ,一个消息发送成功且仅发送了一次</p></li></ul><p>有许多系统声称它们实现了exactly-once，但是它们其实忽略了生产者或消费者在生产和消费过程中有可能失败的情况。比如虽然一个Producer成功发送一个消息，但是消息在发送途中丢失，或者成功发送到broker，也被consumer成功取走，但是这个consumer在处理取过来的消息时失败了。</p><p>从Producer端看：Kafka是这么处理的，当一个消息被发送后，Producer会等待broker成功接收到消息的反馈（可通过参数控制等待时间），如果消息在途中丢失或是其中一个broker挂掉，Producer会重新发送（我们知道Kafka有备份机制，可以通过参数控制是否等待所有备份节点都收到消息）。</p><p>从Consumer端看：前面讲到过partition，broker端记录了partition中的一个offset值，这个值指向Consumer下一个即将消费message。当Consumer收到了消息，但却在处理过程中挂掉，此时Consumer可以通过这个offset值重新找到上一个消息再进行处理。Consumer还有权限控制这个offset值，对持久化到broker端的消息做任意处理。</p><h2 id="备份机制"><a href="#备份机制" class="headerlink" title="备份机制"></a>备份机制</h2><p>备份机制是Kafka0.8版本的新特性，备份机制的出现大大提高了Kafka集群的可靠性、稳定性。有了备份机制后，Kafka允许集群中的节点挂掉后而不影响整个集群工作。一个备份数量为n的集群允许n-1个节点失败。在所有备份节点中，有一个节点作为lead节点，这个节点保存了其它备份节点列表，并维持各个备份间的状体同步。下面这幅图解释了Kafka的备份机制:<br><img src="/images/kafka-2-11.png" alt=""></p><h2 id="Kafka高效性相关设计"><a href="#Kafka高效性相关设计" class="headerlink" title="Kafka高效性相关设计"></a>Kafka高效性相关设计</h2><p>4.6.1 消息的持久化<br>Kafka高度依赖文件系统来存储和缓存消息(AMQ的nessage是持久化到mysql数据库中的)，因为一般的人认为磁盘是缓慢的，这导致人们对持久化结构具有竞争性持怀疑态度。其实，磁盘的快或者慢，这决定于我们如何使用磁盘。因为磁盘线性写的速度远远大于随机写。线性读写在大多数应用场景下是可以预测的。<br>4.6.2 常数时间性能保证<br>每个Topic的Partition的是一个大文件夹，里面有无数个小文件夹segment，但partition是一个队列，队列中的元素是segment,消费的时候先从第0个segment开始消费，新来message存在最后一个消息队列中。对于segment也是对队列，队列元素是message,有对应的offsite标识是哪个message。消费的时候先从这个segment的第一个message开始消费，新来的message存在segment的最后。</p><p>消息系统的持久化队列可以构建在对一个文件的读和追加上，就像一般情况下的日志解决方案。它有一个优点，所有的操作都是常数时间，并且读写之间不会相互阻塞。这种设计具有极大的性能优势：最终系统性能和数据大小完全无关，服务器可以充分利用廉价的硬盘来提供高效的消息服务。</p><p>事实上还有一点，磁盘空间的无限增大而不影响性能这点，意味着我们可以提供一般消息系统无法提供的特性。比如说，消息被消费后不是立马被删除，我们可以将这些消息保留一段相对比较长的时间（比如一个星期）。</p><h1 id="Kafka-生产者-消费者"><a href="#Kafka-生产者-消费者" class="headerlink" title="Kafka 生产者-消费者"></a>Kafka 生产者-消费者</h1><p>消息系统通常都会由生产者，消费者，Broker三大部分组成，生产者会将消息写入到Broker，消费者会从Broker中读取出消息，不同的MQ实现的Broker实现会有所不同，不过Broker的本质都是要负责将消息落地到服务端的存储系统中。具体步骤如下：</p><p>生产者客户端应用程序产生消息：<br>客户端连接对象将消息包装到请求中发送到服务端<br>服务端的入口也有一个连接对象负责接收请求，并将消息以文件的形式存储起来<br>服务端返回响应结果给生产者客户端</p><p>消费者客户端应用程序消费消息：<br>客户端连接对象将消费信息也包装到请求中发送给服务端<br>服务端从文件存储系统中取出消息<br>服务端返回响应结果给消费者客户端<br>客户端将响应结果还原成消息并开始处理消息</p><h2 id="Producers"><a href="#Producers" class="headerlink" title="Producers"></a>Producers</h2><p>Producers直接发送消息到broker上的leader partition，不需要经过任何中介或其他路由转发。为了实现这个特性，kafka集群中的每个broker都可以响应producer的请求，并返回topic的一些元信息，这些元信息包括哪些机器是存活的，topic的leader partition都在哪，现阶段哪些leader partition是可以直接被访问的。</p><p>Producer客户端自己控制着消息被推送到哪些partition。实现的方式可以是随机分配、实现一类随机负载均衡算法，或者指定一些分区算法。Kafka提供了接口供用户实现自定义的partition，用户可以为每个消息指定一个partitionKey，通过这个key来实现一些hash分区算法。比如，把userid作为partitionkey的话，相同userid的消息将会被推送到同一个partition。</p><p>以Batch的方式推送数据可以极大的提高处理效率，kafka Producer 可以将消息在内存中累计到一定数量后作为一个batch发送请求。Batch的数量大小可以通过Producer的参数控制，参数值可以设置为累计的消息的数量（如500条）、累计的时间间隔（如100ms）或者累计的数据大小(64KB)。通过增加batch的大小，可以减少网络请求和磁盘IO的次数，当然具体参数设置需要在效率和时效性方面做一个权衡。</p><p>Producers可以异步的并行的向kafka发送消息，但是通常producer在发送完消息之后会得到一个future响应，返回的是offset值或者发送过程中遇到的错误。这其中有个非常重要的参数“acks”,这个参数决定了producer要求leader partition 收到确认的副本个数，如果acks设置数量为0，表示producer不会等待broker的响应，所以，producer无法知道消息是否发送成功，这样有可能会导致数据丢失，但同时，acks值为0会得到最大的系统吞吐量。</p><p>若acks设置为1，表示producer会在leader partition收到消息时得到broker的一个确认，这样会有更好的可靠性，因为客户端会等待直到broker确认收到消息。若设置为-1，producer会在所有备份的partition收到消息时得到broker的确认，这个设置可以得到最高的可靠性保证。</p><p>Kafka 消息有一个定长的header和变长的字节数组组成。因为kafka消息支持字节数组，也就使得kafka可以支持任何用户自定义的序列号格式或者其它已有的格式如Apache Avro、protobuf等。Kafka没有限定单个消息的大小，但我们推荐消息大小不要超过1MB,通常一般消息大小都在1~10kB之前。</p><p>发布消息时，kafka client先构造一条消息，将消息加入到消息集set中（kafka支持批量发布，可以往消息集合中添加多条消息，一次行发布），send消息时，producer client需指定消息所属的topic。</p><h2 id="Consumers"><a href="#Consumers" class="headerlink" title="Consumers"></a>Consumers</h2><p>Kafka提供了两套consumer api，分为high-level api和sample-api。Sample-api 是一个底层的API，它维持了一个和单一broker的连接，并且这个API是完全无状态的，每次请求都需要指定offset值，因此，这套API也是最灵活的。</p><p>在kafka中，当前读到哪条消息的offset值是由consumer来维护的，因此，consumer可以自己决定如何读取kafka中的数据。比如，consumer可以通过重设offset值来重新消费已消费过的数据。不管有没有被消费，kafka会保存数据一段时间，这个时间周期是可配置的，只有到了过期时间，kafka才会删除这些数据。（这一点与AMQ不一样，AMQ的message一般来说都是持久化到mysql中的，消费完的message会被delete掉）</p><p>High-level API封装了对集群中一系列broker的访问，可以透明的消费一个topic。它自己维持了已消费消息的状态，即每次消费的都是下一个消息。</p><p>High-level API还支持以组的形式消费topic，如果consumers有同一个组名，那么kafka就相当于一个队列消息服务，而各个consumer均衡的消费相应partition中的数据。若consumers有不同的组名，那么此时kafka就相当与一个广播服务，会把topic中的所有消息广播到每个consumer。</p><p>High level api和Low level api是针对consumer而言的，和producer无关。</p><p>High level api是consumer读的partition的offsite是存在zookeeper上。High level api 会启动另外一个线程去每隔一段时间，offsite自动同步到zookeeper上。换句话说，如果使用了High level api， 每个message只能被读一次，一旦读了这条message之后，无论我consumer的处理是否ok。High level api的另外一个线程会自动的把offiste+1同步到zookeeper上。如果consumer读取数据出了问题，offsite也会在zookeeper上同步。因此，如果consumer处理失败了，会继续执行下一条。这往往是不对的行为。因此，Best Practice是一旦consumer处理失败，直接让整个conusmer group抛Exception终止，但是最后读的这一条数据是丢失了，因为在zookeeper里面的offsite已经+1了。等再次启动conusmer group的时候，已经从下一条开始读取处理了。</p><p>Low level api是consumer读的partition的offsite在consumer自己的程序中维护。不会同步到zookeeper上。但是为了kafka manager能够方便的监控，一般也会手动的同步到zookeeper上。这样的好处是一旦读取某个message的consumer失败了，这条message的offsite我们自己维护，我们不会+1。下次再启动的时候，还会从这个offsite开始读。这样可以做到exactly once对于数据的准确性有保证。</p><p>对于Consumer group：</p><ol><li>允许consumer group（包含多个consumer，如一个集群同时消费）对一个topic进行消费，不同的consumer group之间独立消费。</li><li>为了对减小一个consumer group中不同consumer之间的分布式协调开销，指定partition为最小的并行消费单位，即一个group内的consumer只能消费不同的partition。<br><img src="/images/kafka-2-12.png" alt=""></li></ol><p>Consumer与Partition的关系：</p><ul><li>如果consumer比partition多，是浪费，因为kafka的设计是在一个partition上是不允许并发的，所以consumer数不要大于partition数</li><li>如果consumer比partition少，一个consumer会对应于多个partitions，这里主要合理分配consumer数和partition数，否则会导致partition里面的数据被取的不均匀</li><li>如果consumer从多个partition读到数据，不保证数据间的顺序性，kafka只保证在一个partition上数据是有序的，但多个partition，根据你读的顺序会有不同</li><li>增减consumer，broker，partition会导致rebalance，所以rebalance后consumer对应的partition会发生变化</li><li>High-level接口中获取不到数据的时候是会block的</li></ul><p>负载低的情况下可以每个线程消费多个partition。但负载高的情况下，Consumer 线程数最好和Partition数量保持一致。如果还是消费不过来，应该再开 Consumer 进程，进程内线程数同样和分区数一致。</p><p>消费消息时，kafka client需指定topic以及partition number（每个partition对应一个逻辑日志流，如topic代表某个产品线，partition代表产品线的日志按天切分的结果），consumer client订阅后，就可迭代读取消息，如果没有消息，consumer client会阻塞直到有新的消息发布。consumer可以累积确认接收到的消息，当其确认了某个offset的消息，意味着之前的消息也都已成功接收到，此时broker会更新zookeeper上地offset registry。</p><h2 id="高效的数据传输"><a href="#高效的数据传输" class="headerlink" title="高效的数据传输"></a>高效的数据传输</h2><ol><li>发布者每次可发布多条消息（将消息加到一个消息集合中发布）， consumer每次迭代消费一条消息。</li><li>不创建单独的cache，使用系统的page cache。发布者顺序发布，订阅者通常比发布者滞后一点点，直接使用Linux的page cache效果也比较后，同时减少了cache管理及垃圾收集的开销。</li><li>使用sendfile优化网络传输，减少一次内存拷贝。</li></ol><h1 id="Kafka-与-Zookeeper"><a href="#Kafka-与-Zookeeper" class="headerlink" title="Kafka 与 Zookeeper"></a>Kafka 与 Zookeeper</h1><h2 id="Zookeeper-协调控制"><a href="#Zookeeper-协调控制" class="headerlink" title="Zookeeper 协调控制"></a>Zookeeper 协调控制</h2><ol><li>管理broker与consumer的动态加入与离开。(Producer不需要管理，随便一台计算机都可以作为Producer向Kakfa Broker发消息)</li><li>触发负载均衡，当broker或consumer加入或离开时会触发负载均衡算法，使得一<br>个consumer group内的多个consumer的消费负载平衡。（因为一个comsumer消费一个或多个partition，一个partition只能被一个consumer消费）</li><li>维护消费关系及每个partition的消费信息。</li></ol><h2 id="Zookeeper上的细节"><a href="#Zookeeper上的细节" class="headerlink" title="Zookeeper上的细节"></a>Zookeeper上的细节</h2><ol><li>每个broker启动后会在zookeeper上注册一个临时的broker registry，包含broker的ip地址和端口号，所存储的topics和partitions信息。</li><li>每个consumer启动后会在zookeeper上注册一个临时的consumer registry：包含consumer所属的consumer group以及订阅的topics。</li><li>每个consumer group关联一个临时的owner registry和一个持久的offset registry。对于被订阅的每个partition包含一个owner registry，内容为订阅这个partition的consumer id；同时包含一个offset registry，内容为上一次订阅的offset。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zookeeper全解析——Paxos作为灵魂</title>
      <link href="/2017/10/24/zookeeper-1/"/>
      <url>/2017/10/24/zookeeper-1/</url>
      
        <content type="html"><![CDATA[<p>非常努力想找到原文出处，不过在网上发现好多，但都是转载的，只能标注一下自己看到的博客地址：<a href="http://blog.sina.com.cn/s/blog_5d97745a0101ey63.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_5d97745a0101ey63.html</a></p><p>原计划在介绍完ZK Client之后就着手ZK Server的介绍，但是发现ZK Server所包含的内容实在太多，并不是简简单单一篇Blog就能搞定的。于是决定从基础搞起比较好。</p><p>那么ZK Server最基础的东西是什么呢？我想应该是Paxos了。所以本文会介绍Paxos以及它在ZK Server中对应的实现。</p><p>先说Paxos，它是一个基于消息传递的一致性算法，Leslie Lamport在1990年提出，近几年被广泛应用于分布式计算中，Google的Chubby，Apache的Zookeeper都是基于它的理论来实现的，Paxos还被认为是到目前为止唯一的分布式一致性算法，其它的算法都是Paxos的改进或简化。有个问题要提一下，Paxos有一个前提：没有拜占庭将军问题。就是说Paxos只有在一个可信的计算环境中才能成立，这个环境是不会被入侵所破坏的。</p><p>关于Paxos的具体描述可以在Wiki中找到：<a href="http://zh.wikipedia.org/zh-cn/Paxos算法。网上关于Paxos分析的文章也很多。这里希望用最简单的方式加以描述并建立起Paxos和ZK" target="_blank" rel="noopener">http://zh.wikipedia.org/zh-cn/Paxos算法。网上关于Paxos分析的文章也很多。这里希望用最简单的方式加以描述并建立起Paxos和ZK</a><br> Server的对应关系。</p><p>Paxos描述了这样一个场景，有一个叫做Paxos的小岛(Island)上面住了一批居民，岛上面所有的事情由一些特殊的人决定，他们叫做议员(Senator)。议员的总数(Senator Count)是确定的，不能更改。岛上每次环境事务的变更都需要通过一个提议(Proposal)，每个提议都有一个编号(PID)，这个编号是一直增长的，不能倒退。每个提议都需要超过半数((Senator<br> Count)/2 +1)的议员同意才能生效。每个议员只会同意大于当前编号的提议，包括已生效的和未生效的。如果议员收到小于等于当前编号的提议，他会拒绝，并告知对方：你的提议已经有人提过了。这里的当前编号是每个议员在自己记事本上面记录的编号，他不断更新这个编号。整个议会不能保证所有议员记事本上的编号总是相同的。现在议会有一个目标：保证所有的议员对于提议都能达成一致的看法。</p><p>好，现在议会开始运作，所有议员一开始记事本上面记录的编号都是0。有一个议员发了一个提议：将电费设定为1元/度。他首先看了一下记事本，嗯，当前提议编号是0，那么我的这个提议的编号就是1，于是他给所有议员发消息：1号提议，设定电费1元/度。其他议员收到消息以后查了一下记事本，哦，当前提议编号是0，这个提议可接受，于是他记录下这个提议并回复：我接受你的1号提议，同时他在记事本上记录：当前提议编号为1。发起提议的议员收到了超过半数的回复，立即给所有人发通知：1号提议生效！收到的议员会修改他的记事本，将1好提议由记录改成正式的法令，当有人问他电费为多少时，他会查看法令并告诉对方：1元/度。</p><p>现在看冲突的解决：假设总共有三个议员S1-S3，S1和S2同时发起了一个提议:1号提议，设定电费。S1想设为1元/度, S2想设为2元/度。结果S3先收到了S1的提议，于是他做了和前面同样的操作。紧接着他又收到了S2的提议，结果他一查记事本，咦，这个提议的编号小于等于我的当前编号1，于是他拒绝了这个提议：对不起，这个提议先前提过了。于是S2的提议被拒绝，S1正式发布了提议:<br> 1号提议生效。S2向S1或者S3打听并更新了1号法令的内容，然后他可以选择继续发起2号提议。</p><p>好，我觉得Paxos的精华就这么多内容。现在让我们来对号入座，看看在ZK Server里面Paxos是如何得以贯彻实施的。</p><p>小岛(Island)——ZK Server Cluster</p><p>议员(Senator)——ZK Server</p><p>提议(Proposal)——ZNode Change(Create/Delete/SetData…)</p><p>提议编号(PID)——Zxid(ZooKeeper Transaction Id)</p><p>正式法令——所有ZNode及其数据</p><p>貌似关键的概念都能一一对应上，但是等一下，Paxos岛上的议员应该是人人平等的吧，而ZK Server好像有一个Leader的概念。没错，其实Leader的概念也应该属于Paxos范畴的。如果议员人人平等，在某种情况下会由于提议的冲突而产生一个“活锁”（所谓活锁我的理解是大家都没有死，都在动，但是一直解决不了冲突问题）。Paxos的作者Lamport在他的文章”The<br> Part-Time Parliament“中阐述了这个问题并给出了解决方案——在所有议员中设立一个总统，只有总统有权发出提议，如果议员有自己的提议，必须发给总统并由总统来提出。好，我们又多了一个角色：总统。</p><p>总统——ZK Server Leader</p><p>又一个问题产生了，总统怎么选出来的？oh, my god! It’s a long story. 在淘宝核心系统团队的Blog上面有一篇文章是介绍如何选出总统的，有兴趣的可以去看看：<a href="http://rdc.taobao.com/blog/cs/?p=162" target="_blank" rel="noopener">http://rdc.taobao.com/blog/cs/?p=162</a></p><p>现在我们假设总统已经选好了，下面看看ZK Server是怎么实施的。</p><p>情况一：</p><p>屁民甲(Client)到某个议员(ZK Server)那里询问(Get)某条法令的情况(ZNode的数据)，议员毫不犹豫的拿出他的记事本(local storage)，查阅法令并告诉他结果，同时声明：我的数据不一定是最新的。你想要最新的数据？没问题，等着，等我找总统Sync一下再告诉你。</p><p>情况二：</p><p>屁民乙(Client)到某个议员(ZK Server)那里要求政府归还欠他的一万元钱，议员让他在办公室等着，自己将问题反映给了总统，总统询问所有议员的意见，多数议员表示欠屁民的钱一定要还，于是总统发表声明，从国库中拿出一万元还债，国库总资产由100万变成99万。屁民乙拿到钱回去了(Client函数返回)。</p><p>情况三：</p><p>总统突然挂了，议员接二连三的发现联系不上总统，于是各自发表声明，推选新的总统，总统大选期间政府停业，拒绝屁民的请求。</p><p>呵呵，到此为止吧，当然还有很多其他的情况，但这些情况总是能在Paxos的算法中找到原型并加以解决。这也正是我们认为Paxos是Zookeeper的灵魂的原因。当然ZK Server还有很多属于自己特性的东西：Session, Watcher，Version等等等等，需要我们花更多的时间去研究和学习。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>scala之隐式转换</title>
      <link href="/2017/10/17/scala-1/"/>
      <url>/2017/10/17/scala-1/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark streaming集成kafka的两种方式及区别</title>
      <link href="/2017/10/16/sparkstreaming-kafka/"/>
      <url>/2017/10/16/sparkstreaming-kafka/</url>
      
        <content type="html"><![CDATA[<p>Spark Streaming 与 Kafka 集成接收数据的方式有两种：</p><ul><li>Receiver-based Approach</li><li>Direct Approach (No Receivers)</li></ul><h1 id="两种方式的区别"><a href="#两种方式的区别" class="headerlink" title="两种方式的区别"></a>两种方式的区别</h1><h2 id="Receiver-based-Approach"><a href="#Receiver-based-Approach" class="headerlink" title="Receiver-based Approach"></a>Receiver-based Approach</h2><p>构造函数为：KafkaUtils.createDstream(ssc, [zk], [consumer group id], [per-topic,partitions] )<br>使用了receivers来接收数据，利用的是Kafka高层次的消费者api，对于所有的receivers接收到的数据将会保存在spark executors中，然后通过Spark Streaming启动job来处理这些数据，默认会丢失，可启用WAL日志（开启后效率会下降），该日志存储在HDFS上。</p><p>1、创建一个receiver来对kafka进行定时拉取数据，ssc的rdd分区和kafka的topic分区不是一个概念，故如果增加特定主体分区数仅仅是增加一个receiver中消费topic的线程数，并不增加spark的并行处理数据数量<br>2、对于不同的group和topic可以使用多个receivers创建不同的DStream<br>3、如果启用了WAL,需要设置存储级别,即<br><code>KafkaUtils.createStream(….,StorageLevel.MEMORY_AND_DISK_SER)</code></p><h2 id="Direct-Approach-No-Receivers"><a href="#Direct-Approach-No-Receivers" class="headerlink" title="Direct Approach (No Receivers)"></a>Direct Approach (No Receivers)</h2><p>区别Receiver接收数据，这种方式定期地从kafka的topic+partition中查询最新的偏移量，再根据偏移量范围在每个batch里面处理数据，使用的是kafka的简单消费者(SimpleConsumer)api</p><p>这种方式有如下优点：<br>1、简化并行读取：<br>如果要读取多个partition,不需要创建多个输入DStream然后对它们进行union操作。Spark会创建跟Kafka partition一样多的RDD partition，并且会并行从Kafka中读取数据。所以在Kafka partition和RDD partition之间，有一个一对一的映射关系。<br>2、高性能：<br>如果要保证零数据丢失，在基于receiver的方式中，需要开启WAL机制。这种方式其实效率低下，因为数据实际上被复制了两份，Kafka自己本身就有高可靠的机制，会对数据复制一份，而这里又会复制一份到WAL中。而基于direct的方式，不依赖Receiver，不需要开启WAL机制，只要Kafka中作了数据的复制，那么就可以通过Kafka的副本进行恢复。<br>3、恰好恰好一次语义(Exactly-once-semantics):<br>基于receiver的方式，读取kafka数据是使用Kafka的高阶API来将消费过的offset保存在ZooKeeper中的。这种方式配合着WAL机制可以保证数据零丢失的高可靠性，但是却无法保证数据被处理恰好一次，这种方式存在zookeeper和spark的偏移量不一致(同步)的情况，导致数据会被多次处理。<br>基于direct的方式，使用kafka的简单api，Spark Streaming自己就负责追踪消费的offset，并保存在checkpoint中，Spark自己一定是同步的，消除了Spark与zookeeper中偏移量不一致的问题，因此可以保证数据消费恰好一次。缺点是无法使用基于zookeeper的kafka监控工具。</p><h1 id="Direct方式代码实现逻辑"><a href="#Direct方式代码实现逻辑" class="headerlink" title="Direct方式代码实现逻辑"></a>Direct方式代码实现逻辑</h1><p>1、通过 <code>val kafkaCluster = new KafkaCluster(kafkaParams)</code> 创建一个kafkaCluster，kafkaCluster负责与kafka交互。<br>2、通过 <code>val kafkaPartitionsE = kafkaCluster.getPartition(topics)</code> 获取该topic集合对应的各个partition集合（一个topic-&gt;partition集合）<br>3、通过 <code>val kafkaPartitions = kafkaPartitionsE.right.get</code> 获取TopicAndPartition的集合<br>4、通过 <code>val consumerOffsetsE = kafkaCluster.getConsumerOffset(groupId,kafkaPartitions)</code> 获取到该groupId在该topic的每个partition中的offset；<br>5、通过 <code>kafkaCluster.getEarliestLeaderOffset(kafkaPartitions).regit.get</code> 或者<br><code>kafkaCluster.getLatestLeaderOffset(kafkaPartitions).regit.get</code>分别获取该topic的每个partition现在的最小、最大offset，对该groupId对应的各topic的各partition的offset是否在区间内进行判断。<br>然后返回一个(TopicAndPartition,offset)的map集合。<br>6、然后根据 <code>val kafkaStream = kafkaUtils.createDirectStream()</code> 方法创建DirectKafkaInputDStream；<br>创建时需要根据情况设置 <code>auto.offset.reset</code> 参数;<br>该处若设置成smallest，从最小的开始消费;若设置为largest，从最新的开始读取；不设置即从上次消费的地方读取;<br>7、数据取出来处理完之后，通过遍历kafkaStream，获取每个分区的offset，使用 <code>kafkaCluster.setConsumerOffsets</code> 方法同步到Zookeeper中<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">kafkaStream.foreachRDD(rdd =&gt; &#123;</span><br><span class="line">      //得到已读取的topic每个分区的offset</span><br><span class="line">      val offsetsList = rdd.asInstanceOf[HasOffsetRanges].offsetRanges</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (offsets &lt;- offsetsList) &#123;</span><br><span class="line">        val topicAndPartition = TopicAndPartition(offsets.topic, offsets.partition)</span><br><span class="line"></span><br><span class="line">        // 更新offset到kafkaCluster ,将topic每个分区的offset保存到ZooKeeper中</span><br><span class="line">        val o = kafkaCluster.setConsumerOffsets(groupId, Map(topicAndPartition -&gt; offsets.untilOffset))</span><br><span class="line">        <span class="keyword">if</span> (o.isLeft) &#123;</span><br><span class="line">          println(s<span class="string">"Error updating the offset to Kafka cluster: <span class="variable">$&#123;o.left.get&#125;</span>"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> spark streaming </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>更新Xcode导致Git报错的问题</title>
      <link href="/2017/10/16/git-1/"/>
      <url>/2017/10/16/git-1/</url>
      
        <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>更新Xcode以后使用Git报错:<br><img src="/images/git-1-1.png" alt=""></p><h1 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h1><p>1、输入<code>sudo xcodebuild -license</code>打开条款<br>2、将条款拖到最后，输入agree同意条款然后就可以正常使用了<br><img src="/images/git-1-2.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
            <tag> Xcode </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark streaming使用中的问题</title>
      <link href="/2017/09/06/sparkstreaming-2/"/>
      <url>/2017/09/06/sparkstreaming-2/</url>
      
        <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>调用new KafkaCluster(kafkaParams)方法的时候报错。<br>报错代码如下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val brokers =<span class="string">"ip1:9092,ip2:9092,ip3:9092"</span>    </span><br><span class="line">val kafkaParams = Map[String, String](      </span><br><span class="line">  <span class="string">"metadata.broker.list"</span> -&gt; brokers,</span><br><span class="line">  <span class="string">"serializer.class"</span> -&gt; <span class="string">"kafka.serializer.StringEncoder"</span>)</span><br><span class="line">val kafkaCluster = new KafkaCluster(kafkaParams) <span class="comment">#报错</span></span><br></pre></td></tr></table></figure></p><p>报错信息为：not found: type KafkaCluster ，说找不到这个类.<br>但是查看jar包中确实是有这个类:<br><img src="/images/sparkstreaming-1.png" alt=""></p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>该类是私有的所以不能外部访问，将该类的源码拷出来贴到复制到自己的工程下。并将代码中的private[spark]都删掉就OK了。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> spark streaming </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>scala批量操作redis</title>
      <link href="/2017/08/28/redis-1/"/>
      <url>/2017/08/28/redis-1/</url>
      
        <content type="html"><![CDATA[<p>记录一下。。。</p><h1 id="redis批量入库"><a href="#redis批量入库" class="headerlink" title="redis批量入库"></a>redis批量入库</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">object Pipeline &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val jedis = new Jedis(<span class="string">"192.168.1.7"</span>, 6379)</span><br><span class="line">    val p = jedis.pipelined()</span><br><span class="line">    val key = <span class="string">"KEY"</span></span><br><span class="line">    var index = 0</span><br><span class="line">    <span class="keyword">for</span> (i &lt;- 1 to 100000) &#123;</span><br><span class="line">      p.hset(key, i.toString(), <span class="string">"Value:"</span> + i)</span><br><span class="line">      index = index + 1</span><br><span class="line">      <span class="keyword">if</span> (index % 1000 == 0) &#123; //1000条插入一次</span><br><span class="line">        p.sync()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    p.sync()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="redis批量查询"><a href="#redis批量查询" class="headerlink" title="redis批量查询"></a>redis批量查询</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 使用hscan批量读取数据，速度很快，而且不会堵塞客户端，当数据量比较大的时候，不适合一次加载出所有的数据和所有的key，可以使用hscan</span><br><span class="line"> */</span><br><span class="line">def main(args: Array[String]): Unit = &#123;</span><br><span class="line">  val KEY = <span class="string">"KEY"</span></span><br><span class="line">  var ip = <span class="string">"192.168.1.7"</span></span><br><span class="line">  val jedis = new Jedis(ip, 6379)</span><br><span class="line">  var index = 0</span><br><span class="line">  val <span class="built_in">set</span>: Set[String] = Set()</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    val scanParams = new ScanParams()</span><br><span class="line">    scanParams.count(3000) //设置每次scan的条数</span><br><span class="line">    val info = jedis.hscan(KEY, String.valueOf(index), scanParams)</span><br><span class="line">    index = Integer.parseInt(info.getStringCursor()) //scan完之后的下一个数字</span><br><span class="line">    val list = info.getResult //获取一次读出来的3000条数据</span><br><span class="line">    val iter = list.iterator()</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">      val info = iter.next()</span><br><span class="line">      val key = info.getKey</span><br><span class="line">      val value = info.getValue</span><br><span class="line">      val json = new JSONObject(value)</span><br><span class="line">      val keys = json.keys()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">while</span> (index &gt; 0) //当index为0的时候说明数据已经全部读完</span><br><span class="line">  jedis.close()</span><br></pre></td></tr></table></figure><h1 id="redis批量删除"><a href="#redis批量删除" class="headerlink" title="redis批量删除"></a>redis批量删除</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">val arr: ArrayBuffer[String] = ArrayBuffer()</span><br><span class="line">arr.+=(<span class="string">"AA"</span>)</span><br><span class="line">arr.+=(<span class="string">"BB"</span>)</span><br><span class="line">arr.+=(<span class="string">"CC"</span>)</span><br><span class="line"><span class="keyword">if</span> (arr.size != 0 &amp;&amp; arr.size % 1000 == 0) &#123;</span><br><span class="line">       jedis.hdel(getKey, arr: _*) //arr: _* 相当于将数组变成了可变参数的形式，类似AA,BB,CC</span><br><span class="line">       arr.clear()</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
            <tag> scala </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>linux 问题汇总三：文件重定向时报权限不够</title>
      <link href="/2017/08/28/linux-3/"/>
      <url>/2017/08/28/linux-3/</url>
      
        <content type="html"><![CDATA[<h1 id="问题描述（是什么）"><a href="#问题描述（是什么）" class="headerlink" title="问题描述（是什么）"></a>问题描述（是什么）</h1><p>使用命令<code>sudo &quot;echo &#39;aaaa&#39; &gt; /usr/local/aa.log&quot;</code>重定向文件时报权限不够</p><p>错误信息：<br><img src="/images/linux-1.png" alt=""></p><h1 id="原因分析（为什么）"><a href="#原因分析（为什么）" class="headerlink" title="原因分析（为什么）"></a>原因分析（为什么）</h1><p>使用以上命令重定向的时候，sudo只用在了echo上，而重定向并没有用到sudo权限，所以会出现<code>权限不够</code>的情况。</p><h1 id="解决方案（怎么做）"><a href="#解决方案（怎么做）" class="headerlink" title="解决方案（怎么做）"></a>解决方案（怎么做）</h1><p>解决方案有两个：</p><ul><li>一是使用命令<code>sudo sh -c &quot;echo &quot;aa&quot; &gt;&gt; aa.log&quot;</code>，加上<code>sh -c</code>给整条语句赋sudo权限</li><li>二是使用管道和tee命令，该命令可以从标准输入中读入信息并将其写入标准输出或文件中。<br>命令如下：<br><code>echo &quot;aa&quot; |sudo tee -a aa.log</code><br>其中tee命令中的<code>-a</code>，相当于重定向。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>linux 问题汇总四：手动执行脚本成功，但是加入定时任务执行失败</title>
      <link href="/2017/08/28/linux-4/"/>
      <url>/2017/08/28/linux-4/</url>
      
        <content type="html"><![CDATA[<h1 id="问题描述（是什么）"><a href="#问题描述（是什么）" class="headerlink" title="问题描述（是什么）"></a>问题描述（是什么）</h1><p>编写的定时脚本，手动执行的时候没有问题，但是加入crontab定时任务之后就执行失败了。</p><p>其中脚本如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">length=`ps -ef | grep com.tzq.Test01 | grep java | wc -l`</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$length</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$length</span>"</span> -eq <span class="string">"0"</span> ];<span class="keyword">then</span>  </span><br><span class="line">        <span class="built_in">kill</span> -9 $(ps -ef|grep com.tzq.Test02 |gawk <span class="string">'$0 !~/grep/ &#123;print $2&#125;'</span> |tr -s <span class="string">'\n'</span> <span class="string">' '</span>)</span><br><span class="line">        sleep 1</span><br><span class="line">        nohup /home/<span class="built_in">test</span>/Test02.sh &amp;</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p><p>脚本是监控Test01进程的数量，当数量为0的时候，就将Test02进程重新启动。每次手动执行的时候，Test02进程都正常重启，但是放到定时任务里，程序就启动失败。</p><h1 id="原因分析（为什么）"><a href="#原因分析（为什么）" class="headerlink" title="原因分析（为什么）"></a>原因分析（为什么）</h1><ul><li>命令没有用全路径，没有引入环境变量，crontab不知道执行的是哪个目录下的命令。</li><li>需要自行加载环境变量</li></ul><h1 id="解决（怎么做）"><a href="#解决（怎么做）" class="headerlink" title="解决（怎么做）"></a>解决（怎么做）</h1><ul><li>所有命令使用全路径</li><li>使用<code>export</code>或者<code>source</code>命令加载环境变量<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">export</span> PATH=/sbin:/bin:/usr/sbin:/usr/bin <span class="comment">#加载环境变量</span></span><br><span class="line">length=`/bin/ps -ef | grep com.tzq.Test01 | grep /usr/<span class="built_in">local</span>/jdk1.7.0_67/bin/java | wc -l`</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$length</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$length</span>"</span> -eq <span class="string">"0"</span> ];<span class="keyword">then</span>  </span><br><span class="line">        /bin/<span class="built_in">kill</span> -9 $(/bin/ps -ef|grep com.tzq.Test02|gawk <span class="string">'$0 !~/grep/ &#123;print $2&#125;'</span> |tr -s <span class="string">'\n'</span> <span class="string">' '</span>)</span><br><span class="line">        /bin/sleep 1</span><br><span class="line">        /usr/bin/nohup /home/<span class="built_in">test</span>/Test02.sh &amp;</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka监控工具-KafkaOffsetMonitor</title>
      <link href="/2017/08/28/kafka-1/"/>
      <url>/2017/08/28/kafka-1/</url>
      
        <content type="html"><![CDATA[<h1 id="使用背景"><a href="#使用背景" class="headerlink" title="使用背景"></a>使用背景</h1><p>由于Kafka集群每次查询生产消费情况、节点状态等信息，都需要使用命令行查询，不方便也不够直观。</p><h1 id="监控系统搭建"><a href="#监控系统搭建" class="headerlink" title="监控系统搭建"></a>监控系统搭建</h1><p>kafka监控系统的搭建非常简单，<br>1、下载KafkaOffsetMonitor-assembly-0.2.0.jar包<br>下载地址：<br><a href="https://github.com/quantifind/KafkaOffsetMonitor/releases/download/v0.2.0/KafkaOffsetMonitor-assembly-0.2.0.jar" target="_blank" rel="noopener">https://github.com/quantifind/KafkaOffsetMonitor/releases/download/v0.2.0/KafkaOffsetMonitor-assembly-0.2.0.jar</a></p><p>2、创建执行脚本<code>kafka_monitor.sh</code>如下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line">java -cp KafkaOffsetMonitor-assembly-0.2.0.jar \</span><br><span class="line">com.quantifind.kafka.offsetapp.OffsetGetterWeb \</span><br><span class="line">--zk ip1:2181,ip2:2181,ip3:2181 \</span><br><span class="line">--port 8089 \</span><br><span class="line">--refresh 10.seconds \</span><br><span class="line">--retain 1.days &amp;</span><br></pre></td></tr></table></figure></p><p>3、执行脚本<code>sudo sh kafka_monitor.sh</code></p><p>4、打开<a href="http://ip:8089/#/" target="_blank" rel="noopener">http://ip:8089/#/</a> 页面查看kafka信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Topic： 创建Topic名称</span><br><span class="line">Partition： 分区编号</span><br><span class="line">Offset： 表示该Parition已经消费了多少Message</span><br><span class="line">LogSize： 表示该Partition生产了多少Message</span><br><span class="line">Lag： 表示有多少条Message未被消费</span><br><span class="line">Owner： 表示消费者</span><br><span class="line">Created： 表示该Partition创建时间</span><br><span class="line">Last Seen： 表示消费状态刷新最新时间</span><br></pre></td></tr></table></figure></p><p><strong>groupId列表页面</strong><br><img src="/images/kafka-1-1.png" alt=""><br><strong>Topic列表页面</strong><br><img src="/images/kafka-1-2.png" alt=""><br><strong>kafka集群节点列表页面</strong><br><img src="/images/kafka-1-3.png" alt=""><br><strong>一个消费者组对一个topic的消费情况记录</strong><br><img src="/images/kafka-1-4.png" alt=""><br><strong>一个消费者组中一个topic的历史消费情况记录</strong><br><img src="/images/kafka-1-5.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spark work目录定期清理</title>
      <link href="/2017/08/25/spark-1/"/>
      <url>/2017/08/25/spark-1/</url>
      
        <content type="html"><![CDATA[<h1 id="问题背景（是什么）"><a href="#问题背景（是什么）" class="headerlink" title="问题背景（是什么）"></a>问题背景（是什么）</h1><p>在跑spark任务的时候发现任务不能执行。在查看的时候发现spark work节点的/usr/ 目录满了。</p><h1 id="原因排查（为什么）"><a href="#原因排查（为什么）" class="headerlink" title="原因排查（为什么）"></a>原因排查（为什么）</h1><p>使用spark standalone模式执行任务，没提交一次任务，在每个节点work目录下都会生成一个文件夹，命名规则app-20160614191730-0249。该文件夹下是任务提交时，各节点从主节点下载的程序所需要的资源文件。<font color="#FF0000"> 这些目录每次执行都会生成，且不会自动清理</font>，执行任务过多会将内存撑爆。</p><p>spark work目录：<br><img src="/images/spark-1-1.png" alt=""></p><p>每一个application的目录中都是该spark任务运行所需要的依赖包：<br><img src="/images/spark-1-2.png" alt=""></p><h1 id="解决方案（怎么做）"><a href="#解决方案（怎么做）" class="headerlink" title="解决方案（怎么做）"></a>解决方案（怎么做）</h1><p>解决：<br>添加配置：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_WORKER_OPTS=<span class="string">"</span></span><br><span class="line"><span class="string">-Dspark.worker.cleanup.enabled=true</span></span><br><span class="line"><span class="string">-Dspark.worker.cleanup.interval=1800</span></span><br><span class="line"><span class="string">-Dspark.worker.cleanup.appDataTtl=3600"</span></span><br></pre></td></tr></table></figure></p><p><strong>注: </strong><br>-Dspark.worker.cleanup.enabled=true：是否开启自动清理<br>-Dspark.worker.cleanup.interval=1800：清理周期，每隔多长时间清理一次，单位秒<br>-Dspark.worker.cleanup.appDataTtl=3600：保留最近多长时间的数据</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>linux 问题汇总二：如何处理僵尸进程</title>
      <link href="/2017/08/25/linux-2/"/>
      <url>/2017/08/25/linux-2/</url>
      
        <content type="html"><![CDATA[<h1 id="问题描述（是什么）"><a href="#问题描述（是什么）" class="headerlink" title="问题描述（是什么）"></a>问题描述（是什么）</h1><p>跑任务的过程中总会遇到一些进程杀不死，但是也不执行，我们管这个叫僵尸进程。</p><h1 id="解决（怎么做）"><a href="#解决（怎么做）" class="headerlink" title="解决（怎么做）"></a>解决（怎么做）</h1><p>一般通过以下命令来杀死：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -e -o ppid,<span class="built_in">stat</span> | grep Z |awk <span class="string">'&#123;print $1&#125;'</span> |xargs <span class="built_in">kill</span> -9</span><br></pre></td></tr></table></figure></p><p>ps参数含义：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-e：显示所有进程，也可以使用-A</span><br><span class="line">-o：自定义输出字段 就是显示那些字段，我们这显示 ppid(进程父id)，<span class="built_in">stat</span>(状态)这两个字段</span><br></pre></td></tr></table></figure></p><p>为什么 grep Z 呢？<br><strong>科普一下</strong><br>进程状态主要有：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">R(运行中)</span><br><span class="line">S(睡眠中，可中断)</span><br><span class="line">D(睡眠中，不可中断)</span><br><span class="line">T(暂停或被追踪)</span><br><span class="line">X( 已退出，即将被销毁)</span><br><span class="line">Z(已退出，成为僵尸进程)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>linux 问题汇总一：判断一个脚本中的变量是否为空</title>
      <link href="/2017/08/25/linux-1/"/>
      <url>/2017/08/25/linux-1/</url>
      
        <content type="html"><![CDATA[<h1 id="问题描述（是什么）"><a href="#问题描述（是什么）" class="headerlink" title="问题描述（是什么）"></a>问题描述（是什么）</h1><p>在编写监控脚本时，判断监控信息是否为空的时候一直判断不正确。<br>脚本很简单，就是监控一个监听对应端口的进程，当该进程消失后重新启动。但是不管进程是否存在，都输出”progress is normal”。<br>脚本如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">info=$(sudo lsof -i :8888)</span><br><span class="line"><span class="keyword">if</span> [ ! -n <span class="variable">$info</span> ]</span><br><span class="line"><span class="keyword">then</span>  </span><br><span class="line">        nohup /home/restart.sh &amp;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"progress is null"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span>  <span class="string">"progress is normal"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p><h1 id="原因排查（为什么）"><a href="#原因排查（为什么）" class="headerlink" title="原因排查（为什么）"></a>原因排查（为什么）</h1><p>查询资料发现，原来是变量没有加双引号的原因。</p><p><strong>科普一下</strong><br>shell脚本中单引号、双引号、无引号区别：<br>单引号：（是什么就输出什么，管你是变量还是命令）<br>　　可以说是所见即所得：即将单引号内的内容原样输出，或者描述为单引号里面看见的是什么就会输出什么。<br>双引号：（先把引号内的变量或命令执行一下）<br>　　把双引号内的内容输出出来；如果内容中有命令，变量等，会先把变量，命令解析出结果，然后在输出最终内容来。<br>　　双引号内命令或变量的写法为<code>命令或变量</code>或$（命令或变量）。<br>无引号：（先把引号内的变量或命令执行一下，不同的是，如果有空格或特殊字符可就不行了）<br>　　把内容输出出来，可能不会将含有空格的字符串视为一个整体输出，如果内容中有命令，变量等，会先把变量，命令解析结果，然后在输出最终内容来，如果字符串中带有空格等特殊字符，则不能完整的输出，需要改加双引号，一般连续的字符串，数字，路径等可以用，不过最好用双引号替代之</p><h1 id="解决（怎么做）"><a href="#解决（怎么做）" class="headerlink" title="解决（怎么做）"></a>解决（怎么做）</h1><p>所以以上脚本应该改为：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">info=$(sudo lsof -i :8888)</span><br><span class="line"><span class="keyword">if</span> [ ! -n <span class="string">"<span class="variable">$info</span>"</span> ]</span><br><span class="line"><span class="keyword">then</span>  </span><br><span class="line">        nohup /home/restart.sh &amp;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"progress is null"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span>  <span class="string">"progress is normal"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hdfs动态添加、删除节点</title>
      <link href="/2017/08/21/hdfs-1/"/>
      <url>/2017/08/21/hdfs-1/</url>
      
        <content type="html"><![CDATA[<h1 id="需求背景（是什么）"><a href="#需求背景（是什么）" class="headerlink" title="需求背景（是什么）"></a>需求背景（是什么）</h1><p>在正常生产环境中，hdfs集群是不能随便停的，那么如何在不停止集群的情况下动态的添加和删除节点呢？</p><h1 id="添加节点（怎么做）"><a href="#添加节点（怎么做）" class="headerlink" title="添加节点（怎么做）"></a>添加节点（怎么做）</h1><p>1.修改slaves文件，添加需要增加的节点host或者ip，并将其更新到各个节点.</p><p>2.在datanode中启动执行启动datanode命令。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sh sbin/hadoop-daemon.sh start datanode</span><br><span class="line">start-balancer.sh -threshold 5 <span class="comment">#添加节点后做均衡</span></span><br></pre></td></tr></table></figure></p><p>3.可以通过web界面查看节点添加情况。</p><h1 id="删除节点（怎么做）"><a href="#删除节点（怎么做）" class="headerlink" title="删除节点（怎么做）"></a>删除节点（怎么做）</h1><p>1、配置NameNode的hdfs-site.xml，增加dfs.hosts.exclude配置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;name&gt;dfs.hosts.exclude&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;/usr/<span class="built_in">local</span>/hadoop/hadoop-2.6.0/excludes&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br></pre></td></tr></table></figure></p><p>2、在对应路径（/usr/local/hadoop/hadoop-2.6.0）下新建excludes文件，并写入待删除DataNode的ip或域名<br><img src="/images/hdfs-1.png" alt=""><br>3、在NameNode上刷新所有DataNode<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -refreshNodes</span><br><span class="line">start-balancer.sh -threshold 5 <span class="comment">#添加节点后做均衡</span></span><br></pre></td></tr></table></figure></p><p>4、在web页面可以观测到DataNode显示Decommission In Progress，然后会逐渐变为Dead<br><img src="/images/hdfs-2.png" alt=""></p><p>等该节点下架完成会显示为Decommission，例如：<br><img src="/images/hdfs-3.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hdfs </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Maven报错：Missing artifact jdk.tools:jdk.tools:jar:1.7</title>
      <link href="/2017/08/18/maven_1/"/>
      <url>/2017/08/18/maven_1/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> maven </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ELK搭建使用</title>
      <link href="/2017/08/14/elk1/"/>
      <url>/2017/08/14/elk1/</url>
      
        <content type="html"><![CDATA[<h1 id="部署环境"><a href="#部署环境" class="headerlink" title="部署环境"></a>部署环境</h1><p>Elasticsearch:2.4.0<br>kibana:4.6.0<br>logstash:2.0.0</p><p>注：Elasticsearch、Kibana、Lostash的下载地址统一为<a href="https://www.elastic.co/downloads/" target="_blank" rel="noopener">https://www.elastic.co/downloads/</a></p><h1 id="安装Elasticsearch集群"><a href="#安装Elasticsearch集群" class="headerlink" title="安装Elasticsearch集群"></a>安装Elasticsearch集群</h1><h2 id="安装Elasticsearch"><a href="#安装Elasticsearch" class="headerlink" title="安装Elasticsearch"></a>安装Elasticsearch</h2><p>解压elasticsearch-2.4.0.tar.gz，修改配置文件：config/elasticsearch.yml<br><img src="/images/elk-1.png" alt=""></p><p>如果要配置集群，需要两个节点上的elasticsearch配置的cluster.name相同，都启动可以自动组成集群，这里如果不改cluster.name则默认是cluster.name=elasticsearch，node.name随意取但是集群内的各节点不能相同。</p><p>另一个节点配置如下：<br><img src="/images/elk-2.png" alt=""></p><p>安装完成，因为elasticsearch有远程执行脚本的功能，容易中木马病毒，所以不允许用root用户启动，root用户是起不来的，想启动elasticsearch只能用一般的用户启动。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch</span><br><span class="line">./bin/elasticsearch -d <span class="comment">#后台启动</span></span><br></pre></td></tr></table></figure></p><p>但是一般用户在启动Elasticsearch的时候，报错如下<br><img src="/images/elk-15.png" alt=""><br>我们采用sudo chown -R tianzhongqiang elasticsearch-2.4.0 修改一下文件的所有者(组)，就可以执行了</p><p>打开localhost:9200,将会看到以下内容<br><img src="/images/elk-13.png" alt=""></p><p>返回数据中包含配置的cluster_name和name，以及ES的版本等信息。</p><h2 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h2><p>1、elasticsearch-head插件安装<br>在bin目录下安装head插件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./plugin install mobz/elasticsearch-head</span><br></pre></td></tr></table></figure></p><p><img src="/images/elk-3.png" alt=""></p><p>head插件是一个用浏览器跟ES集群交互的插件，可以查看集群状态、集群的doc内容、执行搜索和普通的Rest请求等。<br><a href="http://192.168.1.137:9200/_plugin/head/" target="_blank" rel="noopener">http://192.168.1.137:9200/_plugin/head/</a> 页面来查看ES集群状态<br><img src="/images/elk-14.png" alt=""></p><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><ul><li>要配置network.host才能别的机器或者网卡访问，否则只能是127.0.0.1或者localhost访问</li><li>注意配置yml结尾的配置文件都需要冒号后面加空格才行</li><li>如果是集群最好添加防脑裂配置：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">discovery.zen.ping.multicast.enabled: <span class="literal">false</span></span><br><span class="line">discovery.zen.ping_timeout: 120s</span><br><span class="line">client.transport.ping_timeout: 60s</span><br><span class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"192.168.1.136"</span>,<span class="string">"192.168.1.137"</span>, <span class="string">"192.168.1.138"</span>]</span><br></pre></td></tr></table></figure></li></ul><h1 id="安装Kibana"><a href="#安装Kibana" class="headerlink" title="安装Kibana"></a>安装Kibana</h1><p>解压安装，修改配置文件 config/kibana.yml的elasticsearch.url属性即可。<br><img src="/images/elk-4.png" alt=""></p><h2 id="安装插件-1"><a href="#安装插件-1" class="headerlink" title="安装插件"></a>安装插件</h2><h3 id="安装Marvel"><a href="#安装Marvel" class="headerlink" title="安装Marvel"></a>安装Marvel</h3><p>Marvel是Elasticsearch的管理和监控工具，在开发环境下免费使用。它包含了一个叫做Sense的交互式控制台，使用户方便的通过浏览器直接与Elasticsearch进行交互。<br>1、在elasticsearch中安装Marvel<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/plugin install license</span><br><span class="line">bin/plugin install marvel-agent</span><br></pre></td></tr></table></figure></p><p>2、在kibana中安装Marvel<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kibana plugin --install elasticsearch/marvel/latest</span><br></pre></td></tr></table></figure></p><p>启动<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch</span><br><span class="line">bin/kibana</span><br></pre></td></tr></table></figure></p><p>查看<a href="http://192.168.1.137:5601/app/marvel" target="_blank" rel="noopener">http://192.168.1.137:5601/app/marvel</a> 页面：<br><img src="/images/elk-11.png" alt=""></p><p><img src="/images/elk-12.png" alt=""></p><h3 id="安装Sense"><a href="#安装Sense" class="headerlink" title="安装Sense"></a>安装Sense</h3><p>Sense是flask写的elasticsearch查询工具。<br>支持es查询语言自动提示，es结构自动提示，支持两种主题，支持查询历史记录，支持快捷键。<br>在Kibana目录运行命令安装 Sense插件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/kibana plugin --install elastic/sense</span><br></pre></td></tr></table></figure></p><p>查看<a href="http://192.168.1.137:5601/app/sense" target="_blank" rel="noopener">http://192.168.1.137:5601/app/sense</a> 页面：<br><img src="/images/elk-16.png" alt=""></p><h1 id="安装logstash"><a href="#安装logstash" class="headerlink" title="安装logstash"></a>安装logstash</h1><p>直接解压安装就ok。<br>配置logstash的配置文件<br><img src="/images/elk-5.png" alt=""></p><p>两种启动方式都可以<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/logstash agent -f logstash_log4j_to_es.conf</span><br></pre></td></tr></table></figure></p><p><img src="/images/elk-8.png" alt=""></p><h1 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch</span><br><span class="line">bin/kibana</span><br><span class="line">bin/logstash -f logstash_log4j_to_es.conf</span><br></pre></td></tr></table></figure><p>打开：<a href="http://192.168.1.137:5601" target="_blank" rel="noopener">http://192.168.1.137:5601</a><br><img src="/images/elk-6.png" alt=""><br>警告显示，需要我们创建一个索引。</p><h2 id="创建索引："><a href="#创建索引：" class="headerlink" title="创建索引："></a>创建索引：</h2><p>Kibana界面日志检索只有当第一条日志通过Logstash进入ElasticSearch后，才能配置Kibana索引。</p><p>1、在“Index name or pattern”项下，填入一个elasticsearch的索引名，也即是Logstash配置文件中output项下的index对应的名称；在你这里应该是将“logstash-* ” 改成“test_log”<br>2、在“Time-field name”，选用默认的配置：“@timestamp”<br>3、点击“create”即可<br><img src="/images/elk-7.png" alt=""></p><h1 id="log4j日志接入"><a href="#log4j日志接入" class="headerlink" title="log4j日志接入"></a>log4j日志接入</h1><p>编写测试代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">package cn.tzq.spider;</span><br><span class="line"></span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">public class Test &#123;</span><br><span class="line">Logger logger = LoggerFactory.getLogger(Test.class);</span><br><span class="line">@org.junit.Test</span><br><span class="line">public void testName() throws Exception &#123;</span><br><span class="line"><span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">long s_time = System.currentTimeMillis();</span><br><span class="line">logger.info(<span class="string">"当前的时间戳："</span>+s_time);</span><br><span class="line">logger.warn(<span class="string">"warn："</span>+s_time);</span><br><span class="line">logger.error(<span class="string">"error："</span>+s_time);</span><br><span class="line">Thread.sleep(1000L);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>log4j配置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO,socket</span><br><span class="line"></span><br><span class="line">log4j.appender.socket=org.apache.log4j.net.SocketAppender</span><br><span class="line">log4j.appender.socket.RemoteHost=192.168.1.137</span><br><span class="line">log4j.appender.socket.Port=4567</span><br><span class="line">log4j.appender.socket.LocationInfo=<span class="literal">true</span></span><br></pre></td></tr></table></figure></p><p>执行代码，观察kibana页面变化<br><img src="/images/elk-9.png" alt=""></p><p>搜索错误信息<br><img src="/images/elk-10.png" alt=""></p><p>如果有问题可以去论坛讨论：<br><a href="https://discuss.elastic.co/categories" target="_blank" rel="noopener">https://discuss.elastic.co/categories</a><br>也可以去中文社区<br><a href="https://elasticsearch.cn/explore/category-2" target="_blank" rel="noopener">https://elasticsearch.cn/explore/category-2</a></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elk </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ELK搭建使用</title>
      <link href="/2017/08/14/elk-1/"/>
      <url>/2017/08/14/elk-1/</url>
      
        <content type="html"><![CDATA[<h1 id="需求背景（是什么）"><a href="#需求背景（是什么）" class="headerlink" title="需求背景（是什么）"></a>需求背景（是什么）</h1><p>1、由于执行的任务比较多，导致log日志比较大，不好查看，也不好排查问题。<br>2、集群分布式处理的任务，程序中打印的日志收集和分析都不方便。</p><h1 id="elk搭建（怎么做）"><a href="#elk搭建（怎么做）" class="headerlink" title="elk搭建（怎么做）"></a>elk搭建（怎么做）</h1><p>部署环境<br>Elasticsearch:2.4.0<br>kibana:4.6.0<br>logstash:2.0.0</p><p>注：Elasticsearch、Kibana、Lostash的下载地址统一为<a href="https://www.elastic.co/downloads/" target="_blank" rel="noopener">https://www.elastic.co/downloads/</a></p><h2 id="安装Elasticsearch集群"><a href="#安装Elasticsearch集群" class="headerlink" title="安装Elasticsearch集群"></a>安装Elasticsearch集群</h2><p>解压elasticsearch-2.4.0.tar.gz，修改配置文件：config/elasticsearch.yml<br><img src="/images/elk-1.png" alt=""></p><p>如果要配置集群，需要两个节点上的elasticsearch配置的cluster.name相同，都启动可以自动组成集群，这里如果不改cluster.name则默认是cluster.name=elasticsearch，node.name随意取但是集群内的各节点不能相同。</p><p>另一个节点配置如下：<br><img src="/images/elk-2.png" alt=""></p><p>安装完成，因为elasticsearch有远程执行脚本的功能，容易中木马病毒，所以不允许用root用户启动，root用户是起不来的，想启动elasticsearch只能用一般的用户启动。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch</span><br><span class="line">./bin/elasticsearch -d <span class="comment">#后台启动</span></span><br></pre></td></tr></table></figure></p><p>但是一般用户在启动Elasticsearch的时候，报错如下<br><img src="/images/elk-15.png" alt=""><br>我们采用sudo chown -R tianzhongqiang elasticsearch-2.4.0 修改一下文件的所有者(组)，就可以执行了</p><p>打开localhost:9200,将会看到以下内容<br><img src="/images/elk-13.png" alt=""></p><p>返回数据中包含配置的cluster_name和name，以及ES的版本等信息。</p><h3 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h3><p>1、elasticsearch-head插件安装<br>在bin目录下安装head插件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./plugin install mobz/elasticsearch-head</span><br></pre></td></tr></table></figure></p><p><img src="/images/elk-3.png" alt=""></p><p>head插件是一个用浏览器跟ES集群交互的插件，可以查看集群状态、集群的doc内容、执行搜索和普通的Rest请求等。<br><a href="http://192.168.1.137:9200/_plugin/head/" target="_blank" rel="noopener">http://192.168.1.137:9200/_plugin/head/</a> 页面来查看ES集群状态<br><img src="/images/elk-14.png" alt=""></p><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ul><li>要配置network.host才能别的机器或者网卡访问，否则只能是127.0.0.1或者localhost访问</li><li>注意配置yml结尾的配置文件都需要冒号后面加空格才行</li><li>如果是集群最好添加防脑裂配置：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">discovery.zen.ping.multicast.enabled: <span class="literal">false</span></span><br><span class="line">discovery.zen.ping_timeout: 120s</span><br><span class="line">client.transport.ping_timeout: 60s</span><br><span class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"192.168.1.136"</span>,<span class="string">"192.168.1.137"</span>, <span class="string">"192.168.1.138"</span>]</span><br></pre></td></tr></table></figure></li></ul><h2 id="安装Kibana"><a href="#安装Kibana" class="headerlink" title="安装Kibana"></a>安装Kibana</h2><p>解压安装，修改配置文件 config/kibana.yml的elasticsearch.url属性即可。<br><img src="/images/elk-4.png" alt=""></p><h3 id="安装Marvel插件"><a href="#安装Marvel插件" class="headerlink" title="安装Marvel插件"></a>安装Marvel插件</h3><p>Marvel是Elasticsearch的管理和监控工具，在开发环境下免费使用。它包含了一个叫做Sense的交互式控制台，使用户方便的通过浏览器直接与Elasticsearch进行交互。<br>1、在elasticsearch中安装Marvel<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/plugin install license</span><br><span class="line">bin/plugin install marvel-agent</span><br></pre></td></tr></table></figure></p><p>2、在kibana中安装Marvel<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kibana plugin --install elasticsearch/marvel/latest</span><br></pre></td></tr></table></figure></p><p>启动<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch</span><br><span class="line">bin/kibana</span><br></pre></td></tr></table></figure></p><p>查看<a href="http://192.168.1.137:5601/app/marvel" target="_blank" rel="noopener">http://192.168.1.137:5601/app/marvel</a> 页面：<br><img src="/images/elk-11.png" alt=""></p><p><img src="/images/elk-12.png" alt=""></p><h3 id="安装Sense插件"><a href="#安装Sense插件" class="headerlink" title="安装Sense插件"></a>安装Sense插件</h3><p>Sense是flask写的elasticsearch查询工具。<br>支持es查询语言自动提示，es结构自动提示，支持两种主题，支持查询历史记录，支持快捷键。<br>在Kibana目录运行命令安装 Sense插件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/kibana plugin --install elastic/sense</span><br></pre></td></tr></table></figure></p><p>查看<a href="http://192.168.1.137:5601/app/sense" target="_blank" rel="noopener">http://192.168.1.137:5601/app/sense</a> 页面：<br><img src="/images/elk-16.png" alt=""></p><h2 id="安装logstash"><a href="#安装logstash" class="headerlink" title="安装logstash"></a>安装logstash</h2><p>直接解压安装就ok。<br>配置logstash的配置文件<br><img src="/images/elk-5.png" alt=""></p><p>两种启动方式都可以<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/logstash agent -f logstash_log4j_to_es.conf</span><br></pre></td></tr></table></figure></p><p><img src="/images/elk-8.png" alt=""></p><h1 id="elk使用（怎么做）"><a href="#elk使用（怎么做）" class="headerlink" title="elk使用（怎么做）"></a>elk使用（怎么做）</h1><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch</span><br><span class="line">bin/kibana</span><br><span class="line">bin/logstash -f logstash_log4j_to_es.conf</span><br></pre></td></tr></table></figure><p>打开：<a href="http://192.168.1.137:5601" target="_blank" rel="noopener">http://192.168.1.137:5601</a><br><img src="/images/elk-6.png" alt=""><br>警告显示，需要我们创建一个索引。</p><h3 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h3><p>Kibana界面日志检索只有当第一条日志通过Logstash进入ElasticSearch后，才能配置Kibana索引。</p><p>1、在“Index name or pattern”项下，填入一个elasticsearch的索引名，也即是Logstash配置文件中output项下的index对应的名称；在你这里应该是将“logstash-* ” 改成“test_log”<br>2、在“Time-field name”，选用默认的配置：“@timestamp”<br>3、点击“create”即可<br><img src="/images/elk-7.png" alt=""></p><h2 id="log4j日志接入"><a href="#log4j日志接入" class="headerlink" title="log4j日志接入"></a>log4j日志接入</h2><p>编写测试代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">package cn.tzq.spider;</span><br><span class="line"></span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">public class Test &#123;</span><br><span class="line">Logger logger = LoggerFactory.getLogger(Test.class);</span><br><span class="line">@org.junit.Test</span><br><span class="line">public void testName() throws Exception &#123;</span><br><span class="line"><span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">long s_time = System.currentTimeMillis();</span><br><span class="line">logger.info(<span class="string">"当前的时间戳："</span>+s_time);</span><br><span class="line">logger.warn(<span class="string">"warn："</span>+s_time);</span><br><span class="line">logger.error(<span class="string">"error："</span>+s_time);</span><br><span class="line">Thread.sleep(1000L);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>log4j配置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO,socket</span><br><span class="line"></span><br><span class="line">log4j.appender.socket=org.apache.log4j.net.SocketAppender</span><br><span class="line">log4j.appender.socket.RemoteHost=192.168.1.137</span><br><span class="line">log4j.appender.socket.Port=4567</span><br><span class="line">log4j.appender.socket.LocationInfo=<span class="literal">true</span></span><br></pre></td></tr></table></figure></p><p>执行代码，观察kibana页面变化<br><img src="/images/elk-9.png" alt=""></p><p>搜索错误信息<br><img src="/images/elk-10.png" alt=""></p><p>如果有问题可以去论坛讨论：<br><a href="https://discuss.elastic.co/categories" target="_blank" rel="noopener">https://discuss.elastic.co/categories</a><br>也可以去中文社区<br><a href="https://elasticsearch.cn/explore/category-2" target="_blank" rel="noopener">https://elasticsearch.cn/explore/category-2</a></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elk </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>flume1.6 taildir source使用</title>
      <link href="/2017/08/10/flume-taildir-source-1/"/>
      <url>/2017/08/10/flume-taildir-source-1/</url>
      
        <content type="html"><![CDATA[<h1 id="需求描述（需求是什么）"><a href="#需求描述（需求是什么）" class="headerlink" title="需求描述（需求是什么）"></a>需求描述（需求是什么）</h1><p>文件夹下每分钟生成一个文件，而该文件中的数据需要实时读取上报kafka。</p><h1 id="方案（方案是什么）"><a href="#方案（方案是什么）" class="headerlink" title="方案（方案是什么）"></a>方案（方案是什么）</h1><p>使用flume的taildir source和kafka sink实现。</p><h1 id="问题（问题是什么）"><a href="#问题（问题是什么）" class="headerlink" title="问题（问题是什么）"></a>问题（问题是什么）</h1><p>flume1.7中的taildir source正好满足，但是由于线上kafka版本使用的是0.8.2.0，而flume1.7只支持kafka0.9以上的版本。</p><p>官网描述如下：<br><img src="/images/flume-kafka-2.png" alt=""><br>意思就是：<br>该版本flume1.7目前支持Kafka 0.9.x系列版本（包含0.9.x以上）。而不再支持Kafka的旧版本（0.8.x）。</p><h1 id="解决方案（怎么做）"><a href="#解决方案（怎么做）" class="headerlink" title="解决方案（怎么做）"></a>解决方案（怎么做）</h1><p>解决方案有两个，一个是升级kafka到0.9.x以上版本，第二个就是将flume1.7的taildir source集成到flume1.6中。这里采用的是第二种。</p><p>集成过程中主要改动的是两个module</p><ul><li>将flume-taildir-source添加到flume-ng-sources</li><li>编译根据提示修改flume-ng-core下的部分文件</li></ul><h2 id="pom文件修改"><a href="#pom文件修改" class="headerlink" title="pom文件修改"></a>pom文件修改</h2><p>修改flume-taildir-source的pom.xml文件如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span>?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">Licensed to the Apache Software Foundation (ASF) under one or more</span><br><span class="line">contributor license agreements.  See the NOTICE file distributed with</span><br><span class="line">this work <span class="keyword">for</span> additional information regarding copyright ownership.</span><br><span class="line">The ASF licenses this file to You under the Apache License, Version 2.0</span><br><span class="line">(the <span class="string">"License"</span>); you may not use this file except <span class="keyword">in</span> compliance with</span><br><span class="line">the License.  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">     http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span><br><span class="line">distributed under the License is distributed on an <span class="string">"AS IS"</span> BASIS,</span><br><span class="line">WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">See the License <span class="keyword">for</span> the specific language governing permissions and</span><br><span class="line">limitations under the License.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;project xmlns=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> xmlns:xsi=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span><br><span class="line">  xsi:schemaLocation=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span><br><span class="line"></span><br><span class="line">  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line"></span><br><span class="line">  &lt;parent&gt;</span><br><span class="line">    &lt;artifactId&gt;flume-ng-sources&lt;/artifactId&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.flume&lt;/groupId&gt;</span><br><span class="line">    &lt;version&gt;1.6.0&lt;/version&gt;</span><br><span class="line">  &lt;/parent&gt;</span><br><span class="line"></span><br><span class="line">  &lt;groupId&gt;org.apache.flume.flume-ng-sources&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;flume-taildir-source&lt;/artifactId&gt;</span><br><span class="line">  &lt;name&gt;Flume Taildir Source&lt;/name&gt;</span><br><span class="line">  &lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.flume&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;flume-ng-core&lt;/artifactId&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">      &lt;groupId&gt;junit&lt;/groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;junit&lt;/artifactId&gt;</span><br><span class="line">      &lt;scope&gt;<span class="built_in">test</span>&lt;/scope&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">  &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure></p><p>修改pom文件之后发现程序报错了，报错信息如下：<br><img src="/images/flume-1.png" alt=""></p><p>从错误中可以看到，TaildirSource类中这两个覆写的方法是不存在的。<br>跟着这个思路我们看一下TaildirSource继承和实现的类和接口。<br><img src="/images/flume-3.png" alt=""></p><h2 id="修改flume-ng-core"><a href="#修改flume-ng-core" class="headerlink" title="修改flume-ng-core"></a>修改flume-ng-core</h2><p>查看flume-ng-core1.7的代码，发现这两个方法是实现的接口PollableSource中的方法。而1.6中不存在这两个方法。</p><ul><li>flume-ng-core1.6<br><img src="/images/flume-5.png" alt=""></li><li>flume-ng-core1.7<br><img src="/images/flume-4.png" alt=""></li></ul><p>最简单的方法就是直接将flume-ng-core1.7中PollableSource的内容复制到flume-ng-core1.6中，这样就ok了，其中还有几处编译出错的地方，其他错误跟该错误解决方法一致，参照flume-ng-core1.7的内容修改。</p><p>修改完成之后，将flume-ng-core1.6重新编译，然后再编译flume-taildir-source就可以了。</p><p>编译完成将flume-taildir-source-1.6.0.jar、flume-ng-core-1.6.0.jar放到线上flume的lib下就可以使用了。</p><h2 id="使用样例"><a href="#使用样例" class="headerlink" title="使用样例"></a>使用样例</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sinks= k1</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type = TAILDIR</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sources.r1.positionFile = /var/<span class="built_in">log</span>/flume/taildir_position.json</span><br><span class="line">a1.sources.r1.filegroups = f1 f2</span><br><span class="line">a1.sources.r1.filegroups.f1 = /var/<span class="built_in">log</span>/test1/example.log</span><br><span class="line">a1.sources.r1.headers.f1.headerKey1 = value1</span><br><span class="line">a1.sources.r1.filegroups.f2 = /var/<span class="built_in">log</span>/test2/.*<span class="built_in">log</span>.*</span><br><span class="line">a1.sources.r1.headers.f2.headerKey1 = value2</span><br><span class="line">a1.sources.r1.headers.f2.headerKey2 = value2-2</span><br><span class="line">a1.sources.r1.fileHeader = <span class="literal">true</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># channels 配置</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 10000000</span><br><span class="line">a1.channels.c1.transactionCapacity = 10000</span><br><span class="line">a1.channels.c1.keep-alive = 3</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line">a1.sinks.k1.topic = topic</span><br><span class="line">a1.sinks.k1.brokerList = node1:9092,node2:9092,node3:9092</span><br><span class="line">a1.sinks.k1.requiredAcks = 1</span><br><span class="line">a1.sinks.k1.batchSize = 1000</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><p>具体参数意义参照flume1.7的官网即可。</p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flume </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>flume1.6向kafka不同分区发送数据</title>
      <link href="/2017/08/07/flume-kafka-1/"/>
      <url>/2017/08/07/flume-kafka-1/</url>
      
        <content type="html"><![CDATA[<h1 id="问题背景（是什么）"><a href="#问题背景（是什么）" class="headerlink" title="问题背景（是什么）"></a>问题背景（是什么）</h1><p>Flume1.6向kafka发送数据时，发现kafka接收到的数据总是在一个partition中。</p><h1 id="原因排查（为什么）"><a href="#原因排查（为什么）" class="headerlink" title="原因排查（为什么）"></a>原因排查（为什么）</h1><p>Flume的官方文档中说法是：<br>Kafka Sink uses the topic and key properties from the FlumeEvent headers to send events to Kafka. If topic exists in the headers, the event will be sent to that specific topic, overriding the topic configured for the Sink. If key exists in the headers, the key will used by Kafka to partition the data between the topic partitions. Events with same key will be sent to the same partition. If the key is null, events will be sent to random partitions.</p><p>以上文档中说的很清楚，kafka-sink是从header里的key参数来确定将数据发到kafka的哪个分区中。如果为null，那么就会随机发布至分区中。但测试的结果是flume发布的数据会发布到一个分区中的。</p><p>查看flume的源码，也会发现：<br><img src="/images/flume-kafka-1.png" alt=""></p><p>所以，我们需要向header中写上随机的key，然后数据才会真正的向kafka分区进行随机发布。</p><h1 id="解决办法（怎么做）"><a href="#解决办法（怎么做）" class="headerlink" title="解决办法（怎么做）"></a>解决办法（怎么做）</h1><p>我们的办法是，向flume添加拦截器，官方文档说有一个UUID Interceptor，会为每个event的head添加一个随机唯一的key。其实我们直接用这个即可。</p><p>在flume添加的配置文件如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.interceptors = i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type=org.apache.flume.sink.solr.morphline.UUIDInterceptor<span class="variable">$Builder</span></span><br><span class="line">a1.sources.r1.interceptors.i1.headerName=key</span><br><span class="line">a1.sources.r1.interceptors.i1.preserveExisting=<span class="literal">false</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flume </tag>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
